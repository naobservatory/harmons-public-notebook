{
  "hash": "96cce90bfe1f182613fa389f7002601a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Workflow of O'Connell et al. (2023)\"\nsubtitle: \"Whole blood from US (RNA)\"\nauthor: \"Harmon Bhasin\"\ndate: 2024-09-05\nformat:\n  html:\n    toc: true # table of contents\n    toc-title: \"Table of contents\" # table of contents title\n    number-sections: true # number sections\n    number-depth: 3 # number depth to show in table of contents\n    toc-location: right # table of contents location\n    page-layout: full # full page layout\n    code-fold: true # Keep option to fold code (i.e. show or hide it; default: hide)\n    code-tools: true # Code menu in the header of your document that provides various tools for readers to interact with the source code\n    code-link: true # Enables hyper-linking of functions within code blocks to their online documentation\n    df-print: paged # print data frame\n    fig-format: svg\n    other-links:\n      - text: Paper\n        href: https://doi.org/10.1186/s12863-024-01223-z\n      - text: Data\n        href: https://www.ncbi.nlm.nih.gov/sra/?term=SRP429744\n    code-links:\n      - text: Code for this post\n        icon: file-code\n        href: https://github.com/naobservatory/harmons-public-notebook/blob/main/notebooks/2024-09-05-oconnell.qmd\neditor: \n  visual: true\n  render-on-save: true\ncomments:\n  hypothesis: true # hypothesis\nexecute: \n  freeze: auto\n  cache: true\ntitle-block-banner: \"#de2d26\"\n---\n\n\n\n\n\n\n\nThis is the first whole blood study of [this series](https://data.securebio.org/harmons-public-notebook/notebooks/2024-07-08_cebria-mendoza.html). In this post, I analyze [O'Connell 2023](https://doi.org/10.1186/s12863-024-01223-z), a dataset with 138 adult whole blood donors from Austin, TX.\n\n*This notebook uses the MGS Workflow v2.2.1 (note that this is old).*\n\n# The raw data\n\n## About\n\n[This dataset](https://www.ncbi.nlm.nih.gov/sra/?term=SRP429744) is composed of 138 samples which come from 138 individuals in Austin, TX. They performed RNA sequencing on whole blood samples.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Import libraries and extract metadata from sample names\nlibraries <- read_csv(libraries_path, show_col_types = FALSE)\n#meta_data <- read_csv('/Users/harmonbhasin/work/securebio/nao-harmon/thijssen2023/preprocessing/SraRunTable.txt') %>%\n#  select('Library Name', Run) %>% rename(sample = Run, library = 'Library Name')\n#libraries <- libraries %>%\n#  left_join(meta_data, by = 'sample') %>%\n#  select(sample, library=library.y) %>% \n#  filter(library != 'PCL21') %>%\n#  mutate(library = factor(library, levels = c(paste0('PCL', 1:20))))\n#libraries\n```\n:::\n\n\n\n### Sample + library preparation \n\nParaphrased from the paper:\n\n> Whole blood specimens were collected from 138 adult donors via PAXgene vacutainers at admission to the Emergency Department at Dell-Seton Medical Center (Austin, TX). Total RNA was isolated from archived PAXgene-stabilized whole blood using the PAXgene IVD Blood RNA Kit. Ribosomal RNA and globin mRNA-depleted cDNA libraries were prepared from 500 ng of total RNA using the Illumina TruSeq Stranded Total RNA Ribo-Zero Globin kit. Paired-end 150 bp sequencing was performed on the Illumina NovaSeq 6000 platform.\n\n*More details can be found [here](https://www.sciencedirect.com/science/article/pii/S0888754323001520?via%3Dihub#s0035).*\n\n## Quality control metrics\n\n\n\n\n\n\n\nIn total, these 138 samples contained ~3B read pairs. The samples had ~20.1M - 46.9M (mean ~22.5M) read pairs each. The number of reads looks pretty good, with a few samples having a much higher count. The total number of base pairs also looks reasonable, matching the trends of the number of reads. The duplication rate is high. Adapter content is quite low, although we can see library contamination (illumina_universal_adapter), and polya/polyg contamination.  As we'd expect, we see higher quality Q scores near the beginning of the read and a gradual decline towards the end of the read, however all positions seem to have a Q score of around 35 which means that our reads are \\~99.97% accurate. When looking at the Q score over all sequences, we can see a sharp peak around 35, which corresponds to the previous plot, indicating high read quality. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prepare data\nbasic_stats_raw_metrics <- basic_stats_raw %>%\n  select(library,\n         `# Read pairs` = n_read_pairs,\n         `Total base pairs\\n(approx)` = n_bases_approx,\n         `% Duplicates\\n(FASTQC)` = percent_duplicates) %>%\n  pivot_longer(-library, names_to = \"metric\", values_to = \"value\") %>%\n  mutate(metric = fct_inorder(metric)) \n\n# Set up plot templates\n\ng_basic <- ggplot(basic_stats_raw_metrics, aes(x = library, y = value)) +\n  geom_col(position = \"dodge\") +\n  scale_x_discrete() +\n  scale_y_continuous(expand = c(0, 0)) +\n  expand_limits(y = c(0, 100)) +\n  facet_grid(metric ~ ., scales = \"free\", space = \"free_x\", switch = \"y\") +\n  theme_kit + theme(\n    axis.title.y = element_blank(),\n    strip.text.y = element_text(face = \"plain\"),\n    axis.text.x = element_blank()\n  )\ng_basic\n```\n\n::: {.cell-output-display}\n![](2024-09-05-oconnell_files/figure-html/plot-basic-stats-1.svg)\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set up plotting templates\ng_qual_raw <- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters_raw <- g_qual_raw + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats_raw) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,NA),\n                     breaks = seq(0,10,1), expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0)) +\n  facet_grid(.~adapter)\ng_adapters_raw\n```\n\n::: {.cell-output-display}\n![](2024-09-05-oconnell_files/figure-html/plot-raw-quality-1.svg)\n:::\n\n```{.r .cell-code}\n# Visualize quality\ng_quality_base_raw <- g_qual_raw +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats_raw) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0))\ng_quality_base_raw\n```\n\n::: {.cell-output-display}\n![](2024-09-05-oconnell_files/figure-html/plot-raw-quality-2.svg)\n:::\n\n```{.r .cell-code}\ng_quality_seq_raw <- g_qual_raw +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats_raw) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0))\ng_quality_seq_raw\n```\n\n::: {.cell-output-display}\n![](2024-09-05-oconnell_files/figure-html/plot-raw-quality-3.svg)\n:::\n:::\n\n\n\n# Preprocessing\n\n## Summary\n\nThe average fraction of reads at each stage in the preprocessing pipeline is shown in the following table. Adapter trimming & filtering doesn't lose too many reads. Deduplication loses us about 27% of reads on average, then ribodepletion only loses as about 1% on average.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# TODO: Group by pool size as well\n# Count read losses\nn_reads_rel <- basic_stats %>% \n  select(sample, stage, percent_duplicates, n_read_pairs) %>%\n  group_by(sample) %>% \n  arrange(sample, stage) %>%\n  mutate(p_reads_retained = n_read_pairs / lag(n_read_pairs),\n         p_reads_lost = 1 - p_reads_retained,\n         p_reads_retained_abs = n_read_pairs / n_read_pairs[1],\n         p_reads_lost_abs = 1-p_reads_retained_abs,\n         p_reads_lost_abs_marginal = p_reads_lost_abs - lag(p_reads_lost_abs))\nn_reads_rel_display <- n_reads_rel %>% \n  rename(Stage=stage) %>% \n  group_by(Stage) %>% \n  summarize(`% Total Reads Lost (Cumulative)` = paste0(round(min(p_reads_lost_abs*100),1), \"-\", round(max(p_reads_lost_abs*100),1), \" (mean \", round(mean(p_reads_lost_abs*100),1), \")\"),\n            `% Total Reads Lost (Marginal)` = paste0(round(min(p_reads_lost_abs_marginal*100),1), \"-\", round(max(p_reads_lost_abs_marginal*100),1), \" (mean \", round(mean(p_reads_lost_abs_marginal*100),1), \")\"), .groups=\"drop\") %>% \n  filter(Stage != \"raw_concat\") %>%\n  mutate(Stage = Stage %>% as.numeric %>% factor(labels=c(\"Trimming & filtering\", \"Deduplication\", \"Initial ribodepletion\", \"Secondary ribodepletion\")))\nn_reads_rel_display\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Stage\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"% Total Reads Lost (Cumulative)\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"% Total Reads Lost (Marginal)\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"Trimming & filtering\",\"2\":\"0.6-2.1 (mean 1)\",\"3\":\"0.6-2.1 (mean 1)\"},{\"1\":\"Deduplication\",\"2\":\"23.5-58.5 (mean 27.8)\",\"3\":\"22.5-56.5 (mean 26.8)\"},{\"1\":\"Initial ribodepletion\",\"2\":\"24.4-59.9 (mean 29)\",\"3\":\"0.6-4.1 (mean 1.2)\"},{\"1\":\"Secondary ribodepletion\",\"2\":\"24.5-60.1 (mean 29.1)\",\"3\":\"0.1-0.6 (mean 0.1)\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n## Quality control metrics\n\nTrimming + cleaning gets rid of the library contamination, however there is still some polya + polyg contamination, however given that it makes a small portion of adapter content, I think we're fine ignoring it. Read quality slightly improves after preprocessing + cleaning, this is noticable near the end positions. When looking at the q score over all reads, we see that cleaning gives us most of our improvement.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng_qual <- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters <- g_qual + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,20),\n                     breaks = seq(0,50,10), expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~adapter)\ng_adapters\n```\n\n::: {.cell-output-display}\n![](2024-09-05-oconnell_files/figure-html/plot-quality-1.svg)\n:::\n\n```{.r .cell-code}\n# Visualize quality\ng_quality_base <- g_qual +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~.)\ng_quality_base\n```\n\n::: {.cell-output-display}\n![](2024-09-05-oconnell_files/figure-html/plot-quality-2.svg)\n:::\n\n```{.r .cell-code}\ng_quality_seq <- g_qual +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0)) +\n  facet_grid(stage~., scales = \"free_y\")\ng_quality_seq\n```\n\n::: {.cell-output-display}\n![](2024-09-05-oconnell_files/figure-html/plot-quality-3.svg)\n:::\n:::\n\n\n\nThese plots below show the trends from above in each sample. Everything looks pretty good.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng_stage_trace <- ggplot(basic_stats, aes(x=stage, group=sample)) +\n  theme_kit\n\n# Plot reads over preprocessing\ng_reads_stages <- g_stage_trace +\n  geom_line(aes(y=n_read_pairs)) +\n  scale_y_continuous(\"# Read pairs\", expand=c(0,0), limits=c(0,NA))\ng_reads_stages\n```\n\n::: {.cell-output-display}\n![](2024-09-05-oconnell_files/figure-html/preproc-figures-1.svg)\n:::\n\n```{.r .cell-code}\n# Plot relative read losses during preprocessing\ng_reads_rel <- ggplot(n_reads_rel, \n                      aes(x=stage, group=sample)) +\n  geom_line(aes(y=p_reads_lost_abs_marginal)) +\n  scale_y_continuous(\"% Total Reads Lost\", expand=c(0,0), \n                     labels = function(x) x*100) +\n  theme_kit\ng_reads_rel\n```\n\n::: {.cell-output-display}\n![](2024-09-05-oconnell_files/figure-html/preproc-figures-2.svg)\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstage_dup <- basic_stats %>% group_by(stage) %>% \n  summarize(dmin = min(percent_duplicates), dmax=max(percent_duplicates),\n            dmean=mean(percent_duplicates), .groups = \"drop\")\n\ng_dup_stages <- g_stage_trace +\n  geom_line(aes(y=percent_duplicates)) +\n  scale_y_continuous(\"% Duplicates\", limits=c(0,NA), expand=c(0,0))\ng_dup_stages\n```\n\n::: {.cell-output-display}\n![](2024-09-05-oconnell_files/figure-html/preproc-dedup-1.svg)\n:::\n\n```{.r .cell-code}\ng_readlen_stages <- g_stage_trace + geom_line(aes(y=mean_seq_len)) +\n  scale_y_continuous(\"Mean read length (nt)\", expand=c(0,0), limits=c(0,NA))\ng_readlen_stages\n```\n\n::: {.cell-output-display}\n![](2024-09-05-oconnell_files/figure-html/preproc-dedup-2.svg)\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate reads lost during ribodepletion (approximation for % ribosomal reads)\nreads_ribo <- n_reads_rel %>% \n  filter(stage %in% c(\"dedup\", \"ribo_secondary\")) %>% \n  group_by(sample) %>% \n  summarize(p_reads_ribo=1-n_read_pairs[2]/n_read_pairs[1], .groups = \"drop\") %>%\n  inner_join(libraries, by = 'sample')\nreads_ribo_summ <- reads_ribo %>%\n  group_by(sample) %>%\n  summarize(min=min(p_reads_ribo), max=max(p_reads_ribo),\n            mean=mean(p_reads_ribo), .groups = \"drop\") %>%\n  inner_join(libraries, by = 'sample')\ng_reads_ribo <- ggplot(reads_ribo, \n                       aes(x=library, y=p_reads_ribo)) +\n  geom_point() + \n  scale_y_continuous(name=\"Approx % ribosomal reads\", limits=c(0,1),\n                     breaks=seq(0,1,0.2), expand=c(0,0), labels = function(y) y*100)+\n  theme_kit\ng_reads_ribo\n```\n\n::: {.cell-output-display}\n![](2024-09-05-oconnell_files/figure-html/ribo-frac-1.svg)\n:::\n:::\n\n\n\n# Taxonomic composition\n\n## High-level composition\n\nTo assess the high-level composition of the reads, I ran the ribodepleted files through Kraken2 and summarized the results with Bracken.\n\nThe groups listed below were created by Will:\n\n* Filtered (removed during cleaning)\n* Duplicate (removed during deduplication)\n* Ribosomal (removed during ribodepletion)\n* Unassigned (non-ribosomal reads that were not assigned to any taxon by Kraken/Bracken)\n* Bacterial (non-ribosomal reads assigned to the Bacteria domain by Kraken/Bracken)\n* Archaeal (non-ribosomal reads assigned to the Archaea domain by Kraken/Bracken)\n* Viral (non-ribosomal reads assigned to the Viruses domain by Kraken/Bracken)\n* Human (non-ribosomal reads assigned to the Eukarya domain by Kraken/Bracken)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclassifications <- c(\"Filtered\", \"Duplicate\", \"Ribosomal\", \"Unassigned\",\n                     \"Bacterial\", \"Archaeal\", \"Viral\", \"Human\")\n\n# Import composition data\ntax_final_dir <- file.path(results_dir, \"taxonomy_final\")\ncomp_path <- file.path(tax_final_dir, \"taxonomic_composition.tsv.gz\")\ncomp <- read_tsv(comp_path, show_col_types = FALSE) %>% left_join(libraries, by=\"sample\")\ncomp_minor <- comp %>% \n  filter(classification %in% c(\"Archaeal\", \"Viral\", \"Human\", \"Other\"))\ncomp_assigned <- comp %>%\n  filter(! classification %in% c(\"Filtered\", \"Duplicate\", \n                                 \"Ribosomal\", \"Unassigned\")) %>%\n  group_by(sample) %>%\n  mutate(p_reads = n_reads/sum(n_reads))\ncomp_assigned_minor <- comp_assigned %>% \n  filter(classification %in% c(\"Archaeal\", \"Viral\", \"Human\", \"Other\"))\n\n# Summarize composition\nread_comp_summ <- comp %>% \n  group_by(classification) %>%\n  summarize(n_reads = sum(n_reads), .groups = \"drop_last\") %>%\n  mutate(n_reads = replace_na(n_reads,0),\n         p_reads = n_reads/sum(n_reads),\n         pc_reads = p_reads*100) %>%\n  mutate(classification = factor(classification, levels=classifications)) %>%\n  select(classification, n_reads, pc_reads) %>%\n  rename(`# of reads` = n_reads, \"% of reads\" = pc_reads) %>%\n  mutate(`% of reads` = sprintf(\"%.2f\", `% of reads`))\nread_comp_summ\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"classification\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"# of reads\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"% of reads\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"Archaeal\",\"2\":\"836\",\"3\":\"0.00\"},{\"1\":\"Bacterial\",\"2\":\"1108806\",\"3\":\"0.04\"},{\"1\":\"Duplicate\",\"2\":\"834295220\",\"3\":\"26.89\"},{\"1\":\"Filtered\",\"2\":\"31542742\",\"3\":\"1.02\"},{\"1\":\"Human\",\"2\":\"2192104363\",\"3\":\"70.66\"},{\"1\":\"Ribosomal\",\"2\":\"41206479\",\"3\":\"1.33\"},{\"1\":\"Unassigned\",\"2\":\"1913558\",\"3\":\"0.06\"},{\"1\":\"Viral\",\"2\":\"2392\",\"3\":\"0.00\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prepare plotting templates\ng_comp_base <- ggplot(mapping=aes(x=library, y=p_reads, fill=classification)) +\n  scale_x_discrete(name=\"Plasma pool\") +\n  theme_kit + \n  theme(plot.title = element_text(hjust=0, face=\"plain\", size=rel(1.5)))\nscale_y_pc_reads <- purrr::partial(scale_y_continuous, name = \"% Reads\",\n                                   expand = c(0,0), labels = function(y) y*100)\ngeom_comp <- purrr::partial(geom_col, position = \"stack\", width = 1)\n\n# Define a color palette for the classification\nclassification_colors <- brewer.pal(8, \"Accent\")\nnames(classification_colors) <- c(\"Filtered\", \"Duplicate\", \"Ribosomal\", \"Unassigned\", \"Bacterial\", \"Archaeal\", \"Viral\", \"Human\")\nscale_fill_classification <- function() {\n  scale_fill_manual(values = classification_colors, name = \"Classification\")\n}\n\n# Plot overall composition\ng_comp <- g_comp_base + geom_comp(data = comp) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (all reads, all groups)\")\ng_comp\n```\n\n::: {.cell-output-display}\n![](2024-09-05-oconnell_files/figure-html/plot-composition-all-1.svg)\n:::\n\n```{.r .cell-code}\ng_comp_assigned <- g_comp_base + \n  geom_comp(data = comp_assigned) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (assigned reads, all groups)\")\ng_comp_assigned\n```\n\n::: {.cell-output-display}\n![](2024-09-05-oconnell_files/figure-html/plot-composition-all-2.svg)\n:::\n:::\n\n\n\n## Total viral content\n\nTotal viral fraction average $7.70 \\times 10^{-7}$ across samples. As a fraction of assigned (rather than total) reads, this jumped to $1.18 \\times 10^{-6}$:\n\n\n\n\n\n\n\n## Taxonomic composition of viruses\n\nThe two dominant viruses we see are Anellovirdae and Phycodnaviridae. The threshold for the label \"other\" are the set of families that make up less than 30% composition in all samples.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmajor_threshold <- 0.3\n\n# Identify major viral families\nviral_families_major_tab <- viral_families %>% \n  group_by(name, taxid) %>%\n  summarize(p_reads_viral_max = max(p_reads_viral), .groups=\"drop\") %>%\n  filter(p_reads_viral_max >= major_threshold)\nviral_families_major_list <- viral_families_major_tab %>% pull(name)\nviral_families_major <- viral_families %>% \n  filter(name %in% viral_families_major_list) %>%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_minor <- viral_families_major %>% \n  group_by(sample) %>%\n  summarize(p_reads_viral_major = sum(p_reads_viral), .groups = \"drop\") %>%\n  mutate(name = \"Other\", taxid=NA, p_reads_viral = 1-p_reads_viral_major) %>%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_display <- viral_families_major %>% \n  bind_rows(viral_families_minor) %>%\n  arrange(desc(p_reads_viral)) %>% \n  mutate(name = factor(name, levels=c(viral_families_major_list, \"Other\"))) %>%\n  rename(p_reads = p_reads_viral, classification=name) %>%\n  inner_join(libraries, by='sample')\n\n\npal <- c(brewer.pal(8, 'Dark2'),brewer.pal(8, 'Accent'), brewer.pal(8, 'Set1'), brewer.pal(8, 'Pastel1'), brewer.pal(8, 'Pastel2'))\n\nn_classifications <- length(unique(viral_families_display$classification)) - 1\n\ncustom_palette_with_black <- c(\n  pal[1:n_classifications],\n  \"black\"\n)\n\ng_families <- ggplot(data = viral_families_display, aes(x = library, y = p_reads, fill = classification)) +\n  geom_col(position = \"stack\", width = 1) +\n  scale_y_continuous(name = \"% Viral Reads\", \n                     limits = c(0, 1.01), \n                     breaks = seq(0, 1, 0.2),\n                     expand = c(0, 0), \n                     labels = function(y) y * 100) +\n  scale_fill_manual(values = custom_palette_with_black) +\n  scale_x_discrete(name = \"\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    legend.position = \"bottom\"\n  ) +\n  labs(title = \"Viral Family Composition\",\n       fill = \"Classification\")\n\ng_families\n```\n\n::: {.cell-output-display}\n![](2024-09-05-oconnell_files/figure-html/viral-family-composition-1.svg)\n:::\n:::\n\n\n\n# Human-infecting virus reads\n\n## Overall relative abundance\n\nI calculated the relative abundance of human-infecting viruses in two ways:\n\n-   First, as the total number of deduplicated human-virus reads in each sample, divided by the number of raw reads (\"All reads\"). This results in a viral fraction of $2.62 \\times 10^{-8}$ across all samples\n\n-   Second, as a fraction of preprocessed (cleaned, deduplicated, computationally ribodepleted) reads (\"Preprocessed reads\"). This results in a viral fraction of $3.73 \\times 10^{-8}$ across all samples.\n\n\n\n\n\n\n\n\n\n\n\n## Overall taxonomy and composition\n\nComposition of HV reads was changed from when looking at all viral reads. Only 1 out of the 137 samples had reads for human infecting viruses, with read composition coming from well established viral families in whole blood.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthreshold_major_family <- 0.01\n\n# Count reads for each human-viral family\nhv_family_counts <- hv_reads_family %>% \n  group_by(sample, name, taxid) %>%\n  count(name = \"n_reads_hv\") %>%\n  group_by(sample) %>%\n  mutate(p_reads_hv = n_reads_hv/sum(n_reads_hv))\n\n# Identify high-ranking families and group others\nhv_family_major_tab <- hv_family_counts %>% group_by(name) %>% \n  filter(p_reads_hv == max(p_reads_hv)) %>% filter(row_number() == 1) %>%\n  arrange(desc(p_reads_hv)) %>% filter(p_reads_hv > threshold_major_family)\nhv_family_counts_major <- hv_family_counts %>%\n  mutate(name_display = ifelse(name %in% hv_family_major_tab$name, name, \"Other\")) %>%\n  group_by(sample, name_display) %>%\n  summarize(n_reads_hv = sum(n_reads_hv), p_reads_hv = sum(p_reads_hv), \n            .groups=\"drop\") %>%\n  mutate(name_display = factor(name_display, \n                               levels = c(hv_family_major_tab$name, \"Other\")))\nhv_family_counts_display <- hv_family_counts_major %>%\n  rename(p_reads = p_reads_hv, classification = name_display) %>%\n  inner_join(libraries, by = 'sample')\n\n# Plot\ng_hv_family <- g_comp_base + \n  geom_col(data=hv_family_counts_display, position = \"stack\", width=1) +\n  scale_y_continuous(name=\"% HV Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_brewer(palette = 'Accent', name = \"Viral family\") +\n  labs(title=\"Family composition of human-viral reads\") +\n  guides(fill=guide_legend(ncol=4)) +\n  theme(plot.title = element_text(size=rel(1.4), hjust=0, face=\"plain\"))\ng_hv_family\n```\n\n::: {.cell-output-display}\n![](2024-09-05-oconnell_files/figure-html/hv-family-1.svg)\n:::\n\n```{.r .cell-code}\n# Get most prominent families for text\nhv_family_collate <- hv_family_counts %>%\n  group_by(name, taxid) %>% \n  summarize(n_reads_tot = sum(n_reads_hv),\n            p_reads_max = max(p_reads_hv), .groups=\"drop\") %>% \n  arrange(desc(n_reads_tot))\nhv_family_collate\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"name\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"taxid\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n_reads_tot\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"p_reads_max\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Anelloviridae\",\"2\":\"687329\",\"3\":\"3\",\"4\":\"0.4285714\"},{\"1\":\"Orthoherpesviridae\",\"2\":\"3044472\",\"3\":\"3\",\"4\":\"0.4285714\"},{\"1\":\"Poxviridae\",\"2\":\"10240\",\"3\":\"1\",\"4\":\"0.1428571\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n## Relative abundance of pathogenic viruses of interest\n\n\n\n\n\n\n\n\nEach dot represents a sample, colored by viral family. The x-axis shows the relative abundance of human-infecting viruses, and the y-axis shows the species.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspecies_family <- result %>% select(species, family) %>% rename('name' = 'species')\n\nplay <- hv_species_counts %>% \n  ungroup() %>%\n  inner_join(libraries, by = 'sample') %>%\n  inner_join(species_family, by = 'name')\n\nadjusted_play <- play %>% \n  group_by(name) %>%\n  mutate(virus_prevalence_num = n_distinct(sample)/n_distinct(libraries),\n         total_reads_hv = sum(n_reads_hv)) %>%\n  ungroup() %>%\n  mutate(name = fct_reorder(name, virus_prevalence_num, .desc=TRUE)) %>% \n  select(name, ra_reads_hv, family, virus_prevalence_num, total_reads_hv, n_reads_hv)\n\npal <- c(brewer.pal(8, 'Dark2'),brewer.pal(8, 'Accent'))\n\n#, labels = label_log(digits=2)\n\nra_dot <- ggplot(adjusted_play, aes(x = ra_reads_hv, y=name)) +\n  geom_quasirandom(orientation = 'y', aes(color = family)) +\n  scale_color_manual(values = pal) + \n    scale_x_log10(\n    \"Relative abundance human virus reads\",\n    labels=label_log(digits=3)\n  ) +\n  labs(y =  \"\",\n       color = 'Viral family') + \n  guides(color = guide_legend(ncol=2)) +\n  theme_light() + \n    theme(\n    axis.text.y = element_text(size = 10),\n    axis.text.x = element_text(size = 12),\n    axis.ticks.y = element_blank(),axis.line = element_line(colour = \"black\"),\n    axis.title.x = element_text(size = 14),    \n    legend.text = element_text(size = 10),\n    legend.title = element_text(size = 10, face=\"bold\"),\n    #legend.position = 'bottom',\n    legend.position = c(1, 1),  # Move legend to top right\n    legend.justification = c(1, 1),  # Align legend to top right\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank())\nra_dot\n```\n\n::: {.cell-output-display}\n![](2024-09-05-oconnell_files/figure-html/plot-pathogenic-viruses-1.svg)\n:::\n\n```{.r .cell-code}\n#  geom_text(aes(label = total_reads_hv, y = name), \n#            x = 1e-9, hjust = 0, vjust = 0.5, size = 3, \n#            check_overlap = TRUE)\n```\n:::\n\n\n\n\nWe see EBV, MPX (most likely contamination), and unclassified Anelloviridae, all of what are viruses we'd expect to see in whole blood.\n\n## Relative abundance assuming perfect human read removal\n\n\n\n\n\n\nAssuming we're able to perfectly remove all human reads, the average relative abundance of known human infecting virus is $9.89 \\times 10^{-7}$.\n\n# Conclusion\n\nThere were some takeways from this analysis:\n\n1. Within smaller datasets, we don't expect to find human infecting viruses in samples.\n2. Human reads tend to make up the majority of reads from whole blood.\n3. Anelloviridae doesn't seem to be as abundant in whole blood as it is in plasma.\n\n\n# Appendix\n\n## Human-infecting virus families, genera, and species\n\nTo get a good overview of families, genera, and species, we can look at a Sankey plot where the magnitude of relative abundance, averaged over all samples, is shown in parentheses.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to create links\ncreate_links <- function(data) {\n  family_to_genus <- data %>%\n    filter(!is.na(genus)) %>%\n    group_by(family, genus) %>%\n    summarise(value = n(), .groups = \"drop\") %>%\n    mutate(source = family, target = genus)\n  \n  genus_to_species <- data %>%\n    group_by(genus, species) %>%\n    summarise(value = n(), .groups = \"drop\") %>%\n    mutate(source = genus, target = species)\n\n  family_to_species <- data %>%\n    filter(is.na(genus)) %>%\n    group_by(family, species) %>%\n    summarise(value = n(), .groups = \"drop\") %>%\n    mutate(source = family, target = species)\n\n  bind_rows(family_to_genus, genus_to_species, family_to_species) %>%\n    filter(!is.na(source))\n}\n\n# Function to create nodes\ncreate_nodes <- function(links) {\n  data.frame(\n    name = c(links$source, links$target) %>% unique()\n  )\n}\n\n# Function to prepare data for Sankey diagram\nprepare_sankey_data <- function(links, nodes) {\n  links$IDsource <- match(links$source, nodes$name) - 1\n  links$IDtarget <- match(links$target, nodes$name) - 1\n  list(links = links, nodes = nodes)\n}\n\n# Function to create Sankey plot\ncreate_sankey_plot <- function(sankey_data) {\n  sankeyNetwork(\n    Links = sankey_data$links, \n    Nodes = sankey_data$nodes,\n    Source = \"IDsource\", \n    Target = \"IDtarget\",\n    Value = \"value\", \n    NodeID = \"name\",\n    sinksRight = TRUE,\n    nodeWidth = 25,\n    fontSize = 14,\n  )\n}\n\nsave_sankey_as_png <- function(sankey_plot, width = 1000, height = 800) {\n  # Save the plot as an HTML file\n  saveWidget(sankey_plot, sprintf('%s/sankey.html',data_dir))\n}\n\nformat_scientific <- function(x, digits=2) {\n  sapply(x, function(val) {\n    if (is.na(val) || abs(val) < 1e-15) {\n      return(\"0\")\n    } else {\n      exponent <- floor(log10(abs(val)))\n      coef <- val / 10^exponent\n      #return(sprintf(\"%.1f × 10^%d\", round(coef, digits), exponent))\n      # May or may not be smart, just keeping magnitude\n      return(sprintf(\"10^%d\", exponent))\n    }\n  })\n}\n\ndata <- result %>% \n  mutate(across(c(genus_n_reads_tot, genus_ra_reads_tot), ~replace_na(., 0)),\n         genus = ifelse(is.na(genus), \"Unknown Genus\", genus)) %>%\n  mutate(\n  species = paste0(species, sprintf(' (%s)', format_scientific(species_ra_reads_tot))),\n  genus = paste0(genus, sprintf(' (%s)', format_scientific(genus_ra_reads_tot))),\n  family = paste0(family, sprintf(' (%s)', format_scientific(family_ra_reads_tot)))\n)\nlinks <- as.data.frame(create_links(data))\nnodes <- create_nodes(links)\nsankey_data <- prepare_sankey_data(links, nodes)\nsankey <- create_sankey_plot(sankey_data)\n\nsankey\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"htmlwidget-781e424b3f620b570581\" style=\"width:100%;height:1462px;\" class=\"sankeyNetwork html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-781e424b3f620b570581\">{\"x\":{\"links\":{\"source\":[0,0,1,2,3,4,5,6],\"target\":[3,6,4,5,7,8,9,10],\"value\":[1,1,1,1,1,1,1,1]},\"nodes\":{\"name\":[\"Anelloviridae (10^-7)\",\"Orthoherpesviridae (10^-7)\",\"Poxviridae (10^-8)\",\"Alphatorquevirus (10^-8)\",\"Lymphocryptovirus (10^-7)\",\"Orthopoxvirus (10^-8)\",\"Unknown Genus (0)\",\"Alphatorquevirus homin24 (10^-8)\",\"Lymphocryptovirus humangamma4 (10^-7)\",\"Monkeypox virus (10^-8)\",\"Anelloviridae sp. (10^-8)\"],\"group\":[\"Anelloviridae (10^-7)\",\"Orthoherpesviridae (10^-7)\",\"Poxviridae (10^-8)\",\"Alphatorquevirus (10^-8)\",\"Lymphocryptovirus (10^-7)\",\"Orthopoxvirus (10^-8)\",\"Unknown Genus (0)\",\"Alphatorquevirus homin24 (10^-8)\",\"Lymphocryptovirus humangamma4 (10^-7)\",\"Monkeypox virus (10^-8)\",\"Anelloviridae sp. (10^-8)\"]},\"options\":{\"NodeID\":\"name\",\"NodeGroup\":\"name\",\"LinkGroup\":null,\"colourScale\":\"d3.scaleOrdinal(d3.schemeCategory20);\",\"fontSize\":14,\"fontFamily\":null,\"nodeWidth\":25,\"nodePadding\":10,\"units\":\"\",\"margin\":{\"top\":null,\"right\":null,\"bottom\":null,\"left\":null},\"iterations\":32,\"sinksRight\":true}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/htmlwidgets-1.5.4/htmlwidgets.js\"></script>\n<script src=\"../site_libs/d3-4.5.0/d3.min.js\"></script>\n<script src=\"../site_libs/sankey-1/sankey.js\"></script>\n<script src=\"../site_libs/sankeyNetwork-binding-0.4/sankeyNetwork.js\"></script>\n<link href=\"../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}