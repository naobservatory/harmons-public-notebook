{
  "hash": "549a376b52e85e2bb6777333fdca9fb9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Workflow of Aydillo et al. (2022)\"\nsubtitle: \"Whole blood from US (RNA)\"\nauthor: \"Harmon Bhasin\"\ndate: 2024-09-19\nformat:\n  html:\n    toc: true # table of contents\n    toc-title: \"Table of contents\" # table of contents title\n    number-sections: true # number sections\n    number-depth: 3 # number depth to show in table of contents\n    toc-location: right # table of contents location\n    page-layout: full # full page layout\n    code-fold: true # Keep option to fold code (i.e. show or hide it; default: hide)\n    code-tools: true # Code menu in the header of your document that provides various tools for readers to interact with the source code\n    code-link: true # Enables hyper-linking of functions within code blocks to their online documentation\n    df-print: paged # print data frame\n    fig-format: svg\n    other-links:\n      - text: Paper\n        href: https://doi.org/10.1038/s41541-022-00583-w\n      - text: Data\n        href: https://www.ncbi.nlm.nih.gov/bioproject/?term=GSE217770\n    code-links:\n      - text: Code for this post\n        icon: file-code\n        href: https://github.com/naobservatory/harmons-public-notebook/blob/main/notebooks/2024-09-19-aydillo.qmd\neditor: \n  visual: true\n  render-on-save: true\ncomments:\n  hypothesis: true # hypothesis\nexecute: \n  freeze: auto\n  cache: true\ntitle-block-banner: \"#de2d26\"\n---\n\n\n\n\n\n\n\n\nThis is the third and last whole blood study of [this series](https://data.securebio.org/harmons-public-notebook/notebooks/2024-07-08_cebria-mendoza.html). In this post, I analyze [Aydillo 2022](https://github.com/naobservatory/harmons-public-notebook/blob/main/notebooks/2024-09-12-thompson.qmd), a dataset with 53 healthy individuals in the USA.\n\n*I'd like to thank Lenni for giving me feedback on the notebook and Will for providing me with a boilerplate rmarkdown file. This notebook uses the MGS Workflow v2.2.1 (note that this is old).*\n\n# The raw data\n\n## About\n\n[This dataset](https://www.ncbi.nlm.nih.gov/bioproject/?term=GSE217770) is composed of 53 samples of whole blood from the US. For each sample, they performed RNA-sequencing, with Illumina NovaSeq 6000, producing 2x95 bp reads.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Import libraries and extract metadata from sample names\nlibraries <- read_csv(libraries_path, show_col_types = FALSE)\n```\n:::\n\n\n\n\n### Sample + library preparation \n\nThe following is paraphrased from the paper:\n\n> The study was carried out between October 2017 - August 2019. General inclusion criteria were male or non-pregnant female between, 18 and 39 years. Exclusion criteria included the previous history of Guillain-Barré syndrome, immunosuppression, history of influenza virus vaccination within 6 months prior to study enrollment or use of any other investigational drug or vaccine other than in the present study, among others. A complete list of inclusion and exclusion criteria is provided at https://clinicaltrials.gov/ct2/show/NCT03300050.\n> \n> PAXgene blood samples were processed for total RNA extraction using the Agencourt RNAdvance Blood Kit on a BioMek FXP Laboratory Automation Workstation. Concentration and RNA integrity number (RIN) of isolated RNA were determined using Quant-iT™ RiboGreen™ RNA Assay Kit and an RNA Standard Sensitivity Kit on a Fragment Analyzer Automated CE system, respectively. Subsequently, RNA-seq libraries were constructed from 300 ng of total RNA using the Universal Plus mRNA-Seq kit in a Biomek i7 Automated Workstation. The transcripts for ribosomal RNA (rRNA) and globin were further depleted using the AnyDeplete kit prior to the amplification of libraries. Library concentration was assessed fluorometrically using the Qubit dsDNA HS Kit, and quality was assessed with the Genomic DNA 50Kb Analysis Kit. Deep sequencing was subsequently performed using an S2 flow cell in a NovaSeq sequencing system (Illumina) (average read depth ~30 million pairs of 2 × 95 bp reads) at the New York Genome Center.\n\n## Quality control metrics\n\n\n\n\n\n\n\n\n\nIn total, these 53 samples contained ~1.7B read pairs. The samples had 27.2M - 37.3M (mean ~32.8M) read pairs each. The number of reads looks pretty good and consistent throughout all samples. The total number of base pairs also looks reasonable, matching the trends of the number of reads. The duplication rate is high. Adapter content is reasonable (below 10%). As we'd expect, we see higher quality Q scores near the beginning of the read and a gradual decline towards the end of the read, however all positions seem to have a Q score of 35 which means that our reads are \\~99.97% accurate. When looking at the Q score over all sequences, we can see a sharp peak after 35, which corresponds to the previous plot, indicating high read quality. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prepare data\nbasic_stats_raw_metrics <- basic_stats_raw %>%\n  select(library,\n         `# Read pairs` = n_read_pairs,\n         `Total base pairs\\n(approx)` = n_bases_approx,\n         `% Duplicates\\n(FASTQC)` = percent_duplicates) %>%\n  pivot_longer(-library, names_to = \"metric\", values_to = \"value\") %>%\n  mutate(metric = fct_inorder(metric)) \n\n# Set up plot templates\n\ng_basic <- ggplot(basic_stats_raw_metrics, aes(x = library, y = value)) +\n  geom_col(position = \"dodge\") +\n  scale_x_discrete() +\n  scale_y_continuous(expand = c(0, 0)) +\n  expand_limits(y = c(0, 100)) +\n  facet_grid(metric ~ ., scales = \"free\", space = \"free_x\", switch = \"y\") +\n  theme_kit + theme(\n    axis.title.y = element_blank(),\n    strip.text.y = element_text(face = \"plain\")\n  )\ng_basic\n```\n\n::: {.cell-output-display}\n![](2024-09-19-aydillo_files/figure-html/plot-basic-stats-1.svg)\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set up plotting templates\ng_qual_raw <- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters_raw <- g_qual_raw + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats_raw) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,NA),\n                     breaks = seq(0,10,1), expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0)) +\n  facet_grid(.~adapter)\ng_adapters_raw\n```\n\n::: {.cell-output-display}\n![](2024-09-19-aydillo_files/figure-html/plot-raw-quality-1.svg)\n:::\n\n```{.r .cell-code}\n# Visualize quality\ng_quality_base_raw <- g_qual_raw +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats_raw) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0))\ng_quality_base_raw\n```\n\n::: {.cell-output-display}\n![](2024-09-19-aydillo_files/figure-html/plot-raw-quality-2.svg)\n:::\n\n```{.r .cell-code}\ng_quality_seq_raw <- g_qual_raw +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats_raw) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0))\ng_quality_seq_raw\n```\n\n::: {.cell-output-display}\n![](2024-09-19-aydillo_files/figure-html/plot-raw-quality-3.svg)\n:::\n:::\n\n\n\n\n# Preprocessing\n\n## Summary\n\nThe average fraction of reads at each stage in the preprocessing pipeline is shown in the following table. Adapter trimming & filtering removes about 2.5% of reads. Deduplication loses us about 50% of reads on average which makes sense given the high duplication rate. The ribodepletion only loses about 0.6% on average which makes sense given the ribodepletion done during sample preparation.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# TODO: Group by pool size as well\n# Count read losses\nn_reads_rel <- basic_stats %>% \n  select(sample, stage, percent_duplicates, n_read_pairs) %>%\n  group_by(sample) %>% \n  arrange(sample, stage) %>%\n  mutate(p_reads_retained = n_read_pairs / lag(n_read_pairs),\n         p_reads_lost = 1 - p_reads_retained,\n         p_reads_retained_abs = n_read_pairs / n_read_pairs[1],\n         p_reads_lost_abs = 1-p_reads_retained_abs,\n         p_reads_lost_abs_marginal = p_reads_lost_abs - lag(p_reads_lost_abs))\nn_reads_rel_display <- n_reads_rel %>% \n  rename(Stage=stage) %>% \n  group_by(Stage) %>% \n  summarize(`% Total Reads Lost (Cumulative)` = paste0(round(min(p_reads_lost_abs*100),1), \"-\", round(max(p_reads_lost_abs*100),1), \" (mean \", round(mean(p_reads_lost_abs*100),1), \")\"),\n            `% Total Reads Lost (Marginal)` = paste0(round(min(p_reads_lost_abs_marginal*100),1), \"-\", round(max(p_reads_lost_abs_marginal*100),1), \" (mean \", round(mean(p_reads_lost_abs_marginal*100),1), \")\"), .groups=\"drop\") %>% \n  filter(Stage != \"raw_concat\") %>%\n  mutate(Stage = Stage %>% as.numeric %>% factor(labels=c(\"Trimming & filtering\", \"Deduplication\", \"Initial ribodepletion\", \"Secondary ribodepletion\")))\nn_reads_rel_display\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Stage\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"% Total Reads Lost (Cumulative)\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"% Total Reads Lost (Marginal)\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"Trimming & filtering\",\"2\":\"1.3-8.3 (mean 2.6)\",\"3\":\"1.3-8.3 (mean 2.6)\"},{\"1\":\"Deduplication\",\"2\":\"39.1-83.1 (mean 52)\",\"3\":\"35.8-80.9 (mean 49.3)\"},{\"1\":\"Initial ribodepletion\",\"2\":\"39.4-83.4 (mean 52.5)\",\"3\":\"0.1-1.7 (mean 0.5)\"},{\"1\":\"Secondary ribodepletion\",\"2\":\"39.4-83.5 (mean 52.6)\",\"3\":\"0-0.3 (mean 0.1)\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n## Quality control metrics\n\nCleaning seems to get rid of the library contamination and the polyg contamination. Polya contamination still is present, but I don't think we've found a solution to remove it as yet. Q score remain the same during read cleaning when looking at the positions, with the end of the read actually improving in score. Q scores across all sequences look pretty much the same throughout cleaning.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng_qual <- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters <- g_qual + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,20),\n                     breaks = seq(0,50,10), expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~adapter)\ng_adapters\n```\n\n::: {.cell-output-display}\n![](2024-09-19-aydillo_files/figure-html/plot-quality-1.svg)\n:::\n\n```{.r .cell-code}\n# Visualize quality\ng_quality_base <- g_qual +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~.)\ng_quality_base\n```\n\n::: {.cell-output-display}\n![](2024-09-19-aydillo_files/figure-html/plot-quality-2.svg)\n:::\n\n```{.r .cell-code}\ng_quality_seq <- g_qual +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0)) +\n  facet_grid(stage~., scales = \"free_y\")\ng_quality_seq\n```\n\n::: {.cell-output-display}\n![](2024-09-19-aydillo_files/figure-html/plot-quality-3.svg)\n:::\n:::\n\n\n\n\nThese plots below show the trends from above in each sample. Deduplication seems to drop by a lot post deduplication,which is a good thing given it was so high earlier. Mean read length remains relatively constant throuhgout. Ribsomal content remains low, which is good.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng_stage_trace <- ggplot(basic_stats, aes(x=stage, group=sample)) +\n  theme_kit\n\n# Plot reads over preprocessing\ng_reads_stages <- g_stage_trace +\n  geom_line(aes(y=n_read_pairs)) +\n  scale_y_continuous(\"# Read pairs\", expand=c(0,0), limits=c(0,NA))\ng_reads_stages\n```\n\n::: {.cell-output-display}\n![](2024-09-19-aydillo_files/figure-html/preproc-figures-1.svg)\n:::\n\n```{.r .cell-code}\n# Plot relative read losses during preprocessing\ng_reads_rel <- ggplot(n_reads_rel, \n                      aes(x=stage, group=sample)) +\n  geom_line(aes(y=p_reads_lost_abs_marginal)) +\n  scale_y_continuous(\"% Total Reads Lost\", expand=c(0,0), \n                     labels = function(x) x*100) +\n  theme_kit\ng_reads_rel\n```\n\n::: {.cell-output-display}\n![](2024-09-19-aydillo_files/figure-html/preproc-figures-2.svg)\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstage_dup <- basic_stats %>% group_by(stage) %>% \n  summarize(dmin = min(percent_duplicates), dmax=max(percent_duplicates),\n            dmean=mean(percent_duplicates), .groups = \"drop\")\n\ng_dup_stages <- g_stage_trace +\n  geom_line(aes(y=percent_duplicates)) +\n  scale_y_continuous(\"% Duplicates\", limits=c(0,NA), expand=c(0,0))\ng_dup_stages\n```\n\n::: {.cell-output-display}\n![](2024-09-19-aydillo_files/figure-html/preproc-dedup-1.svg)\n:::\n\n```{.r .cell-code}\ng_readlen_stages <- g_stage_trace + geom_line(aes(y=mean_seq_len)) +\n  scale_y_continuous(\"Mean read length (nt)\", expand=c(0,0), limits=c(0,NA))\ng_readlen_stages\n```\n\n::: {.cell-output-display}\n![](2024-09-19-aydillo_files/figure-html/preproc-dedup-2.svg)\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate reads lost during ribodepletion (approximation for % ribosomal reads)\nreads_ribo <- n_reads_rel %>% \n  filter(stage %in% c(\"dedup\", \"ribo_secondary\")) %>% \n  group_by(sample) %>% \n  summarize(p_reads_ribo=1-n_read_pairs[2]/n_read_pairs[1], .groups = \"drop\") %>%\n  inner_join(libraries, by = 'sample')\nreads_ribo_summ <- reads_ribo %>%\n  group_by(sample) %>%\n  summarize(min=min(p_reads_ribo), max=max(p_reads_ribo),\n            mean=mean(p_reads_ribo), .groups = \"drop\") %>%\n  inner_join(libraries, by = 'sample')\ng_reads_ribo <- ggplot(reads_ribo, \n                       aes(x=library, y=p_reads_ribo)) +\n  geom_point() + \n  scale_y_continuous(name=\"Approx % ribosomal reads\", limits=c(0,1),\n                     breaks=seq(0,1,0.2), expand=c(0,0), labels = function(y) y*100)+\n  theme_kit\ng_reads_ribo\n```\n\n::: {.cell-output-display}\n![](2024-09-19-aydillo_files/figure-html/ribo-frac-1.svg)\n:::\n:::\n\n\n\n\n# Taxonomic composition\n\n## High-level composition\n\nTo assess the high-level composition of the reads, I ran the ribodepleted files through Kraken2 and summarized the results with Bracken.\n\nThe groups listed below were created by Will:\n\n* Filtered (removed during cleaning)\n* Duplicate (removed during deduplication)\n* Ribosomal (removed during ribodepletion)\n* Unassigned (non-ribosomal reads that were not assigned to any taxon by Kraken/Bracken)\n* Bacterial (non-ribosomal reads assigned to the Bacteria domain by Kraken/Bracken)\n* Archaeal (non-ribosomal reads assigned to the Archaea domain by Kraken/Bracken)\n* Viral (non-ribosomal reads assigned to the Viruses domain by Kraken/Bracken)\n* Human (non-ribosomal reads assigned to the Eukarya domain by Kraken/Bracken)\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prepare plotting templates\ng_comp_base <- ggplot(mapping=aes(x=library, y=p_reads, fill=classification)) +\n  scale_x_discrete(name=\"Plasma pool\") +\n  theme_kit + \n  theme(plot.title = element_text(hjust=0, face=\"plain\", size=rel(1.5)))\nscale_y_pc_reads <- purrr::partial(scale_y_continuous, name = \"% Reads\",\n                                   expand = c(0,0), labels = function(y) y*100)\ngeom_comp <- purrr::partial(geom_col, position = \"stack\", width = 1)\n\n# Define a color palette for the classification\nclassification_colors <- brewer.pal(8, \"Accent\")\nnames(classification_colors) <- c(\"Filtered\", \"Duplicate\", \"Ribosomal\", \"Unassigned\", \"Bacterial\", \"Archaeal\", \"Viral\", \"Human\")\nscale_fill_classification <- function() {\n  scale_fill_manual(values = classification_colors, name = \"Classification\")\n}\n\n# Plot overall composition\ng_comp <- g_comp_base + geom_comp(data = comp) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (all reads, all groups)\")\ng_comp\n```\n\n::: {.cell-output-display}\n![](2024-09-19-aydillo_files/figure-html/plot-composition-all-1.svg)\n:::\n\n```{.r .cell-code}\ng_comp_assigned <- g_comp_base + \n  geom_comp(data = comp_assigned) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (assigned reads, all groups)\")\ng_comp_assigned\n```\n\n::: {.cell-output-display}\n![](2024-09-19-aydillo_files/figure-html/plot-composition-all-2.svg)\n:::\n:::\n\n\n\n\n## Total viral content\n\nTotal viral fraction average $1.30 \\times 10^{-6}$ across samples. As a fraction of assigned (rather than total) reads, this jumped to $2.82 \\times 10^{-6}$:\n\n\n\n\n\n\n\n\n\n## Taxonomic composition of viruses\n\nThe taxonomic profile seems to be relatively similar across samples. The threshold for the label \"other\" are the set of families that make up less than 5% composition in all samples.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmajor_threshold <- 0.3\n\n# Identify major viral families\nviral_families_major_tab <- viral_families %>% \n  group_by(name, taxid) %>%\n  summarize(p_reads_viral_max = max(p_reads_viral), .groups=\"drop\") %>%\n  filter(p_reads_viral_max >= major_threshold)\nviral_families_major_list <- viral_families_major_tab %>% pull(name)\nviral_families_major <- viral_families %>% \n  filter(name %in% viral_families_major_list) %>%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_minor <- viral_families_major %>% \n  group_by(sample) %>%\n  summarize(p_reads_viral_major = sum(p_reads_viral), .groups = \"drop\") %>%\n  mutate(name = \"Other\", taxid=NA, p_reads_viral = 1-p_reads_viral_major) %>%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_display <- viral_families_major %>% \n  bind_rows(viral_families_minor) %>%\n  arrange(desc(p_reads_viral)) %>% \n  mutate(name = factor(name, levels=c(viral_families_major_list, \"Other\"))) %>%\n  rename(p_reads = p_reads_viral, classification=name) %>%\n  inner_join(libraries, by='sample')\n\n\npal <- c(brewer.pal(8, 'Dark2'),brewer.pal(8, 'Accent'), brewer.pal(8, 'Set1'), brewer.pal(8, 'Pastel1'), brewer.pal(8, 'Pastel2'))\n\nn_classifications <- length(unique(viral_families_display$classification)) - 1\n\ncustom_palette_with_black <- c(\n  pal[1:n_classifications],\n  \"black\"\n)\n\n# Plot\ng_families <- g_comp_base + \n  geom_comp(data=viral_families_display) +\n  scale_y_continuous(name=\"% Viral Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_manual(values = custom_palette_with_black)\ng_families\n```\n\n::: {.cell-output-display}\n![](2024-09-19-aydillo_files/figure-html/viral-family-composition-1.svg)\n:::\n:::\n\n\n\n\n# Human-infecting virus reads\n\n## Overall relative abundance\n\nI calculated the relative abundance of human-infecting viruses in two ways:\n\n-   First, as the total number of deduplicated human-virus reads in each sample, divided by the number of raw reads (\"All reads\"). This results in a viral fraction of $3.58 \\times 10^{-7}$ across all samples\n\n-   Second, as a fraction of preprocessed (cleaned, deduplicated, computationally ribodepleted) reads (\"Preprocessed reads\"). This results in a viral fraction of $6.81 \\times 10^{-7}$ across all samples.\n\n\n\n\n\n\n\n\n\n\n\n## Overall taxonomy and composition\n\nComposition of HV reads was changed from when looking at all viral reads. First, we see that ~10% of individuals had human infecting viral reads, which is higher than what we saw in our O'Connell et al. 2023 analysis (~1% of samples had human-infecting viruses). Second, we see that the two dominant families we see is Flaviviridae and Orthoherpesviridae. The threshold for the label \"other\" are the set of families that make up less than 5% composition in all samples.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthreshold_major_family <- 0.05\n\n# Count reads for each human-viral family\nhv_family_counts <- hv_reads_family %>% \n  group_by(sample, name, taxid) %>%\n  count(name = \"n_reads_hv\") %>%\n  group_by(sample) %>%\n  mutate(p_reads_hv = n_reads_hv/sum(n_reads_hv))\n\n# Identify high-ranking families and group others\nhv_family_major_tab <- hv_family_counts %>% group_by(name) %>% \n  filter(p_reads_hv == max(p_reads_hv)) %>% filter(row_number() == 1) %>%\n  arrange(desc(p_reads_hv)) %>% filter(p_reads_hv > threshold_major_family)\nhv_family_counts_major <- hv_family_counts %>%\n  mutate(name_display = ifelse(name %in% hv_family_major_tab$name, name, \"Other\")) %>%\n  group_by(sample, name_display) %>%\n  summarize(n_reads_hv = sum(n_reads_hv), p_reads_hv = sum(p_reads_hv), \n            .groups=\"drop\") %>%\n  mutate(name_display = factor(name_display, \n                               levels = c(hv_family_major_tab$name, \"Other\")))\nhv_family_counts_display <- hv_family_counts_major %>%\n  rename(p_reads = p_reads_hv, classification = name_display) %>%\n  inner_join(libraries, by = 'sample')\n\n# Plot\ng_hv_family <- g_comp_base + \n  geom_col(data=hv_family_counts_display, position = \"stack\", width=1) +\n  scale_y_continuous(name=\"% HV Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_brewer(palette = 'Accent', name = \"Viral family\") +\n  labs(title=\"Family composition of human-viral reads\") +\n  guides(fill=guide_legend(ncol=4)) +\n  theme(plot.title = element_text(size=rel(1.4), hjust=0, face=\"plain\"))\ng_hv_family\n```\n\n::: {.cell-output-display}\n![](2024-09-19-aydillo_files/figure-html/hv-family-1.svg)\n:::\n\n```{.r .cell-code}\n# Get most prominent families for text\nhv_family_collate <- hv_family_counts %>%\n  group_by(name, taxid) %>% \n  summarize(n_reads_tot = sum(n_reads_hv),\n            p_reads_max = max(p_reads_hv), .groups=\"drop\") %>% \n  arrange(desc(n_reads_tot))\nhv_family_collate\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"name\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"taxid\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n_reads_tot\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"p_reads_max\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Flaviviridae\",\"2\":\"11050\",\"3\":\"594\",\"4\":\"1.0000000\"},{\"1\":\"Orthoherpesviridae\",\"2\":\"3044472\",\"3\":\"1\",\"4\":\"0.1428571\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n## Analyzing specific families\n\nWe now investigate the composition of specific families that had more than 5 viral reads. In investigating individual viral families, to avoid distortions from a few rare reads, I restricted myself to samples where that family made up at least 1% of human-viral reads:\n\n\n\n\n\n\n\n\n\n### Flaviviridae (Number of reads: 594)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Flaviviridae\nplot_viral_family_histogram(taxid_chosen=11050)\n```\n\n::: {.cell-output-display}\n![](2024-09-19-aydillo_files/figure-html/plot-flaviviridae-histogram-1.svg)\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Flaviviridae\nplot_viral_family_composition(taxid_chosen=11050, threshold_major_species = 0.01)\n```\n\n::: {.cell-output-display}\n![](2024-09-19-aydillo_files/figure-html/plot-flaviviridae-composition-1.svg)\n:::\n:::\n\n\n\n\n## Relative abundance of pathogenic viruses of interest\n\n\n\n\n\n\n\n\n\n\n\nEach dot represents a sample, colored by viral family. The x-axis shows the relative abundance of human-infecting viruses, and the y-axis shows the species.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspecies_family <- result %>% select(species, family) %>% rename('name' = 'species')\n\nplay <- hv_species_counts %>% \n  ungroup() %>%\n  inner_join(libraries, by = 'sample') %>%\n  inner_join(species_family, by = 'name') %>%\n  mutate(name = ifelse(name == \"Severe acute respiratory syndrome-related coronavirus\", \"SARS-related coronavirus\", name))\n\nadjusted_play <- play %>% \n  group_by(name) %>%\n  mutate(virus_prevalence_num = n_distinct(sample)/n_distinct(libraries),\n         total_reads_hv = sum(n_reads_hv)) %>%\n  ungroup() %>%\n  mutate(name = fct_reorder(name, virus_prevalence_num, .desc=TRUE)) %>% \n  select(name, ra_reads_hv, family, virus_prevalence_num, total_reads_hv, n_reads_hv)\n\npal <- c(brewer.pal(8, 'Dark2'),brewer.pal(8, 'Accent'))\n\n#, labels = label_log(digits=2)\n\nra_dot <- ggplot(adjusted_play, aes(x = ra_reads_hv, y=name)) +\n  geom_quasirandom(orientation = 'y', aes(color = family)) +\n  scale_color_manual(values = pal) + \n    scale_x_log10(\n    \"Relative abundance human virus reads\",\n    labels=label_log(digits=3)\n  ) +\n  labs(y =  \"\",\n       color = 'Viral family') + \n  guides(color = guide_legend(ncol=2)) +\n  theme_light() + \n    theme(\n    axis.text.y = element_text(size = 10),\n    axis.text.x = element_text(size = 12),\n    axis.ticks.y = element_blank(),axis.line = element_line(colour = \"black\"),\n    axis.title.x = element_text(size = 14),    \n    legend.text = element_text(size = 10),\n    legend.title = element_text(size = 10, face=\"bold\"),\n    #legend.position = 'bottom',\n    legend.position = c(1, 1),  # Move legend to top right\n    legend.justification = c(1, 1),  # Align legend to top right\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank())\nra_dot\n```\n\n::: {.cell-output-display}\n![](2024-09-19-aydillo_files/figure-html/plot-pathogenic-viruses-1.svg)\n:::\n:::\n\n\n\n\nI can then take all of the viruses that we found and look up what they're responsible for and whether they're dangerous.\n\n| Virus Name | Common Name | Pathogenic Potential |\n|------------|-------------|----------------------|\n| Cytomegalovirus humanbeta5 | Human Cytomegalovirus | Moderate to high, can cause severe disease in immunocompromised individuals and congenital infections |\n| Pegivirus hominis | Human Pegivirus | Very low, not known to cause disease in humans |\n\nWe see human pegivirus which is well documented to be in human blood, and we get CMV which is another virus of interest.\n\n## Relative abundance assuming perfect human read removal\n\n\n\n\n\n\n\n\nAssuming we're able to perfectly remove all human reads, the average relative abundance of known human infecting virus is $6.52 \\times 10^{-6}$.\n\n# Conclusion\n\nThere were some takeways from this analysis:\n1. It seems that human infecting viruses found in whole blood tend to be more diverse than viruses found in plasma.\n2. We're able to detect latent viruses such as the herpesviruses (CMV) pretty consistently through whole blood studies, although the relative abundance remains low.\n\n# Appendix\n\n## Human-infecting virus families, genera, and species\n\nTo get a good overview of families, genera, and species, we can look at a Sankey plot where the magnitude of relative abundance, averaged over all samples, is shown in parentheses.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to create links\ncreate_links <- function(data) {\n  family_to_genus <- data %>%\n    filter(!is.na(genus)) %>%\n    group_by(family, genus) %>%\n    summarise(value = n(), .groups = \"drop\") %>%\n    mutate(source = family, target = genus)\n  \n  genus_to_species <- data %>%\n    group_by(genus, species) %>%\n    summarise(value = n(), .groups = \"drop\") %>%\n    mutate(source = genus, target = species)\n\n  family_to_species <- data %>%\n    filter(is.na(genus)) %>%\n    group_by(family, species) %>%\n    summarise(value = n(), .groups = \"drop\") %>%\n    mutate(source = family, target = species)\n\n  bind_rows(family_to_genus, genus_to_species, family_to_species) %>%\n    filter(!is.na(source))\n}\n\n# Function to create nodes\ncreate_nodes <- function(links) {\n  data.frame(\n    name = c(links$source, links$target) %>% unique()\n  )\n}\n\n# Function to prepare data for Sankey diagram\nprepare_sankey_data <- function(links, nodes) {\n  links$IDsource <- match(links$source, nodes$name) - 1\n  links$IDtarget <- match(links$target, nodes$name) - 1\n  list(links = links, nodes = nodes)\n}\n\n# Function to create Sankey plot\ncreate_sankey_plot <- function(sankey_data) {\n  sankeyNetwork(\n    Links = sankey_data$links, \n    Nodes = sankey_data$nodes,\n    Source = \"IDsource\", \n    Target = \"IDtarget\",\n    Value = \"value\", \n    NodeID = \"name\",\n    sinksRight = TRUE,\n    nodeWidth = 25,\n    fontSize = 14,\n  )\n}\n\nsave_sankey_as_png <- function(sankey_plot, width = 1000, height = 800) {\n  # Save the plot as an HTML file\n  saveWidget(sankey_plot, sprintf('%s/sankey.html',data_dir))\n}\n\nformat_scientific <- function(x, digits=2) {\n  sapply(x, function(val) {\n    if (is.na(val) || abs(val) < 1e-15) {\n      return(\"0\")\n    } else {\n      exponent <- floor(log10(abs(val)))\n      coef <- val / 10^exponent\n      #return(sprintf(\"%.1f × 10^%d\", round(coef, digits), exponent))\n      # May or may not be smart, just keeping magnitude\n      return(sprintf(\"10^%d\", exponent))\n    }\n  })\n}\n\ndata <- result %>% \n  mutate(across(c(genus_n_reads_tot, genus_ra_reads_tot), ~replace_na(., 0)),\n         genus = ifelse(is.na(genus), \"Unknown Genus\", genus)) %>%\n  mutate(\n  species = paste0(species, sprintf(' (%s)', format_scientific(species_ra_reads_tot))),\n  genus = paste0(genus, sprintf(' (%s)', format_scientific(genus_ra_reads_tot))),\n  family = paste0(family, sprintf(' (%s)', format_scientific(family_ra_reads_tot)))\n)\nlinks <- as.data.frame(create_links(data))\nnodes <- create_nodes(links)\nsankey_data <- prepare_sankey_data(links, nodes)\nsankey <- create_sankey_plot(sankey_data)\n\nsankey\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"sankeyNetwork html-widget html-fill-item\" id=\"htmlwidget-9cdfda17962c937e2d78\" style=\"width:100%;height:1462px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-9cdfda17962c937e2d78\">{\"x\":{\"links\":{\"source\":[0,1,2,3],\"target\":[3,2,4,5],\"value\":[1,1,1,1]},\"nodes\":{\"name\":[\"Flaviviridae (10^-6)\",\"Orthoherpesviridae (10^-8)\",\"Cytomegalovirus (10^-8)\",\"Pegivirus (10^-6)\",\"Cytomegalovirus humanbeta5 (10^-8)\",\"Pegivirus hominis (10^-6)\"],\"group\":[\"Flaviviridae (10^-6)\",\"Orthoherpesviridae (10^-8)\",\"Cytomegalovirus (10^-8)\",\"Pegivirus (10^-6)\",\"Cytomegalovirus humanbeta5 (10^-8)\",\"Pegivirus hominis (10^-6)\"]},\"options\":{\"NodeID\":\"name\",\"NodeGroup\":\"name\",\"LinkGroup\":null,\"colourScale\":\"d3.scaleOrdinal(d3.schemeCategory20);\",\"fontSize\":14,\"fontFamily\":null,\"nodeWidth\":25,\"nodePadding\":10,\"units\":\"\",\"margin\":{\"top\":null,\"right\":null,\"bottom\":null,\"left\":null},\"iterations\":32,\"sinksRight\":true}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<script src=\"../site_libs/d3-4.5.0/d3.min.js\"></script>\n<script src=\"../site_libs/sankey-1/sankey.js\"></script>\n<script src=\"../site_libs/sankeyNetwork-binding-0.4/sankeyNetwork.js\"></script>\n<link href=\"../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}