{
  "hash": "c421c66c41e4b4780aecc609eca8f525",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Workflow of Blauwkamp et al. (2019)\"\nsubtitle: \"Individual plasma from USA\"\nauthor: \"Harmon Bhasin\"\ndate: 2024-07-09\nformat:\n  html:\n    code-fold: true\n    code-tools: true\n    code-link: true\n    df-print: paged\nexecute: \n  freeze: auto\neditor: visual\ntitle-block-banner: \"#de2d26\" \n---\n\n\n\n\n\n\nTHIS IS CURRENTLY A WORK IN PROGRESS!\n\nThis is the second study of [this series](https://data.securebio.org/harmons-public-notebook/notebooks/2024-07-08_cebria-mendoza.html). In this post, I analyze [Blauwkamp 2019](https://doi.org/10.1038/s41564-018-0349-6), a dataset with \\~170 samples, one for each individual of cell-free DNA in plasma in the United States.\n\n# The raw data\n\nThe samples utilized in the determination of the reference range were collected from 167 healthy asymptomatic donors in five geographically diverse areas of the United States who were 18 to 65 years of age and had been screened for common health conditions including infectious diseases through a questionnaire and standard blood donor screening assays (Serologix and StemExpress). We only have DNA sequencing for this data.\n\nIn total, these 170 samples contained 115M read pairs. The samples had 8 - 2M (mean .7M) read pairs each.\n\nCOME BACK ADAPTER STATISTICS WERE NOT COMPUTED, slightly fucked up the multiqc, but we can solve it here. This probably explains why adapter statsistics were not computed.\n\n\n\n\n\n\n\n\n\nYou may have noticed that the dataset has 170 samples, however they only report 167 samples in the paper. This is because three of the samples have very few reads, for this reason, we omit those, when we do that we get the following statistics. We then go from 170 samples to 167 samples containing approximately for both 115M read pairs. The samples went from 8 - 2M (mean .7M) read pairs each to .1M-2M (mean .7M).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nremove_samples <- pre_basic_stats %>% filter(n_read_pairs < 100) %>% select(sample) %>% distinct() %>% pull()\n\n# Filter libraries\nlibraries <- libraries %>%\n  filter(!(sample %in% remove_samples)) \n\n# Import QC data\nbasic_stats <- pre_basic_stats %>%\n  filter(!(sample %in% remove_samples))\n\nquality_base_stats <- pre_quality_base_stats %>%\n  filter(!(sample %in% remove_samples))\n  \nquality_seq_stats <- pre_quality_seq_stats %>%\n  filter(!(sample %in% remove_samples))\n  \n # Filter to raw data\n basic_stats_raw <- basic_stats %>% filter(stage == \"raw_concat\")\n quality_base_stats_raw <- quality_base_stats %>% filter(stage == \"raw_concat\")\n quality_seq_stats_raw <- quality_seq_stats %>% filter(stage == \"raw_concat\")\n \n# Get key values for readout\nraw_read_counts <- basic_stats_raw %>% \n   summarize(rmin = min(n_read_pairs), rmax=max(n_read_pairs),\n             rmean=mean(n_read_pairs), \n             rtot = sum(n_read_pairs),\n             btot = sum(n_bases_approx),\n             dmin = min(percent_duplicates), dmax=max(percent_duplicates),\n             dmean=mean(percent_duplicates), .groups = \"drop\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prepare data\nbasic_stats_raw_metrics <- basic_stats_raw %>%\n  select(library,\n         `# Reads` = n_read_pairs,\n         `Total base pairs\\n(approx)` = n_bases_approx,\n         `% Duplicates\\n(FASTQC)` = percent_duplicates) %>%\n  pivot_longer(-library, names_to = \"metric\", values_to = \"value\") %>%\n  mutate(metric = fct_inorder(metric))\n\ng_basic <- ggplot(basic_stats_raw_metrics, aes(x=library, y=value)) +\n  geom_col(position = \"dodge\") +\n  scale_x_discrete() +\n  scale_y_continuous(expand=c(0,0)) +\n  expand_limits(y=c(0,100)) +\n  facet_grid(metric~., scales = \"free\", space=\"free_x\", switch=\"y\") +\n  theme_kit + theme(\n    axis.title.y = element_blank(),\n    strip.text.y = element_text(face=\"plain\")\n  )\ng_basic\n```\n\n::: {.cell-output-display}\n![](2024-07-09_blauwkamp_files/figure-html/plot-basic-stats-1.png){width=2400}\n:::\n:::\n\n\n\n\nTODO interpret the below plot.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set up plotting templates\ng_qual_raw <- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read\") +\n  theme_base\n\n# Visualize quality\ng_quality_base_raw <- g_qual_raw +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats_raw) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0))\ng_quality_base_raw\n```\n\n::: {.cell-output-display}\n![](2024-07-09_blauwkamp_files/figure-html/plot-raw-quality-1.png){width=768}\n:::\n\n```{.r .cell-code}\ng_quality_seq_raw <- g_qual_raw +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats_raw) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0))\ng_quality_seq_raw\n```\n\n::: {.cell-output-display}\n![](2024-07-09_blauwkamp_files/figure-html/plot-raw-quality-2.png){width=768}\n:::\n:::\n\n\n\n\n# Preprocessing\n\n## High-level metrics\n\nThe average fraction of reads at each stage in the preprocessing pipeline is shown in the following table. Given that human reads were removed before hand, we'd expect our trimming and filtering to make minimal change, and that's what we see. However, the researchers did not deduplicate and we can see that that removes a large portion of our reads, about 25% on average. Ribdepletion doesn't remove any reads, I'm not sure how to feel about this.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Count read losses\nn_reads_rel <- basic_stats %>% \n  select(sample, stage, percent_duplicates, n_read_pairs) %>%\n  group_by(sample) %>% \n  arrange(sample, stage) %>%\n  mutate(p_reads_retained = n_read_pairs / lag(n_read_pairs),\n         p_reads_lost = 1 - p_reads_retained,\n         p_reads_retained_abs = n_read_pairs / n_read_pairs[1],\n         p_reads_lost_abs = 1-p_reads_retained_abs,\n         p_reads_lost_abs_marginal = p_reads_lost_abs - lag(p_reads_lost_abs))\nn_reads_rel_display <- n_reads_rel %>% \n  rename(Stage=stage) %>% \n  group_by(Stage) %>% \n  summarize(`% Total Reads Lost (Cumulative)` = paste0(round(min(p_reads_lost_abs*100),1), \"-\", round(max(p_reads_lost_abs*100),1), \" (mean \", round(mean(p_reads_lost_abs*100),1), \")\"),\n            `% Total Reads Lost (Marginal)` = paste0(round(min(p_reads_lost_abs_marginal*100),1), \"-\", round(max(p_reads_lost_abs_marginal*100),1), \" (mean \", round(mean(p_reads_lost_abs_marginal*100),1), \")\"), .groups=\"drop\") %>% \n  filter(Stage != \"raw_concat\") %>%\n  mutate(Stage = Stage %>% as.numeric %>% factor(labels=c(\"Trimming & filtering\", \"Deduplication\", \"Initial ribodepletion\", \"Secondary ribodepletion\")))\nn_reads_rel_display\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Stage\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"% Total Reads Lost (Cumulative)\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"% Total Reads Lost (Marginal)\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"Trimming & filtering\",\"2\":\"0-0 (mean 0)\",\"3\":\"0-0 (mean 0)\"},{\"1\":\"Deduplication\",\"2\":\"8.1-42.4 (mean 24.3)\",\"3\":\"8.1-42.4 (mean 24.2)\"},{\"1\":\"Initial ribodepletion\",\"2\":\"8.1-42.4 (mean 24.3)\",\"3\":\"0-0 (mean 0)\"},{\"1\":\"Secondary ribodepletion\",\"2\":\"8.1-42.4 (mean 24.3)\",\"3\":\"0-0 (mean 0)\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ng_stage_trace <- ggplot(basic_stats, aes(x=stage, group=sample)) +\n  theme_kit\n\n# Plot reads over preprocessing\ng_reads_stages <- g_stage_trace +\n  geom_line(aes(y=n_read_pairs)) +\n  scale_y_continuous(\"# Reads\", expand=c(0,0), limits=c(0,NA))\ng_reads_stages\n```\n\n::: {.cell-output-display}\n![](2024-07-09_blauwkamp_files/figure-html/preproc-figures-1.png){width=576}\n:::\n\n```{.r .cell-code}\n# Plot relative read losses during preprocessing\ng_reads_rel <- ggplot(n_reads_rel, \n                      aes(x=stage, group=sample)) +\n  geom_line(aes(y=p_reads_lost_abs_marginal)) +\n  scale_y_continuous(\"% Total Reads Lost\", expand=c(0,0), \n                     labels = function(x) x*100) +\n  theme_kit\ng_reads_rel\n```\n\n::: {.cell-output-display}\n![](2024-07-09_blauwkamp_files/figure-html/preproc-figures-2.png){width=576}\n:::\n:::\n\n\n\n\nTODO interpret the below plot.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng_qual <- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read\") +\n  theme_base\n\n# Visualize quality\ng_quality_base <- g_qual +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~.)\ng_quality_base\n```\n\n::: {.cell-output-display}\n![](2024-07-09_blauwkamp_files/figure-html/plot-quality-1.png){width=672}\n:::\n\n```{.r .cell-code}\ng_quality_seq <- g_qual +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0)) +\n  facet_grid(stage~., scales = \"free_y\")\ng_quality_seq\n```\n\n::: {.cell-output-display}\n![](2024-07-09_blauwkamp_files/figure-html/plot-quality-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstage_dup <- basic_stats %>% group_by(stage) %>% \n  summarize(dmin = min(percent_duplicates), dmax=max(percent_duplicates),\n            dmean=mean(percent_duplicates), .groups = \"drop\")\n\ng_dup_stages <- g_stage_trace +\n  geom_line(aes(y=percent_duplicates)) +\n  scale_y_continuous(\"% Duplicates\", limits=c(0,NA), expand=c(0,0))\ng_dup_stages\n```\n\n::: {.cell-output-display}\n![](2024-07-09_blauwkamp_files/figure-html/preproc-dedup-1.png){width=576}\n:::\n\n```{.r .cell-code}\ng_readlen_stages <- g_stage_trace + geom_line(aes(y=mean_seq_len)) +\n  scale_y_continuous(\"Mean read length (nt)\", expand=c(0,0), limits=c(0,NA))\ng_readlen_stages\n```\n\n::: {.cell-output-display}\n![](2024-07-09_blauwkamp_files/figure-html/preproc-dedup-2.png){width=576}\n:::\n:::\n\n\n\n\n# Taxonomic composition\n\n## High-level composition\n\nTo assess the high-level composition of the reads, I ran the ribodepleted files through Kraken2 and summarized the results with Bracken.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prepare plotting templates\ng_comp_base <- ggplot(mapping=aes(x=library, y=p_reads, fill=classification)) +\n  scale_x_discrete(name=\"Plasma pool\") +\n  theme_kit + \n  theme(plot.title = element_text(hjust=0, face=\"plain\", size=rel(1.5)))\nscale_y_pc_reads <- purrr::partial(scale_y_continuous, name = \"% of reads\",\n                                   expand = c(0,0), labels = function(y) y*100)\ngeom_comp <- purrr::partial(geom_col, position = \"stack\", width = 1)\n\n# Plot overall composition\ng_comp <- g_comp_base + geom_comp(data = comp) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_brewer(palette = \"Set1\", name = \"Classification\") +\n  ggtitle(\"Read composition (all reads, all groups)\")\ng_comp\n```\n\n::: {.cell-output-display}\n![](2024-07-09_blauwkamp_files/figure-html/plot-composition-all-1.png){width=2400}\n:::\n\n```{.r .cell-code}\n# Repeat for classified reads only\npalette_assigned <- brewer.pal(9, \"Set1\")[5:9]\ng_comp_assigned <- g_comp_base + \n  geom_comp(data = comp_assigned) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_manual(values=palette_assigned, name = \"Classification\") +\n  ggtitle(\"Read composition (assigned reads, all groups)\")\ng_comp_assigned\n```\n\n::: {.cell-output-display}\n![](2024-07-09_blauwkamp_files/figure-html/plot-composition-all-2.png){width=2400}\n:::\n\n```{.r .cell-code}\n# Plot composition of minor components\npalette_minor <- brewer.pal(9, \"Set1\")[6:9]\ng_comp_minor <- g_comp_base + \n  geom_comp(data=comp_minor) +\n  scale_y_pc_reads() +\n  scale_fill_manual(values=palette_minor, name = \"Classification\") +\n  ggtitle(\"Read composition (all reads, minor groups)\")\ng_comp_minor\n```\n\n::: {.cell-output-display}\n![](2024-07-09_blauwkamp_files/figure-html/plot-composition-all-3.png){width=2400}\n:::\n\n```{.r .cell-code}\ng_comp_assigned_minor <- g_comp_base + \n  geom_comp(data=comp_assigned_minor) +\n  scale_y_pc_reads() +\n  scale_fill_manual(values=palette_minor, name = \"Classification\") +\n  ggtitle(\"Read composition (assigned reads, minor groups)\")\ng_comp_assigned_minor\n```\n\n::: {.cell-output-display}\n![](2024-07-09_blauwkamp_files/figure-html/plot-composition-all-4.png){width=2400}\n:::\n:::\n\n\n\n\nTODO analyze this above\n\n## Total viral content\n\nTotal viral fraction average $6.13 \\times 10^{-6}$ across samples. As a fraction of assigned (rather than total) reads, this jumped to $1.88 \\times 10^{-3}$:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_reads_viral_all <- comp %>% filter(classification == \"Viral\") %>%\n  mutate(read_group = \"All reads\")\np_reads_viral_assigned <- comp_assigned %>% filter(classification == \"Viral\") %>%\n  mutate(read_group = \"Classified reads\")\np_reads_viral <- bind_rows(p_reads_viral_all, p_reads_viral_assigned)\n\n# Plot\ng_viral <- ggplot(p_reads_viral, aes(x=library, y=p_reads)) +\n  geom_point() +\n  scale_x_discrete(name=\"Plasma pool\") +\n  scale_y_log10(name=\"Viral read fraction\") +\n  facet_grid(.~read_group, scales = \"free\") +\n  guides(color=guide_legend(nrow=2), shape=guide_legend(nrow=2),\n         linetype=guide_legend(nrow=2)) +\n  theme_kit\ng_viral\n```\n\n::: {.cell-output-display}\n![](2024-07-09_blauwkamp_files/figure-html/p-viral-1.png){width=2400}\n:::\n:::\n\n\n\n\n## Taxonomic composition of viruses\n\nWhen we drop down to the taxonomic composition of viral families, we go from 167 samples to 119 samples.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get viral taxonomy\nviral_taxa_path <- file.path(data_dir, \"total-virus-db.tsv.gz\")\nviral_taxa <- read_tsv(viral_taxa_path, show_col_types = FALSE)\n\n# Get Kraken reports\nreports_path <- file.path(tax_final_dir, \"kraken_reports.tsv.gz\")\nreports <- read_tsv(reports_path, show_col_types = FALSE) %>%\n  inner_join(libraries, by=\"sample\") %>% arrange(sample)\n\n# Filter to viral taxa\nkraken_reports_viral <- filter(reports, taxid %in% viral_taxa$taxid) %>%\n  group_by(sample) %>%\n  mutate(p_reads_viral = n_reads_clade/n_reads_clade[1])\nkraken_reports_viral_cleaned <- kraken_reports_viral %>%\n  select(-pc_reads_total, -n_reads_direct, -contains(\"minimizers\")) %>%\n  select(name, taxid, p_reads_viral, n_reads_clade, everything()) %>% ungroup\n\nviral_classes <- kraken_reports_viral_cleaned %>% filter(rank == \"C\")\nviral_families <- kraken_reports_viral_cleaned %>% filter(rank == \"F\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmajor_threshold <- 0.01\n\n# Identify major viral families\nviral_families_major_tab <- viral_families %>% \n  group_by(name, taxid) %>%\n  summarize(p_reads_viral_max = max(p_reads_viral), .groups=\"drop\") %>%\n  filter(p_reads_viral_max >= major_threshold)\nviral_families_major_list <- viral_families_major_tab %>% pull(name)\nviral_families_major <- viral_families %>% \n  filter(name %in% viral_families_major_list) %>%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_minor <- viral_families_major %>% \n  group_by(sample) %>%\n  summarize(p_reads_viral_major = sum(p_reads_viral), .groups = \"drop\") %>%\n  mutate(name = \"Other\", taxid=NA, p_reads_viral = 1-p_reads_viral_major) %>%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_display <- viral_families_major %>% \n  bind_rows(viral_families_minor) %>%\n  arrange(desc(p_reads_viral)) %>% \n  mutate(name = factor(name, levels=c(viral_families_major_list, \"Other\"))) %>%\n  rename(p_reads = p_reads_viral, classification=name) %>%\n  inner_join(libraries, by='sample')\n\n# Plot\npalette_viral <- c(brewer.pal(12, \"Set3\"), brewer.pal(8, \"Dark2\"))\ng_families <- g_comp_base + \n  geom_comp(data=viral_families_display) +\n  scale_y_continuous(name=\"% Viral Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_manual(values=palette_viral, name = \"Viral class\")\ng_families\n```\n\n::: {.cell-output-display}\n![](2024-07-09_blauwkamp_files/figure-html/viral-family-composition-1.png){width=2400}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get viral taxonomy\nviral_taxa_path <- file.path(data_dir, \"total-virus-db.tsv.gz\")\nviral_taxa <- read_tsv(viral_taxa_path, show_col_types = FALSE)\n\n# Get Kraken reports\nreports_path <- file.path(tax_final_dir, \"kraken_reports.tsv.gz\")\nreports <- read_tsv(reports_path, show_col_types = FALSE) %>%\n  inner_join(libraries, by=\"sample\") %>% arrange(sample) %>% drop_na() \n\n# Filter to viral taxa\nkraken_reports_viral <- filter(reports, taxid %in% viral_taxa$taxid) %>%\n  group_by(sample) %>%\n  mutate(p_reads_viral = n_reads_clade/n_reads_clade[1])\nkraken_reports_viral_cleaned <- kraken_reports_viral %>%\n  select(-pc_reads_total, -n_reads_direct, -contains(\"minimizers\")) %>%\n  select(name, taxid, p_reads_viral, n_reads_clade, everything()) %>% \n  rename(old_rank=rank) %>% ungroup\n\nmajor_threshold <- 0.01\n\n# Identify major viral families\nall_virus_name <- kraken_reports_viral_cleaned %>% \n  group_by(name, taxid) %>%\n  summarize(p_reads_viral_max = max(p_reads_viral), .groups=\"drop\") %>%\n  filter(p_reads_viral_max >= major_threshold) %>%\n  pull(name)\n\nkraken_reports_viral_cleaned <- kraken_reports_viral_cleaned %>% \n  filter(name %in% all_virus_name) %>%\n  select(name, taxid, sample, p_reads_viral, n_reads_clade)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#ranks_of_interest <- rev(c(\"species\", \"subgenus\", \"genus\", \"subfamily\", \"family\"))\nranks_of_interest <- c(\"family\", \"genus\")\n\n# Filter the ranks we're interested in\nfiltered_taxa <- viral_taxa %>%\n  filter(rank %in% ranks_of_interest)\n\n# Join the datasets and create the links dataframe\nlinks <- kraken_reports_viral_cleaned %>%\n  inner_join(filtered_taxa, by = c(\"taxid\", \"name\")) %>%\n  inner_join(filtered_taxa, by = c(\"parent_taxid\" = \"taxid\"), suffix = c(\"\", \"_parent\")) %>%\n  #filter(rank != rank_parent) %>%  # Ensure source and target are not in the same rank\n  select(source = name_parent, target = name, value = p_reads_viral)\n\n# Create nodes dataframe from unique names in links\nnodes <- data.frame(\n  name = c(links$source, links$target) %>% unique()\n) %>%\n  mutate(node = row_number() - 1)  # zero-indexed for networkD3\n\n# Join rank information to nodes\nnodes <- nodes %>%\n  left_join(filtered_taxa, by = c(\"name\")) %>%\n  select(name, node, rank)\n\n# Add IDs to links dataframe\nlinks <- links %>%\n  left_join(nodes, by = c(\"source\" = \"name\")) %>%\n  rename(IDsource = node) %>%\n  left_join(nodes, by = c(\"target\" = \"name\")) %>%\n  rename(IDtarget = node)\n\n# Aggregate link values\nlinks_aggregated <- links %>%\n  group_by(IDsource, IDtarget, source, target) %>%\n  summarise(value = sum(value), .groups = \"drop\")\n\n# Get rid of some warnings\nlinks_aggregated <- as.data.frame(links_aggregated)\nnodes <- as.data.frame(nodes)\n\n# Create Sankey diagram\nsankey_diagram <- sankeyNetwork(Links = links_aggregated, \n                                Nodes = nodes,\n                                Source = \"IDsource\", \n                                Target = \"IDtarget\",\n                                Value = \"value\", \n                                NodeID = \"name\",\n                                fontSize = 12,\n                                NodeGroup = \"rank\",\n                                nodeWidth = 30,\n                                height = 800,\n                                width = 1000,\n                                sinksRight = FALSE)\n\n# Display the diagram\n#sankey_diagram\n```\n:::\n\n\n\n\n## Number of reads for viruses of interest\n\n\n\n\n\n\n\n\n\nWe're particulary interested in the following viruses:\n\n1.  Hepatitis B\n    -   Family: Hepadnaviridae\n    -   Genus: Orthohepadnavirus\n    -   Species: Hepatitis B virus\n2.  Hepatitis C\n    -   Family: Flaviviridae\n    -   Genus: Hepacivirus\n    -   Species: Hepatitis C virus\n3.  EBV (Epstein-Barr virus)\n    -   Family: Herpesviridae\n    -   Genus: Lymphocryptovirus\n    -   Species: Human gammaherpesvirus 4\n4.  CMV (Cytomegalovirus)\n    -   Family: Herpesviridae\n    -   Genus: Cytomegalovirus\n    -   Species: Human betaherpesvirus 5\n5.  HIV-1 (Human Immunodeficiency Virus type 1)\n    -   Family: Retroviridae\n    -   Genus: Lentivirus\n    -   Species: Human immunodeficiency virus 1\n6.  Anelloviridae\n    -   Family: Anelloviridae\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#reads_post_process <- basic_stats %>% filter(stage == 'ribo_secondary') %>% \n  #select(sample, n_read_pairs)\n\nviral_families_interest <- viral_families %>% filter(name == \"Hepadnaviridae\" | \n    name ==  \"Flaviviridae\" | \n    name ==  \"Orthoherpesviridae\" |\n    name ==  \"Herpesviridae\" |\n    name ==  \"Retroviridae\" |\n    name == \"Anelloviridae\") %>% group_by(name) %>% summarize(sum=sum(n_reads_clade))\n\nviral_families_interest\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"name\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"sum\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Anelloviridae\",\"2\":\"14\"},{\"1\":\"Orthoherpesviridae\",\"2\":\"439\"},{\"1\":\"Retroviridae\",\"2\":\"2\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Species\n# Hepatitis B virus <- 10407\n# Hepatitis C virus <- 10407\n# HIV - 1 <- 11676\n\nviral_families_interest <- viral_genus %>% filter( name == \"Orthohepadnavirus\" | \n    name ==  \"Hepacivirus\" | \n    name ==  \"Lymphocryptovirus\" |\n    name ==  \"Cytomegalovirus\" |\n    name == \"Lentivirus\") %>% group_by(name) %>% summarize(sum=sum(n_reads_clade))\n\nviral_families_interest\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"name\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"sum\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Cytomegalovirus\",\"2\":\"5\"},{\"1\":\"Lymphocryptovirus\",\"2\":\"79\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n# Conclusion\n\nSecond rough analysis, I plan on going in-depth during the next few days, luckily this revealed a few bugs that I hope to take care off.\n\nAfter going through this a second time, I realized that there are three potential bugs: - Forgot to remove prefix of stage from sample names in multiqc_single_format - (may be connected to above) adapter statistics are not calculated - Getting negative unassigned reads from kraken, I assume this probably has to do with some paired stuff\n",
    "supporting": [
      "2024-07-09_blauwkamp_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}