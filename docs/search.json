[
  {
    "objectID": "notebooks/2024-07-23-mengyi.html",
    "href": "notebooks/2024-07-23-mengyi.html",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "",
    "text": "This one of the studies that we hope to discuss in our third blog post, which will cover the metagenomic analysis of whole blood/plasma. In this notebook, I analyze Mengyi 2023, a dataset from China with 200 pools of plasma, where each pool contains 160 samples from 7 different locations, for a total of 10,720 samples.\nI’d like to thank Lenni for giving me feedback on this and Will for providing me with access to this rmarkdown file."
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#about",
    "href": "notebooks/2024-07-23-mengyi.html#about",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n1.1 About",
    "text": "1.1 About\nThis dataset from China has 200 pools of plasma, where each pool contains 160 samples from 7 different locations between 2012-2018, for a total of 10,720 samples. This paper did not discuss the number of individuals that contributed to the samples, but we’re going to attempt to contact the authors to get this information (this shouldn’t hold up any further analysis, but would be good to have this information). They did DNA sequencing for each pool, with 150 base pair paired-end sequencing (2x150 bp).\n\n1.1.1 Sample + library preparation\nThe following excerpt from the paper describes the sample and library preparation process. It’s crucial to note that while blood samples were initially collected from volunteers, these samples were converted to plasma through ultracentrifugation prior to sequencing:\n\nFrom January 1, 2012, to December 31, 2018, a total of 10,720 blood samples of 10 ml each were randomly selected from voluntary blood donors in 7 regions. The blood samples taken from various places were mixed in units of 160 (each 100 μl) for ultracentrifugation (32,000 rpm, 120 min, maximum centrifugal radius of 91.9 mm). Afterward, we rinsed and resuspended the precipitate with 500 μl PBS.\nThe pooled suspensions were subjected to extraction of total DNA using QIAamp® DNA Blood mini Kit (QIAGEN Cat. NO.160019269, Frankfurt, Germany), DNA concentration was measured by Equalbit® 1 × dsDNA HS Assay Kit (Vazyme Cat. NO. 7E302K9, Nanjing, China).\nThe metagenomic library was constructed using KAPA HyperPlus Kit (KAPA Cat. NO. 0000097583, Boston, USA) with dual-indexed Adapters (KAPA Cat. NO. 0000093370, Boston, USA), the DNA was fragmented to 250 bp approximately by the enzyme at 37 °C for 20 min, after end repair and A-tailing, adapter ligation, post-ligation cleanup, library amplification, and post-amplification cleanup, the library was constructed.\nAgilent 2100 Bioanalyzer (Agilent Technologies, Beijing, China) was used for library quality control, and qualified DNA library was sent to the Novogene company to sequence in HiSeq 4500."
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#quality-control-metrics",
    "href": "notebooks/2024-07-23-mengyi.html#quality-control-metrics",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n1.2 Quality control metrics",
    "text": "1.2 Quality control metrics\nIn total, these 200 samples contained 3.4B read pairs. The samples had 8.2M - 30.1M (mean 17.1M) read pairs each.\nNumber of read pairs, total bases and % of duplicates all look good.\n\nCode# Prepare data\nbasic_stats_raw_metrics &lt;- basic_stats_raw %&gt;%\n  select(library,\n         location,\n         `# Read pairs` = n_read_pairs,\n         `Total base pairs\\n(approx)` = n_bases_approx,\n         `% Duplicates\\n(FASTQC)` = percent_duplicates) %&gt;%\n  pivot_longer(-(library:location), names_to = \"metric\", values_to = \"value\") %&gt;%\n  mutate(metric = fct_inorder(metric)) \n\n# Set up plot templates\n\ng_basic &lt;- ggplot(basic_stats_raw_metrics, aes(x = library, y = value, fill=location)) +\n  geom_col(position = \"dodge\") +\n  scale_x_discrete() +\n  scale_fill_brewer(palette = \"Dark2\") +\n  scale_y_continuous(expand = c(0, 0)) +\n  expand_limits(y = c(0, 100)) +\n  facet_grid(metric ~ ., scales = \"free\", space = \"free_x\", switch = \"y\") +\n  theme_kit + theme(\n    axis.title.y = element_blank(),\n    strip.text.y = element_text(face = \"plain\")\n  )\ng_basic\n\n\n\n\n\n\n\nAdapter content is low. As we’d expect, we see higher quality Q scores near the beginning of the read and a gradual decline towards the end of the read, however all positions seem to have a Q score of 35 which means that our reads are ~99.97% accurate. When looking at the Q score over all sequences, we can see a sharp peak after 35, which closely follows the previous plot, indicating high read quality.\n\nCode# Set up plotting templates\ng_qual_raw &lt;- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters_raw &lt;- g_qual_raw + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats_raw) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,5),\n                     expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0)) +\n  facet_grid(.~adapter)\ng_adapters_raw\n\n\n\n\n\n\nCode# Visualize quality\ng_quality_base_raw &lt;- g_qual_raw +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats_raw) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0))\ng_quality_base_raw\n\n\n\n\n\n\nCodeg_quality_seq_raw &lt;- g_qual_raw +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats_raw) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0))\ng_quality_seq_raw"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#summary",
    "href": "notebooks/2024-07-23-mengyi.html#summary",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n2.1 Summary",
    "text": "2.1 Summary\nThe average fraction of reads at each stage in the preprocessing pipeline is shown in the following table. Reads lost during trimming and filtering approximately matches what we’d expect based on the raw adapter content. Deduplication loses us about 10% of reads which matched the amount of estimated duplicated reads by QC. Low ribodepletion is observed which makes sense because they only sequneced DNA.\n\nCode# TODO: Group by pool size as well\n# Count read losses\nn_reads_rel &lt;- basic_stats %&gt;% \n  select(sample, stage, percent_duplicates, n_read_pairs) %&gt;%\n  group_by(sample) %&gt;% \n  arrange(sample, stage) %&gt;%\n  mutate(p_reads_retained = n_read_pairs / lag(n_read_pairs),\n         p_reads_lost = 1 - p_reads_retained,\n         p_reads_retained_abs = n_read_pairs / n_read_pairs[1],\n         p_reads_lost_abs = 1-p_reads_retained_abs,\n         p_reads_lost_abs_marginal = p_reads_lost_abs - lag(p_reads_lost_abs))\nn_reads_rel_display &lt;- n_reads_rel %&gt;% \n  rename(Stage=stage) %&gt;% \n  group_by(Stage) %&gt;% \n  summarize(`% Total Reads Lost (Cumulative)` = paste0(round(min(p_reads_lost_abs*100),1), \"-\", round(max(p_reads_lost_abs*100),1), \" (mean \", round(mean(p_reads_lost_abs*100),1), \")\"),\n            `% Total Reads Lost (Marginal)` = paste0(round(min(p_reads_lost_abs_marginal*100),1), \"-\", round(max(p_reads_lost_abs_marginal*100),1), \" (mean \", round(mean(p_reads_lost_abs_marginal*100),1), \")\"), .groups=\"drop\") %&gt;% \n  filter(Stage != \"raw_concat\") %&gt;%\n  mutate(Stage = Stage %&gt;% as.numeric %&gt;% factor(labels=c(\"Trimming & filtering\", \"Deduplication\", \"Initial ribodepletion\", \"Secondary ribodepletion\")))\nn_reads_rel_display"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#quality-control-metrics-1",
    "href": "notebooks/2024-07-23-mengyi.html#quality-control-metrics-1",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n2.2 Quality control metrics",
    "text": "2.2 Quality control metrics\nThese plots below show the trends from above in each sample.\nTrimming and cleaning gets rid of Illumnia unviersal adapter as well as polyg, and we see a decrease in polya. Q score remain the same during read cleaning when looking at the positions, with the end of the read actually improving in score. Q scores across all sequences look pretty much the same throughout cleaning.\n\nCodeg_qual &lt;- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters &lt;- g_qual + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,5),\n                     expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~adapter)\ng_adapters\n\n\n\n\n\n\nCode# Visualize quality\ng_quality_base &lt;- g_qual +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~.)\ng_quality_base\n\n\n\n\n\n\nCodeg_quality_seq &lt;- g_qual +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0)) +\n  facet_grid(stage~., scales = \"free_y\")\ng_quality_seq\n\n\n\n\n\n\n\n\nCodeg_stage_trace &lt;- ggplot(basic_stats, aes(x=stage, group=sample)) +\n  theme_kit\n\n# Plot reads over preprocessing\ng_reads_stages &lt;- g_stage_trace +\n  geom_line(aes(y=n_read_pairs)) +\n  scale_y_continuous(\"# Read pairs\", expand=c(0,0), limits=c(0,NA))\ng_reads_stages\n\n\n\n\n\n\nCode# Plot relative read losses during preprocessing\ng_reads_rel &lt;- ggplot(n_reads_rel, \n                      aes(x=stage, group=sample)) +\n  geom_line(aes(y=p_reads_lost_abs_marginal)) +\n  scale_y_continuous(\"% Total Reads Lost\", expand=c(0,0), \n                     labels = function(x) x*100) +\n  theme_kit\ng_reads_rel\n\n\n\n\n\n\n\nAll samples tend to follow similar trends for deduplication, with a large decrease in read length post adapter trimming.\n\nCodestage_dup &lt;- basic_stats %&gt;% group_by(stage) %&gt;% \n  summarize(dmin = min(percent_duplicates), dmax=max(percent_duplicates),\n            dmean=mean(percent_duplicates), .groups = \"drop\")\n\ng_dup_stages &lt;- g_stage_trace +\n  geom_line(aes(y=percent_duplicates)) +\n  scale_y_continuous(\"% Duplicates\", limits=c(0,NA), expand=c(0,0))\ng_dup_stages\n\n\n\n\n\n\n\n\nCodeg_readlen_stages &lt;- g_stage_trace + geom_line(aes(y=mean_seq_len)) +\n  scale_y_continuous(\"Mean read length (nt)\", expand=c(0,0), limits=c(0,NA))\ng_readlen_stages\n\n\n\nReminder that this data is 2x150 bp.\n\n\n\nAs expected, ribosomal reads are near 0% for every sample.\n\nCode# Calculate reads lost during ribodepletion (approximation for % ribosomal reads)\nreads_ribo &lt;- n_reads_rel %&gt;% \n  filter(stage %in% c(\"dedup\", \"ribo_secondary\")) %&gt;% \n  group_by(sample) %&gt;% \n  summarize(p_reads_ribo=1-n_read_pairs[2]/n_read_pairs[1], .groups = \"drop\") %&gt;%\n  inner_join(libraries, by = 'sample')\nreads_ribo_summ &lt;- reads_ribo %&gt;%\n  group_by(sample) %&gt;%\n  summarize(min=min(p_reads_ribo), max=max(p_reads_ribo),\n            mean=mean(p_reads_ribo), .groups = \"drop\") %&gt;%\n  inner_join(libraries, by = 'sample')\ng_reads_ribo &lt;- ggplot(reads_ribo, \n                       aes(x=library, y=p_reads_ribo)) +\n  geom_point() + \n  scale_y_continuous(name=\"Approx % ribosomal reads\", limits=c(0,1),\n                     breaks=seq(0,1,0.2), expand=c(0,0), labels = function(y) y*100)+\n  theme_kit\ng_reads_ribo\n\n\n\nRibodepletion aims to get rid of ribosomal RNA, so we don’t expect DNA sequencing to have this."
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#high-level-composition",
    "href": "notebooks/2024-07-23-mengyi.html#high-level-composition",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n3.1 High-level composition",
    "text": "3.1 High-level composition\nTo assess the high-level composition of the reads, I ran the files through Kraken2 and summarized the results with Bracken.\nThe groups listed below were created by Will:\n\nFiltered (removed during cleaning)\nDuplicate (removed during deduplication)\nRibosomal (removed during ribodepletion)\nUnassigned (non-ribosomal reads that were not assigned to any taxon by Kraken/Bracken)\nBacterial (non-ribosomal reads assigned to the Bacteria domain by Kraken/Bracken)\nArchaeal (non-ribosomal reads assigned to the Archaea domain by Kraken/Bracken)\nViral (non-ribosomal reads assigned to the Viruses domain by Kraken/Bracken)\nHuman (non-ribosomal reads assigned to the Eukarya domain by Kraken/Bracken)\n\nAdditionally, there are two groups:\n\nAll groups (all of the categories above)\nMinor groups (Archeal, Viral, Human, Other)\n\n\nCode# Prepare plotting templates\ng_comp_base &lt;- ggplot(mapping=aes(x=library, y=p_reads, fill=classification)) +\n  scale_x_discrete(name=\"Plasma pool\") +\n  theme_kit + \n  theme(plot.title = element_text(hjust=0, face=\"plain\", size=rel(1.5)))\nscale_y_pc_reads &lt;- purrr::partial(scale_y_continuous, name = \"% Reads\",\n                                   expand = c(0,0), labels = function(y) y*100)\ngeom_comp &lt;- purrr::partial(geom_col, position = \"stack\", width = 1)\n\nclassification_colors &lt;- brewer.pal(8, \"Accent\")\nnames(classification_colors) &lt;- c(\"Filtered\", \"Duplicate\", \"Ribosomal\", \"Unassigned\", \"Bacterial\", \"Archaeal\", \"Viral\", \"Human\")\n\n# Update the scale_fill_manual function to use the named vector\nscale_fill_classification &lt;- function() {\n  scale_fill_manual(values = classification_colors, name = \"Classification\")\n}\n\n# Plot overall composition\ng_comp &lt;- g_comp_base + geom_comp(data = comp) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (all reads, all groups)\")\ng_comp\n\n\n\n\n\n\nCode# Repeat for classified reads only\ng_comp_assigned &lt;- g_comp_base + \n  geom_comp(data = comp_assigned) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (assigned reads, all groups)\")\ng_comp_assigned\n\n\n\n\n\n\nCode# Plot composition of minor components\ng_comp_minor &lt;- g_comp_base + \n  geom_comp(data=comp_minor) +\n  scale_y_pc_reads() +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (all reads, minor groups)\")\ng_comp_minor\n\n\n\n\n\n\nCodeg_comp_assigned_minor &lt;- g_comp_base + \n  geom_comp(data=comp_assigned_minor) +\n  scale_y_pc_reads() +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (assigned reads, minor groups)\")\ng_comp_assigned_minor"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#total-viral-content",
    "href": "notebooks/2024-07-23-mengyi.html#total-viral-content",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n3.2 Total viral content",
    "text": "3.2 Total viral content\nTotal viral fraction average \\(1.03 \\times 10^{-4}\\) across samples. As a fraction of assigned (rather than total) reads, this jumped to \\(1.28 \\times 10^{-4}\\):\n\nCodep_reads_viral_all &lt;- comp %&gt;% filter(classification == \"Viral\") %&gt;%\n  mutate(read_group = \"All reads\")\np_reads_viral_assigned &lt;- comp_assigned %&gt;% filter(classification == \"Viral\") %&gt;%\n  mutate(read_group = \"Classified reads\")\np_reads_viral &lt;- bind_rows(p_reads_viral_all, p_reads_viral_assigned)\n\n# Plot\ng_viral &lt;- ggplot(p_reads_viral, aes(x=p_reads, y=library, color=location, shape=read_group)) +\n  geom_point() +\n  scale_y_discrete(name=\"Plasma pool\") +\n  scale_x_log10(name=\"Viral read fraction\") +\n  scale_color_brewer(palette = \"Dark2\") +\n  #facet_grid(.~read_group, scales = \"free\") +\n  guides(color=guide_legend(nrow=2), shape=guide_legend(nrow=2),\n         linetype=guide_legend(nrow=2)) +\n  theme_kit\ng_viral\n\nWarning: Transformation introduced infinite values in continuous x-axis"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#taxonomic-composition-of-viruses",
    "href": "notebooks/2024-07-23-mengyi.html#taxonomic-composition-of-viruses",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n3.3 Taxonomic composition of viruses",
    "text": "3.3 Taxonomic composition of viruses\nThe one dominant viruses we see is Hepadnaviridae. The threshold for the label “other” are the set of families that make up less than 20% composition in all samples (the only reason I did this was because there were too many matches).\n\nCodemajor_threshold &lt;- 0.20\n\n# Identify major viral families\nviral_families_major_tab &lt;- viral_families %&gt;% \n  group_by(name, taxid) %&gt;%\n  summarize(p_reads_viral_max = max(p_reads_viral), .groups=\"drop\") %&gt;%\n  filter(p_reads_viral_max &gt;= major_threshold)\nviral_families_major_list &lt;- viral_families_major_tab %&gt;% pull(name)\nviral_families_major &lt;- viral_families %&gt;% \n  filter(name %in% viral_families_major_list) %&gt;%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_minor &lt;- viral_families_major %&gt;% \n  group_by(sample) %&gt;%\n  summarize(p_reads_viral_major = sum(p_reads_viral), .groups = \"drop\") %&gt;%\n  mutate(name = \"Other\", taxid=NA, p_reads_viral = 1-p_reads_viral_major) %&gt;%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_display &lt;- viral_families_major %&gt;% \n  bind_rows(viral_families_minor) %&gt;%\n  arrange(desc(p_reads_viral)) %&gt;% \n  mutate(name = factor(name, levels=c(viral_families_major_list, \"Other\"))) %&gt;%\n  rename(p_reads = p_reads_viral, classification=name) %&gt;%\n  inner_join(libraries, by='sample')\n\n# Create a custom color palette with up to 20 colors\ncustom_palette &lt;- c(\n  brewer.pal(8, \"Set2\"),\n  brewer.pal(8, \"Set1\"),\n  brewer.pal(4, \"Pastel1\")\n)\n\n# Plot\ng_families &lt;- g_comp_base + \n  geom_comp(data=viral_families_display) +\n  scale_y_continuous(name=\"% Viral Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_manual(values = custom_palette)\ng_families"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#overall-relative-abundance",
    "href": "notebooks/2024-07-23-mengyi.html#overall-relative-abundance",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n4.1 Overall relative abundance",
    "text": "4.1 Overall relative abundance\nI calculated the relative abundance of human-infecting viruses in two ways:\n\nFirst, as the total number of deduplicated human-virus reads in each sample, divided by the number of raw reads (“All reads”).\nSecond, as a fraction of preprocessed (cleaned, deduplicated, computationally ribodepleted) reads (“Preprocessed reads”).\n\n\nCode# Get raw read counts\nread_counts_raw &lt;- filter(basic_stats_raw) %&gt;%\n  select(sample, n_reads_raw = n_read_pairs)\nread_counts_preproc &lt;- basic_stats %&gt;% filter(stage == \"ribo_initial\") %&gt;%\n  select(sample, n_reads_preproc = n_read_pairs)\n\n# Get HV read counts\nread_counts_hv &lt;- mrg_hv %&gt;% filter(hv_status) %&gt;% \n  group_by(sample) %&gt;% \n  count(name=\"n_reads_hv\")\nread_counts &lt;- read_counts_raw %&gt;%\n  left_join(read_counts_hv, by=c(\"sample\")) %&gt;%\n  mutate(n_reads_hv = replace_na(n_reads_hv, 0)) %&gt;%\n  left_join(read_counts_preproc, by=c(\"sample\")) %&gt;%\n  inner_join(libraries, by=c(\"sample\")) %&gt;%\n  select(sample, n_reads_raw, n_reads_preproc, n_reads_hv) %&gt;%\n  mutate(n_samples = 1,\n         p_reads_total = n_reads_hv/n_reads_raw,\n         p_reads_preproc = n_reads_hv/n_reads_preproc)\nread_counts_long &lt;- read_counts %&gt;%\n  pivot_longer(starts_with(\"p_reads\"), names_to=\"read_group\", values_to=\"p_reads\") %&gt;%\n  mutate(read_group = ifelse(read_group == \"p_reads_total\", \"All reads\", \"Preprocessed reads\"))\n\n# Combine for display\nread_counts_agg &lt;- read_counts %&gt;%\n  mutate(p_reads_total = n_reads_hv/n_reads_raw,\n         p_reads_preproc = n_reads_hv/n_reads_preproc) %&gt;%\n  inner_join(libraries, by=c(\"sample\"))\nread_counts_agg_long &lt;- read_counts_agg %&gt;%\n  pivot_longer(starts_with(\"p_reads\"), names_to=\"read_group\", values_to=\"p_reads\") %&gt;%\n  mutate(read_group = ifelse(read_group == \"p_reads_total\", \"All reads\", \"Preprocessed reads\")) \n\n# Visualize\n#g_read_counts &lt;- ggplot(read_counts_agg_long, aes(x=library, y=p_reads)) +\n#  geom_point() +\n#  scale_y_log10(name = \"Unique human-viral read fraction\") +\n#  facet_grid(.~read_group, scales = \"free\") +\n#  theme_kit\n#g_read_counts\n\ng_viral &lt;- ggplot(read_counts_agg_long, aes(x=p_reads, y=library, color=location, shape=read_group)) +\n  geom_point() +\n  scale_y_discrete(name=\"Plasma pool\") +\n  scale_x_log10(name=\"Viral read fraction\") +\n  scale_color_brewer(palette = \"Dark2\") +\n  #facet_grid(.~read_group, scales = \"free\") +\n  guides(color=guide_legend(nrow=2), shape=guide_legend(nrow=2),\n         linetype=guide_legend(nrow=2)) +\n  theme_kit\ng_viral"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#overall-taxonomy-and-composition",
    "href": "notebooks/2024-07-23-mengyi.html#overall-taxonomy-and-composition",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n4.2 Overall taxonomy and composition",
    "text": "4.2 Overall taxonomy and composition\nComposition of HV reads was changed from when looking at all viral reads. The two dominant viruses we see are Anellovirdae and Hepadnaviridae. The threshold for the label “other” are the set of families that make up less than 5% composition in all samples.\n\nCodethreshold_major_family &lt;- 0.05\n\n# Count reads for each human-viral family\nhv_family_counts &lt;- hv_reads_family %&gt;% \n  group_by(sample, name, taxid) %&gt;%\n  count(name = \"n_reads_hv\") %&gt;%\n  group_by(sample) %&gt;%\n  mutate(p_reads_hv = n_reads_hv/sum(n_reads_hv))\n\n# Identify high-ranking families and group others\nhv_family_major_tab &lt;- hv_family_counts %&gt;% group_by(name) %&gt;% \n  filter(p_reads_hv == max(p_reads_hv)) %&gt;% filter(row_number() == 1) %&gt;%\n  arrange(desc(p_reads_hv)) %&gt;% filter(p_reads_hv &gt; threshold_major_family)\nhv_family_counts_major &lt;- hv_family_counts %&gt;%\n  mutate(name_display = ifelse(name %in% hv_family_major_tab$name, name, \"Other\")) %&gt;%\n  group_by(sample, name_display) %&gt;%\n  summarize(n_reads_hv = sum(n_reads_hv), p_reads_hv = sum(p_reads_hv), \n            .groups=\"drop\") %&gt;%\n  mutate(name_display = factor(name_display, \n                               levels = c(hv_family_major_tab$name, \"Other\")))\nhv_family_counts_display &lt;- hv_family_counts_major %&gt;%\n  rename(p_reads = p_reads_hv, classification = name_display) %&gt;%\n  inner_join(libraries, by = 'sample')\n\n# Plot\ng_hv_family &lt;- g_comp_base + \n  geom_col(data=hv_family_counts_display, position = \"stack\", width=1) +\n  scale_y_continuous(name=\"% HV Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_brewer(palette = \"Accent\", name = \"Viral family\") +\n  labs(title=\"Family composition of human-viral reads\") +\n  guides(fill=guide_legend(ncol=4)) +\n  theme(plot.title = element_text(size=rel(1.4), hjust=0, face=\"plain\"))\ng_hv_family\n\n\n\n\n\n\nCode# Get most prominent families for text\nhv_family_collate &lt;- hv_family_counts %&gt;%\n  group_by(name, taxid) %&gt;% \n  summarize(n_reads_tot = sum(n_reads_hv),\n            p_reads_max = max(p_reads_hv), .groups=\"drop\") %&gt;% \n  arrange(desc(n_reads_tot))\nhv_family_collate"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#species-analysis",
    "href": "notebooks/2024-07-23-mengyi.html#species-analysis",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n4.3 Species analysis",
    "text": "4.3 Species analysis\nTo get a good overview of families, genera, and species, we can look at a Sankey plot where the magnitude of relative abundance, averaged over all samples, is shown in parentheses.\n\nCode# Function to create links\ncreate_links &lt;- function(data) {\n  family_to_genus &lt;- data %&gt;%\n    filter(!is.na(genus)) %&gt;%\n    group_by(family, genus) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = genus)\n  \n  genus_to_species &lt;- data %&gt;%\n    group_by(genus, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = genus, target = species)\n\n  family_to_species &lt;- data %&gt;%\n    filter(is.na(genus)) %&gt;%\n    group_by(family, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = species)\n\n  bind_rows(family_to_genus, genus_to_species, family_to_species) %&gt;%\n    filter(!is.na(source))\n}\n\n# Function to create nodes\ncreate_nodes &lt;- function(links) {\n  data.frame(\n    name = c(links$source, links$target) %&gt;% unique()\n  )\n}\n\n# Function to prepare data for Sankey diagram\nprepare_sankey_data &lt;- function(links, nodes) {\n  links$IDsource &lt;- match(links$source, nodes$name) - 1\n  links$IDtarget &lt;- match(links$target, nodes$name) - 1\n  list(links = links, nodes = nodes)\n}\n\n# Function to create Sankey plot\ncreate_sankey_plot &lt;- function(sankey_data) {\n  sankeyNetwork(\n    Links = sankey_data$links, \n    Nodes = sankey_data$nodes,\n    Source = \"IDsource\", \n    Target = \"IDtarget\",\n    Value = \"value\", \n    NodeID = \"name\",\n    sinksRight = TRUE,\n    nodeWidth = 25,\n    fontSize = 14,\n  )\n}\n\nsave_sankey_as_png &lt;- function(sankey_plot, width = 1000, height = 800) {\n  # Save the plot as an HTML file\n  saveWidget(sankey_plot, sprintf('%s/sankey.html',data_dir))\n}\n\nformat_scientific &lt;- function(x, digits=2) {\n  sapply(x, function(val) {\n    if (is.na(val) || abs(val) &lt; 1e-15) {\n      return(\"0\")\n    } else {\n      exponent &lt;- floor(log10(abs(val)))\n      coef &lt;- val / 10^exponent\n      #return(sprintf(\"%.1f × 10^%d\", round(coef, digits), exponent))\n      # May or may not be smart, just keeping magnitude\n      return(sprintf(\"10^%d\", exponent))\n    }\n  })\n}\n\ndata &lt;- result %&gt;% \n  mutate(across(c(genus_n_reads_tot, genus_ra_reads_tot), ~replace_na(., 0)),\n         genus = ifelse(is.na(genus), \"Unknown Genus\", genus)) %&gt;%\n  mutate(\n  species = paste0(species, sprintf(' (%s)', format_scientific(species_ra_reads_tot))),\n  genus = paste0(genus, sprintf(' (%s)', format_scientific(genus_ra_reads_tot))),\n  family = paste0(family, sprintf(' (%s)', format_scientific(family_ra_reads_tot)))\n)\nlinks &lt;- as.data.frame(create_links(data))\nnodes &lt;- create_nodes(links)\nsankey_data &lt;- prepare_sankey_data(links, nodes)\nsankey &lt;- create_sankey_plot(sankey_data)\n\nsankey\n\n\n\n\n\nTo get a better idea of the relative abundance of species, we can create a dot plot where each dot represents the relative abundance of a particular species in a sample.\n\nCodespecies_family &lt;- result %&gt;% select(species, family) %&gt;% rename('name' = 'species')\n\nplay &lt;- hv_species_counts %&gt;% \n  ungroup() %&gt;%\n  inner_join(libraries, by = 'sample') %&gt;%\n  inner_join(species_family, by = 'name')\n\nplay$family &lt;- factor(play$family, levels=hv_family_collate %&gt;% pull(family))\nplay &lt;- play %&gt;%\n  arrange(family, name) %&gt;%\n  mutate(name = factor(name, levels = unique(name))) %&gt;%\n  group_by(name) %&gt;%\n  mutate(virus_count = n_distinct(sample),\n         mean_ra = mean(ra_reads_hv)) %&gt;%\n  ungroup() %&gt;%\n  mutate(total_samples = n_distinct(libraries),\n         virus_prevalence = paste0(virus_count, \"/\", total_samples),\n          virus_prevalence_num = virus_count/total_samples,\n            name = paste0(name, ' (', virus_prevalence, ')')) %&gt;% \n  mutate(name = fct_reorder(name, virus_prevalence_num, .desc = TRUE))\n#name_order &lt;- play %&gt;% arrange(family) %&gt;% pull(name)\n#play$name &lt;- factor(play$name, levels = name_order)\n\npal &lt;- c(brewer.pal(8, 'Dark2'),brewer.pal(8, 'Accent'))\n\nra_dot &lt;- ggplot(play, aes(x = ra_reads_hv, y=name)) +\n  geom_quasirandom(orientation = 'y', aes(color = family)) +\n  scale_color_manual(values = pal) + \n    scale_x_log10(\n    \"Relative abundance human virus reads\",\n    labels = function(x) parse(text = paste0(\"10^\", round(log10(x)))),\n    limits = c(1e-9, 1),\n    n.breaks = 8\n  ) +\n  labs(y = 'Human virus  (# samples with virus/total # samples)',\n       color = 'Viral family') + \n  theme_light() + \n    theme(\n    axis.text.y = element_text(size = 8),\n    axis.text.x = element_text(size = 14),\n    axis.ticks.y = element_blank(),axis.line = element_line(colour = \"black\"),\n    axis.title.x = element_text(size = 15),    \n    axis.title.y = element_text(size = 15),  \n    legend.text = element_text(size = 13),\n    legend.title = element_text(size = 16),\n    legend.position = c(1, 1),  # Move legend to top right\n    legend.justification = c(1, 1),  # Align legend to top right\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank())\nra_dot\n\n\n\n\n\n\n\nWe now exclude Anelloviridae from the plot and add in the locations of the samples in a separate bar plot.\n\nCodeplay_subset &lt;- play %&gt;% filter(family != \"Anelloviridae\")\nplay_subset &lt;- play_subset%&gt;%\n  group_by(name) %&gt;%\n  mutate(virus_count = n_distinct(sample),\n         mean_ra = mean(ra_reads_hv)) %&gt;%\n  ungroup() %&gt;%\n  mutate(total_samples = n_distinct(libraries),\n         virus_prevalence = paste0(virus_count, \"/\", total_samples),\n         virus_prevalence_num = virus_count/total_samples,\n            name = paste0(name, ' (', virus_prevalence, ')')) %&gt;% \n  mutate(name = fct_reorder(name, virus_prevalence_num, .desc = TRUE))\n\n#play_subset &lt;- left_join(play_subset, libraries %&gt;% select(sample, location), by = 'sample')\n\npal &lt;- brewer.pal(12, 'Set3')\n\nra_dot &lt;- ggplot(play_subset, aes(x = ra_reads_hv, y=name)) +\n  geom_quasirandom(orientation = 'y', aes(color = family)) +\n#  geom_point(aes(x = mean_ra), shape = 18, size = 4) + \n  scale_color_manual(values = pal) + \n  scale_x_log10(\n    \"Relative abundance human virus reads\",\n    labels = function(x) parse(text = paste0(\"10^\", round(log10(x)))),\n    limits = c(1e-9, 1),\n    n.breaks = 8\n  ) +\n  labs(y = 'Human virus (# samples with virus/total # samples)',\n       color = 'Viral family') +\n  theme_light() + \n  theme(\n    axis.text.y = element_text(size = 8),\n    axis.text.x = element_text(size = 14),\n    axis.ticks.y = element_blank(),axis.line = element_line(colour = \"black\"),\n    axis.title.x = element_text(size = 15),    \n    axis.title.y = element_text(size = 15),  \n    legend.text = element_text(size = 13),\n    legend.title = element_text(size = 16),\n    legend.position = c(1, 1),  # Move legend to top right\n    legend.justification = c(1, 1),  # Align legend to top right\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank())\n\nprevalence_bar &lt;- ggplot(play_subset, aes(x = virus_prevalence_num, y = name, fill = location)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  scale_x_continuous(\n    \"Percent of samples with virus\",\n    labels = scales::percent_format(scale = 1, accuracy = 1)\n  ) +\n  labs(y = 'Human virus',\n       fill = 'Location') +\n  theme_light() + \n  theme(\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size = 14),\n    axis.ticks.y = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    axis.title.x = element_text(size = 15),    \n    axis.title.y = element_blank(),  \n    legend.text = element_text(size = 13),\n    legend.title = element_text(size = 16),\n    legend.position = c(1, 1),  # Move legend to top right\n    legend.justification = c(1, 1),  # Align legend to top right\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank())\n\n# Combine the plots using ggarrange\ncombined_plot &lt;- ggarrange(ra_dot, prevalence_bar, \n                           ncol = 2, \n                           widths = c(1.2, 1),\n                           common.legend = FALSE,\n                           align = \"h\")\ncombined_plot\n\n\n\n\n\n\n\nWe can ask Claude to analyze the pathogenicity of these viruses along with their popular names.\n\n\n\n\n\n\n\nScientific Name\nPopular/Well-known Name\nPathogenicity to Humans\n\n\n\nHuman immunodeficiency virus 1\nHIV-1\nVery High\n\n\nSevere acute respiratory syndrome-related coronavirus\nSARS-CoV\nHigh\n\n\nHepatitis B virus\nHBV\nHigh\n\n\nHepacivirus hominis\nHepatitis C virus (HCV)\nHigh\n\n\nSimplexvirus humanalpha1\nHerpes simplex virus 1 (HSV-1)\nModerate to High\n\n\nCytomegalovirus humanbeta5\nHuman cytomegalovirus (HCMV)\nModerate to High\n\n\nLymphocryptovirus humangamma4\nEpstein-Barr virus (EBV)\nModerate\n\n\nHuman mastadenovirus C\nAdenovirus C\nModerate\n\n\nHuman mastadenovirus F\nAdenovirus F\nModerate\n\n\nRoseolovirus humanbeta6a\nHuman herpesvirus 6A (HHV-6A)\nLow to Moderate\n\n\nRoseolovirus humanbeta6b\nHuman herpesvirus 6B (HHV-6B)\nLow to Moderate\n\n\nRoseolovirus humanbeta7\nHuman herpesvirus 7 (HHV-7)\nLow to Moderate\n\n\nRhadinovirus humangamma8\nKaposi’s sarcoma-associated herpesvirus (KSHV)\nLow to Moderate\n\n\nMolluscum contagiosum virus\nMCV\nLow\n\n\nErythroparvovirus primate1\nParvovirus B19\nLow\n\n\nHuman erythrovirus V9\nErythrovirus V9\nLow\n\n\nAlphapapillomavirus 4\nHuman papillomavirus 4 (HPV-4)\nLow\n\n\nBetapolyomavirus hominis\nHuman polyomavirus\nLow\n\n\nDependoparvovirus primate1\nAdeno-associated virus (AAV)\nVery Low\n\n\nMurine leukemia virus\nMLV\nVery Low (not a human pathogen)\n\n\nMurine leukemia-related retroviruses\nMLV-related viruses\nVery Low (not typical human pathogens)\n\n\nGokushovirus WZ-2015a\n-\nUnknown (likely Very Low)\n\n\nHuman gut gokushovirus\n-\nUnknown (likely Very Low)\n\n\nMicroviridae sp.\n-\nUnknown (likely Very Low)\n\n\nMicrovirus sp.\n-\nUnknown (likely Very Low)\n\n\n\nI’d like to BLAST some of these reads against the NCBI nt database to see if we can get some more info on them."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Harmon’s public notebook",
    "section": "",
    "text": "Workflow of Mengyi et al. (2023)\n\n\nPooled plasma from China (DNA)\n\n\n\n\n\n\n\n\nJul 23, 2024\n\n\nHarmon Bhasin\n\n\n\n\n\n\nNo matching items"
  }
]