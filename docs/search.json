[
  {
    "objectID": "notebooks/2024-07-23-mengyi.html",
    "href": "notebooks/2024-07-23-mengyi.html",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "",
    "text": "This one of the studies that we hope to discuss in our third blog post, which will cover the metagenomic analysis of whole blood/plasma. In this notebook, I analyze Mengyi 2023, a dataset from China with 201 pools of plasma, where each pool contains 160 samples (we don’t know whether 1 sample = 1 donation) from 7 different locations, for a total of 10,720 samples.\nI’d like to thank Lenni for giving me feedback on the notebook, Will for providing me with a boilerplate rmarkdown file, and Simon for giving me feedback on my figures. This notebook uses the MGS Workflow v2.2.1 (note that this is old)."
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#about",
    "href": "notebooks/2024-07-23-mengyi.html#about",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n1.1 About",
    "text": "1.1 About\nThis dataset from China has 201 pools of plasma, where each pool contains 160 samples from 7 different locations between 2012-2018, for a total of 10,720 samples. This paper did not discuss the number of individuals that contributed to the samples, but we’re going to attempt to contact the authors to get this information (this shouldn’t hold up any further analysis, but would be good to have this information). They did DNA-sequencing for each pool, with Illumina HiSeq 4500, producing 2x150 bp reads.\n\nCode# Import libraries and extract metadata from sample names\nlibraries &lt;- read_csv(libraries_path, show_col_types = FALSE)\nmetadata &lt;- read_tsv(sprintf('%s/metadata.tsv', data_dir), show_col_types = FALSE) %&gt;%\n  select('sample'=`Library`, `library`=`Sample title`, 'Geographic location') %&gt;%\n  mutate('location' = str_split(`Geographic location`, \":\", simplify = TRUE)[, ncol(str_split(`Geographic location`, \":\", simplify = TRUE))])\nlibraries &lt;- libraries %&gt;%\n  left_join(metadata, by = 'sample') %&gt;%\n  select(sample, library=library.y, location) %&gt;%\n  mutate(library = factor(library))\n\nlibraries %&gt;% group_by(location) %&gt;% summarize(n_pools = n())\n\n\n  \n\n\n\n\n1.1.1 Sample + library preparation\nThe following excerpt from the paper describes the sample and library preparation process. It’s crucial to note that while blood samples were initially collected from volunteers, these samples were converted to plasma through ultracentrifugation prior to sequencing:\n\nFrom January 1, 2012, to December 31, 2018, a total of 10,720 blood samples of 10 ml each were randomly selected from voluntary blood donors in 7 regions. The blood samples taken from various places were mixed in units of 160 (each 100 μl) for ultracentrifugation (32,000 rpm, 120 min, maximum centrifugal radius of 91.9 mm). Afterward, we rinsed and resuspended the precipitate with 500 μl PBS.\nThe pooled suspensions were subjected to extraction of total DNA using QIAamp® DNA Blood mini Kit (QIAGEN Cat. NO.160019269, Frankfurt, Germany), DNA concentration was measured by Equalbit® 1 × dsDNA HS Assay Kit (Vazyme Cat. NO. 7E302K9, Nanjing, China).\nThe metagenomic library was constructed using KAPA HyperPlus Kit (KAPA Cat. NO. 0000097583, Boston, USA) with dual-indexed Adapters (KAPA Cat. NO. 0000093370, Boston, USA), the DNA was fragmented to 250 bp approximately by the enzyme at 37 °C for 20 min, after end repair and A-tailing, adapter ligation, post-ligation cleanup, library amplification, and post-amplification cleanup, the library was constructed.\nAgilent 2100 Bioanalyzer (Agilent Technologies, Beijing, China) was used for library quality control, and qualified DNA library was sent to the Novogene company to sequence in HiSeq 4500."
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#quality-control-metrics",
    "href": "notebooks/2024-07-23-mengyi.html#quality-control-metrics",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n1.2 Quality control metrics",
    "text": "1.2 Quality control metrics\nThese 201 samples contained 3.4B read pairs. The samples had 8.2M - 30.1M (mean 17.1M) read pairs each. The number of read pairs and total bases look relatively evenly distributed across the locations. The duplication rate is also quite low, around ~10%. Adapter content is low. As we’d expect, we see higher quality Q scores near the beginning of the read and a gradual decline towards the end of the read, however all positions seem to have a Q score of 35 which means that our reads are ~99.97% accurate. When looking at the Q score over all sequences, we can see a sharp peak after 35, which closely follows the previous plot, indicating high read quality.\n\nCode# Prepare data\nbasic_stats_raw_metrics &lt;- basic_stats_raw %&gt;%\n  select(library,\n         location,\n         `# Read pairs` = n_read_pairs,\n         `Total base pairs\\n(approx)` = n_bases_approx,\n         `% Duplicates\\n(FASTQC)` = percent_duplicates) %&gt;%\n  pivot_longer(-(library:location), names_to = \"metric\", values_to = \"value\") %&gt;%\n  mutate(metric = fct_inorder(metric)) \n\n# Set up plot templates\n\ng_basic &lt;- ggplot(basic_stats_raw_metrics, aes(x = library, y = value, fill=location)) +\n  geom_col(position = \"dodge\") +\n  scale_x_discrete() +\n  scale_fill_brewer(palette = \"Dark2\") +\n  scale_y_continuous(expand = c(0, 0)) +\n  expand_limits(y = c(0, 100)) +\n  facet_grid(metric ~ ., scales = \"free\", space = \"free_x\", switch = \"y\") +\n  theme_kit + theme(\n    axis.title.y = element_blank(),\n    strip.text.y = element_text(face = \"plain\"),\n    axis.text.x = element_blank()\n  )\ng_basic\n\n\n\n\n\n\n\n\nCode# Set up plotting templates\ng_qual_raw &lt;- ggplot(mapping=aes(color = location, linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  scale_color_brewer(palette = \"Dark2\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters_raw &lt;- g_qual_raw + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats_raw) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,5),\n                     expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0)) +\n  facet_grid(.~adapter)\ng_adapters_raw\n\n\n\n\n\n\nCode# Visualize quality\ng_quality_base_raw &lt;- g_qual_raw +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats_raw) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0))\ng_quality_base_raw\n\n\n\n\n\n\nCodeg_quality_seq_raw &lt;- g_qual_raw +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats_raw) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0))\ng_quality_seq_raw"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#summary",
    "href": "notebooks/2024-07-23-mengyi.html#summary",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n2.1 Summary",
    "text": "2.1 Summary\nThe average fraction of reads at each stage in the preprocessing pipeline is shown in the following table. Reads lost during trimming and filtering approximately matches what we’d expect based on the raw adapter content. Deduplication loses us about 10% of reads which matched the amount of estimated duplicated reads by QC. Low ribodepletion is observed which makes sense because they only sequenced DNA.\n\nCode# TODO: Group by pool size as well\n# Count read losses\nn_reads_rel &lt;- basic_stats %&gt;% \n  select(sample,location, stage, percent_duplicates, n_read_pairs) %&gt;%\n  group_by(sample) %&gt;% \n  arrange(sample, stage) %&gt;%\n  mutate(p_reads_retained = n_read_pairs / lag(n_read_pairs),\n         p_reads_lost = 1 - p_reads_retained,\n         p_reads_retained_abs = n_read_pairs / n_read_pairs[1],\n         p_reads_lost_abs = 1-p_reads_retained_abs,\n         p_reads_lost_abs_marginal = p_reads_lost_abs - lag(p_reads_lost_abs))\nn_reads_rel_display &lt;- n_reads_rel %&gt;% \n  rename(Stage=stage) %&gt;% \n  group_by(Stage) %&gt;% \n  summarize(`% Total Reads Lost (Cumulative)` = paste0(round(min(p_reads_lost_abs*100),1), \"-\", round(max(p_reads_lost_abs*100),1), \" (mean \", round(mean(p_reads_lost_abs*100),1), \")\"),\n            `% Total Reads Lost (Marginal)` = paste0(round(min(p_reads_lost_abs_marginal*100),1), \"-\", round(max(p_reads_lost_abs_marginal*100),1), \" (mean \", round(mean(p_reads_lost_abs_marginal*100),1), \")\"), .groups=\"drop\") %&gt;% \n  filter(Stage != \"raw_concat\") %&gt;%\n  mutate(Stage = Stage %&gt;% as.numeric %&gt;% factor(labels=c(\"Trimming & filtering\", \"Deduplication\", \"Initial ribodepletion\", \"Secondary ribodepletion\")))\nn_reads_rel_display"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#quality-control-metrics-1",
    "href": "notebooks/2024-07-23-mengyi.html#quality-control-metrics-1",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n2.2 Quality control metrics",
    "text": "2.2 Quality control metrics\nTrimming and cleaning gets rid of the Illumina adapter as well as polyg, and we see a decrease in polya. Q score remain the same during read cleaning when looking at the positions, with the end of the read actually improving in score. Q scores across all sequences look pretty much the same throughout cleaning.\n\nCodeg_qual &lt;- ggplot(mapping=aes(color = location, linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  scale_color_brewer(palette = \"Dark2\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters &lt;- g_qual + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,5),\n                     expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~adapter)\ng_adapters\n\n\n\n\n\n\nCode# Visualize quality\ng_quality_base &lt;- g_qual +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~.)\ng_quality_base\n\n\n\n\n\n\nCodeg_quality_seq &lt;- g_qual +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0)) +\n  facet_grid(stage~., scales = \"free_y\")\ng_quality_seq\n\n\n\n\n\n\n\nNumber of read pairs look reasonable, same with a large portion being lost during deduplication. At the end of deduplication it seems that only 5% of reads are duplicates which doesn’t seem too bad. Mean read length stays around 150 bp which is pretty good.\n\nCodeg_stage_trace &lt;- ggplot(basic_stats, aes(x=stage, group=sample, color = location)) +\n  theme_kit +\n  scale_color_brewer(palette = \"Dark2\")\n# Plot reads over preprocessing\ng_reads_stages &lt;- g_stage_trace +\n  geom_line(aes(y=n_read_pairs)) +\n  scale_y_continuous(\"# Read pairs\", expand=c(0,0), limits=c(0,NA))\ng_reads_stages\n\n\n\n\n\n\nCode# Plot relative read losses during preprocessing\ng_reads_rel &lt;- ggplot(n_reads_rel, \n                      aes(x=stage, group=sample, color = location)) +\n  geom_line(aes(y=p_reads_lost_abs_marginal)) +\n  scale_y_continuous(\"% Total Reads Lost\", expand=c(0,0), \n                     labels = function(x) x*100) +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme_kit\ng_reads_rel\n\n\n\n\n\n\n\n\nCodestage_dup &lt;- basic_stats %&gt;% group_by(stage) %&gt;% \n  summarize(dmin = min(percent_duplicates), dmax=max(percent_duplicates),\n            dmean=mean(percent_duplicates), .groups = \"drop\")\n\ng_dup_stages &lt;- g_stage_trace +\n  geom_line(aes(y=percent_duplicates)) +\n  scale_y_continuous(\"% Duplicates\", limits=c(0,NA), expand=c(0,0))\ng_dup_stages\n\n\n\n\n\n\n\n\nCodeg_readlen_stages &lt;- g_stage_trace + geom_line(aes(y=mean_seq_len)) +\n  scale_y_continuous(\"Mean read length (nt)\", expand=c(0,0), limits=c(0,NA))\ng_readlen_stages\n\n\n\nReminder that this data is 2x150 bp."
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#high-level-composition",
    "href": "notebooks/2024-07-23-mengyi.html#high-level-composition",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n3.1 High-level composition",
    "text": "3.1 High-level composition\nTo assess the high-level composition of the reads, I ran the files through Kraken2 and summarized the results with Bracken.\nThe groups listed below were created by Will:\n\nFiltered (removed during cleaning)\nDuplicate (removed during deduplication)\nRibosomal (removed during ribodepletion)\nUnassigned (non-ribosomal reads that were not assigned to any taxon by Kraken/Bracken)\nBacterial (non-ribosomal reads assigned to the Bacteria domain by Kraken/Bracken)\nArchaeal (non-ribosomal reads assigned to the Archaea domain by Kraken/Bracken)\nViral (non-ribosomal reads assigned to the Viruses domain by Kraken/Bracken)\nHuman (non-ribosomal reads assigned to the Eukarya domain by Kraken/Bracken)\n\nHuman reads make up a large proportion of all reads at 82% total composition, whereas viruses only account for 0.01% of all reads.\n\nCodeclassifications &lt;- c(\"Filtered\", \"Duplicate\", \"Ribosomal\", \"Unassigned\",\n                     \"Bacterial\", \"Archaeal\", \"Viral\", \"Human\")\n\n# Import composition data\ntax_final_dir &lt;- file.path(results_dir, \"taxonomy_final\")\ncomp &lt;- read_tsv(sprintf(\"%s/taxonomic_composition.tsv.gz\", tax_final_dir)) %&gt;% \n  inner_join(libraries, by='sample')\n\ncomp_minor &lt;- comp %&gt;% \n  filter(classification %in% c(\"Archaeal\", \"Viral\", \"Human\", \"Other\"))\ncomp_assigned &lt;- comp %&gt;%\n  filter(! classification %in% c(\"Filtered\", \"Duplicate\", \n                                 \"Ribosomal\", \"Unassigned\")) %&gt;%\n  group_by(sample) %&gt;%\n  mutate(p_reads = n_reads/sum(n_reads))\ncomp_assigned_minor &lt;- comp_assigned %&gt;% \n  filter(classification %in% c(\"Archaeal\", \"Viral\", \"Human\", \"Other\"))\n\n# Summarize composition\nread_comp_summ &lt;- comp %&gt;% \n  group_by(classification) %&gt;%\n  summarize(n_reads = sum(n_reads), .groups = \"drop_last\") %&gt;%\n  mutate(n_reads = replace_na(n_reads,0),\n         p_reads = n_reads/sum(n_reads),\n         pc_reads = p_reads*100) %&gt;%\n  mutate(classification = factor(classification, levels=classifications)) %&gt;%\n  select(classification, n_reads, pc_reads) %&gt;%\n  rename(`# of reads` = n_reads, \"% of reads\" = pc_reads) %&gt;%\n  mutate(`% of reads` = sprintf(\"%.2f\", `% of reads`))\nread_comp_summ\n\n\n  \n\n\n\n\nCode# Prepare plotting templates\ng_comp_base &lt;- ggplot(mapping=aes(x=library, y=p_reads, fill=classification)) +\n  scale_x_discrete(name=\"Plasma pool\") +\n  theme_kit + \n  theme(plot.title = element_text(hjust=0, face=\"plain\", size=rel(1.5)),\n        axis.text.x = element_blank())\n\nscale_y_pc_reads &lt;- purrr::partial(scale_y_continuous, name = \"% Reads\",\n                                   expand = c(0,0), labels = function(y) y*100)\ngeom_comp &lt;- purrr::partial(geom_col, position = \"stack\", width = 1)\n\n# Define a color palette for the classification\nclassification_colors &lt;- brewer.pal(8, \"Accent\")\nnames(classification_colors) &lt;- c(\"Filtered\", \"Duplicate\", \"Ribosomal\", \"Unassigned\", \"Bacterial\", \"Archaeal\", \"Viral\", \"Human\")\nscale_fill_classification &lt;- function() {\n  scale_fill_manual(values = classification_colors, name = \"Classification\")\n}\n\n# Plot overall composition\ng_comp &lt;- g_comp_base + geom_comp(data = comp) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (all reads, all groups)\")\ng_comp\n\n\n\n\n\n\nCode# Create a faceted plot of composition by location\n#g_comp_by_location &lt;- g_comp_base +\n#  geom_comp(data = comp) +\n#  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n#  scale_fill_classification() +\n#  facet_wrap(~ location, scales = \"free_x\", ncol = 2) +\n#  theme(axis.text.x = element_blank(),  # Remove x-axis labels\n#        axis.ticks.x = element_blank()) +  # Remove x-axis ticks\n#  ggtitle(\"Read composition (all reads, all groups)\")\n\n# Display the plot\n#g_comp_by_location\n\n# Repeat for classified reads only\ng_comp_assigned &lt;- g_comp_base + \n  geom_comp(data = comp_assigned) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (assigned reads, all groups)\")\ng_comp_assigned\n\n\n\n\n\n\nCode# Plot composition of minor components\n#g_comp_minor &lt;- g_comp_base + \n#  geom_comp(data=comp_minor) +\n#  scale_y_pc_reads() +\n#  scale_fill_classification() + \n#  ggtitle(\"Read composition (all reads, minor groups)\")\n#g_comp_minor\n#g_comp_assigned_minor &lt;- g_comp_base + \n#  geom_comp(data=comp_assigned_minor) +\n#  scale_y_pc_reads() +\n#  scale_fill_classification() + \n#  ggtitle(\"Read composition (assigned reads, minor groups)\")\n#g_comp_assigned_minor"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#total-viral-content",
    "href": "notebooks/2024-07-23-mengyi.html#total-viral-content",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n3.2 Total viral content",
    "text": "3.2 Total viral content\nTotal viral fraction average \\(1.03 \\times 10^{-4}\\) across samples. As a fraction of assigned (rather than total) reads, this jumped to \\(1.28 \\times 10^{-4}\\). The increase in viral fraction from assigned reads to total reads was constant across all samples, however, we can see that the viral fractions differed by location. Note that one of the pools from “Heilongjiang,Mudanjiang” had no viral reads.\n\nCode#p_reads_viral_all &lt;- comp %&gt;% filter(classification == \"Viral\") %&gt;%\n#  mutate(read_group = \"All reads\")\np_reads_viral_assigned &lt;- comp_assigned %&gt;% filter(classification == \"Viral\") %&gt;%\n  mutate(read_group = \"Classified reads\")\n#p_reads_viral &lt;- bind_rows(p_reads_viral_all, p_reads_viral_assigned)\n\nlocation_viral &lt;- comp_assigned %&gt;% filter(classification == \"Viral\" ) %&gt;% group_by(location) \n\n# Plot\n# g_viral &lt;- ggplot(p_reads_viral, aes(x=p_reads, y=library, color=location, shape=read_group)) +\n#   geom_point() +\n#   scale_y_discrete(name=\"Plasma pool\") +\n#   scale_x_log10(name=\"Viral read fraction\") +\n#   scale_color_brewer(palette = \"Dark2\") +\n#   #facet_grid(.~read_group, scales = \"free\") +\n#   guides(color=guide_legend(nrow=2), shape=guide_legend(nrow=2),\n#          linetype=guide_legend(nrow=2)) +\n#   theme_kit\n\n#ggplot(location_viral, aes(x=p_reads, y=location, color = location)) +\n#  geom_quasirandom(size=2) +\n#  scale_x_log10(name=\"Viral read fraction\", labels = label_log(digits=2)) +\n#  scale_y_discrete(name=\"Location\") +\n#  scale_color_brewer(palette = \"Dark2\") +\n#  theme_light() + \n#    theme(\n#    axis.text.y = element_text(size = 8),\n#    axis.text.x = element_text(size = 14),\n#    axis.ticks.y = element_blank(),\n#    axis.line = element_line(colour = \"black\"),\n#    axis.title.x = element_text(size = 15),    \n#    axis.title.y = element_text(size = 15),  \n#    legend.text = element_text(size = 13),\n#    legend.title = element_text(size = 16),\n#    legend.position = c(1, 1),  # Move legend to top right\n##    legend.justification = c(1, 1),  # Align legend to top right\n#    panel.grid.minor = element_blank(),\n#    panel.border = element_blank(),\n#    panel.background = element_blank())\n\n# Calculate the number of samples per location\nlocation_counts &lt;- location_viral %&gt;%\n  group_by(location) %&gt;%\n  summarise(count = n()) %&gt;%\n  mutate(label = paste0(location, \" (n=\", count, \")\"))\n\n# Create a named vector for easy mapping\nlocation_labels &lt;- setNames(location_counts$label, location_counts$location)\n\ng_viral &lt;- ggplot(location_viral, aes(x=location, y=p_reads, fill=location)) +\n  geom_violin(trim=FALSE) +\n  geom_boxplot(width=0.1, fill=\"white\", color=\"black\", outlier.shape=NA) +\n  geom_jitter(width=0.1, size=0.5, alpha=0.5) +\n  scale_y_log10(name=\"Viral read fraction\", labels = label_log(digits=2)) +\n  scale_x_discrete(name=\"Location\", labels = location_labels) +\n  scale_fill_brewer(palette = \"Dark2\") +\n  labs(title=\"Total viral fraction based on assigned reads over all locations\") +\n  theme_light() + \n  theme(\n    axis.text.y = element_text(size = 12),\n    axis.text.x = element_text(size = 12, angle = 45, hjust = 1),\n    axis.title.x = element_text(size = 15),    \n    axis.title.y = element_text(size = 15),  \n    legend.position = \"none\",\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank()\n  ) +\n  theme_kit +\n  coord_flip()  # This flips the coordinates to make the plot horizontal\n\ng_viral"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#taxonomic-composition-of-viruses",
    "href": "notebooks/2024-07-23-mengyi.html#taxonomic-composition-of-viruses",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n3.3 Taxonomic composition of viruses",
    "text": "3.3 Taxonomic composition of viruses\nThe threshold for the label “other” are the set of families that make up less than 20% composition in all samples (the only reason I did this was because there were too many matches). We can see that other makes up a big portion of the viral composition. Outside of the “other” label, Hepadnaviridae makes up the largest portion of the viral composition.\n\nCodemajor_threshold &lt;- 0.20\n\n# Identify major viral families\nviral_families_major_tab &lt;- viral_families %&gt;% \n  group_by(name, taxid) %&gt;%\n  summarize(p_reads_viral_max = max(p_reads_viral), .groups=\"drop\") %&gt;%\n  filter(p_reads_viral_max &gt;= major_threshold)\nviral_families_major_list &lt;- viral_families_major_tab %&gt;% pull(name)\nviral_families_major &lt;- viral_families %&gt;% \n  filter(name %in% viral_families_major_list) %&gt;%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_minor &lt;- viral_families_major %&gt;% \n  group_by(sample) %&gt;%\n  summarize(p_reads_viral_major = sum(p_reads_viral), .groups = \"drop\") %&gt;%\n  mutate(name = \"Other\", taxid=NA, p_reads_viral = 1-p_reads_viral_major) %&gt;%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_display &lt;- viral_families_major %&gt;% \n  bind_rows(viral_families_minor) %&gt;%\n  arrange(desc(p_reads_viral)) %&gt;% \n  mutate(name = factor(name, levels=c(viral_families_major_list, \"Other\"))) %&gt;%\n  rename(p_reads = p_reads_viral, classification=name) %&gt;%\n  inner_join(libraries, by='sample')\n\n# Create a custom color palette with up to 20 colors\ncustom_palette &lt;- c(\n  brewer.pal(12, \"Paired\"),\n  brewer.pal(12, \"Set3\")\n)\n\nn_classifications &lt;- length(unique(viral_families_display$classification)) - 1\n\ncustom_palette_with_black &lt;- c(\n  custom_palette[1:n_classifications],\n  \"black\"\n)\n\n# Create a new color palette with black for \"Other\"\ncustom_palette_with_black &lt;- c(\n  custom_palette[1:n_classifications],\n  \"black\"\n)\n\n# Plot\ng_families &lt;- g_comp_base + \n  geom_comp(data=viral_families_display) +\n  scale_y_continuous(name=\"% Viral Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_manual(values = custom_palette_with_black) +\n  facet_wrap(~ location, scales = \"free_x\", ncol = 2) \ng_families"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#overall-relative-abundance",
    "href": "notebooks/2024-07-23-mengyi.html#overall-relative-abundance",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n4.1 Overall relative abundance",
    "text": "4.1 Overall relative abundance\nI calculated the relative abundance of human-infecting viruses in two ways:\n\nFirst, as the total number of deduplicated human-virus reads in each sample, divided by the number of raw reads (“All reads”). This results in a viral fraction of \\(9.84 \\times 10^{-5}\\) across all samples.\nSecond, as a fraction of preprocessed (cleaned, deduplicated, computationally ribodepleted) reads (“Preprocessed reads”). This results in a viral fraction of \\(1.18 \\times 10^{-4}\\) across all samples.\n\nNote that 10 of the pools had no viral reads: 5 from “Heilongjiang, Mudanjiang”, 4 from “Jiangsu, Nanjing”, and 1 from “Xinjiang, Urmqi”.\n\nCode# Get raw read counts\nread_counts_raw &lt;- filter(basic_stats_raw) %&gt;%\n  select(sample, n_reads_raw = n_read_pairs)\nread_counts_preproc &lt;- basic_stats %&gt;% filter(stage == \"ribo_initial\") %&gt;%\n  select(sample, n_reads_preproc = n_read_pairs)\n\n# Get HV read counts\nread_counts_hv &lt;- mrg_hv %&gt;% filter(hv_status) %&gt;% \n  group_by(sample) %&gt;% \n  count(name=\"n_reads_hv\")\nread_counts &lt;- read_counts_raw %&gt;%\n  left_join(read_counts_hv, by=c(\"sample\")) %&gt;%\n  mutate(n_reads_hv = replace_na(n_reads_hv, 0)) %&gt;%\n  left_join(read_counts_preproc, by=c(\"sample\")) %&gt;%\n  inner_join(libraries, by=c(\"sample\")) %&gt;%\n  select(sample, n_reads_raw, n_reads_preproc, n_reads_hv) %&gt;%\n  mutate(n_samples = 1,\n         p_reads_total = n_reads_hv/n_reads_raw,\n         p_reads_preproc = n_reads_hv/n_reads_preproc)\nread_counts_long &lt;- read_counts %&gt;%\n  pivot_longer(starts_with(\"p_reads\"), names_to=\"read_group\", values_to=\"p_reads\") %&gt;%\n  mutate(read_group = ifelse(read_group == \"p_reads_total\", \"All reads\", \"Preprocessed reads\"))\n\n# Combine for display\nread_counts_agg &lt;- read_counts %&gt;%\n  mutate(p_reads_total = n_reads_hv/n_reads_raw,\n         p_reads_preproc = n_reads_hv/n_reads_preproc) %&gt;%\n  inner_join(libraries, by=c(\"sample\"))\nread_counts_agg_long &lt;- read_counts_agg %&gt;%\n  pivot_longer(starts_with(\"p_reads\"), names_to=\"read_group\", values_to=\"p_reads\") %&gt;%\n  mutate(read_group = ifelse(read_group == \"p_reads_total\", \"All reads\", \"Preprocessed reads\")) \n\n# Visualize\n#g_read_counts &lt;- ggplot(read_counts_agg_long, aes(x=library, y=p_reads)) +\n#  geom_point() +\n#  scale_y_log10(name = \"Unique human-viral read fraction\") +\n#  facet_grid(.~read_group, scales = \"free\") +\n#  theme_kit\n#g_read_counts\n\n#g_viral &lt;- ggplot(read_counts_agg_long, aes(x=p_reads, y=library, color=location, shape=read_group)) +\n#  geom_point() +\n#  scale_y_discrete(name=\"Plasma pool\") +\n#  scale_x_log10(name=\"Viral read fraction\") +\n#  scale_color_brewer(palette = \"Dark2\") +\n#  facet_grid(.~read_group, scales = \"free\") +\n#  guides(color=guide_legend(nrow=2), shape=guide_legend(nrow=2),\n#         linetype=guide_legend(nrow=2)) +\n#  theme_kit\n#g_viral\n\nhv_location &lt;- read_counts_agg_long %&gt;% filter(read_group == \"Preprocessed reads\" ) %&gt;% group_by(location) \n\nhv_location_counts &lt;- hv_location %&gt;%\n  group_by(location) %&gt;%\n  summarise(count = n()) %&gt;%\n  mutate(label = paste0(location, \" (n=\", count, \")\"))\n\n  # Create a named vector for easy mapping\nlocation_labels &lt;- setNames(hv_location_counts$label, hv_location_counts$location)\n\n# Create a named vector for easy mapping\n# Plot\n# g_viral &lt;- ggplot(p_reads_viral, aes(x=p_reads, y=library, color=location, shape=read_group)) +\n#   geom_point() +\n#   scale_y_discrete(name=\"Plasma pool\") +\n#   scale_x_log10(name=\"Viral read fraction\") +\n#   scale_color_brewer(palette = \"Dark2\") +\n#   #facet_grid(.~read_group, scales = \"free\") +\n#   guides(color=guide_legend(nrow=2), shape=guide_legend(nrow=2),\n#          linetype=guide_legend(nrow=2)) +\n#   theme_kit\n\n#ggplot(location_viral, aes(x=p_reads, y=location, color = location)) +\n#  geom_quasirandom(size=2) +\n#  scale_x_log10(name=\"Viral read fraction\", labels = label_log(digits=2)) +\n#  scale_y_discrete(name=\"Location\") +\n#  scale_color_brewer(palette = \"Dark2\") +\n#  theme_light() + \n#    theme(\n#    axis.text.y = element_text(size = 8),\n#    axis.text.x = element_text(size = 14),\n#    axis.ticks.y = element_blank(),\n#    axis.line = element_line(colour = \"black\"),\n#    axis.title.x = element_text(size = 15),    \n#    axis.title.y = element_text(size = 15),  \n#    legend.text = element_text(size = 13),\n#    legend.title = element_text(size = 16),\n#    legend.position = c(1, 1),  # Move legend to top right\n##    legend.justification = c(1, 1),  # Align legend to top right\n#    panel.grid.minor = element_blank(),\n#    panel.border = element_blank(),\n#    panel.background = element_blank())\n\ng_viral &lt;- ggplot(hv_location, aes(x=location, y=p_reads, fill=location)) +\n  geom_violin(trim=FALSE) +\n  geom_boxplot(width=0.1, fill=\"white\", color=\"black\", outlier.shape=NA) +\n  geom_jitter(width=0.1, size=0.5, alpha=0.5) +\n  scale_y_log10(name=\"Viral read fraction\", labels = label_log(digits=2)) +\n  scale_x_discrete(name=\"Location\", labels = location_labels) +\n  scale_fill_brewer(palette = \"Dark2\") +\n  theme_light() + \n  theme(\n    axis.text.y = element_text(size = 12),\n    axis.text.x = element_text(size = 12, angle = 45, hjust = 1),\n    axis.title.x = element_text(size = 15),    \n    axis.title.y = element_text(size = 15),  \n    legend.position = \"none\",\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank()\n  ) +\n  theme_kit +\n  coord_flip()  # This flips the coordinates to make the plot horizontal\n\ng_viral"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#overall-taxonomy-and-composition",
    "href": "notebooks/2024-07-23-mengyi.html#overall-taxonomy-and-composition",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n4.2 Overall taxonomy and composition",
    "text": "4.2 Overall taxonomy and composition\nThe two dominant viruses we see are Anellovirdae and Hepadnaviridae, with Parvoviridae . The threshold for the label “other” are the set of families that make up less than 5% composition in all samples.\n\nCodethreshold_major_family &lt;- 0.05\n\n# Count reads for each human-viral family\nhv_family_counts &lt;- hv_reads_family %&gt;% \n  group_by(sample, name, taxid) %&gt;%\n  count(name = \"n_reads_hv\") %&gt;%\n  group_by(sample) %&gt;%\n  mutate(p_reads_hv = n_reads_hv/sum(n_reads_hv))\n\n# Identify high-ranking families and group others\nhv_family_major_tab &lt;- hv_family_counts %&gt;% group_by(name) %&gt;% \n  filter(p_reads_hv == max(p_reads_hv)) %&gt;% filter(row_number() == 1) %&gt;%\n  arrange(desc(p_reads_hv)) %&gt;% filter(p_reads_hv &gt; threshold_major_family)\nhv_family_counts_major &lt;- hv_family_counts %&gt;%\n  mutate(name_display = ifelse(name %in% hv_family_major_tab$name, name, \"Other\")) %&gt;%\n  group_by(sample, name_display) %&gt;%\n  summarize(n_reads_hv = sum(n_reads_hv), p_reads_hv = sum(p_reads_hv), \n            .groups=\"drop\") %&gt;%\n  mutate(name_display = factor(name_display, \n                               levels = c(hv_family_major_tab$name, \"Other\")))\nhv_family_counts_display &lt;- hv_family_counts_major %&gt;%\n  rename(p_reads = p_reads_hv, classification = name_display) %&gt;%\n  inner_join(libraries, by = 'sample')\n\n# Plot\ng_hv_family &lt;- g_comp_base + \n  geom_col(data=hv_family_counts_display, position = \"stack\", width=1) +\n  scale_y_continuous(name=\"% HV Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_brewer(palette = \"Set1\", name = \"Viral family\") +\n\n  labs(title=\"Family composition of human-viral reads\") +\n  guides(fill=guide_legend(ncol=4)) +\n  theme(plot.title = element_text(size=rel(1.4), hjust=0, face=\"plain\")) +  \n  facet_wrap(~ location, scales = \"free_x\", ncol = 2) \ng_hv_family\n\n\n\n\n\n\nCode# Get most prominent families for text\nhv_family_collate &lt;- hv_family_counts %&gt;%\n  group_by(name, taxid) %&gt;% \n  summarize(n_reads_tot = sum(n_reads_hv),\n            p_reads_max = max(p_reads_hv), .groups=\"drop\") %&gt;% \n  arrange(desc(n_reads_tot))\ndisplay_hv_family_collate &lt;- hv_family_collate %&gt;%\n  select(name, n_reads_tot) %&gt;%\n  rename(`Family` = name, `Total number of reads` = n_reads_tot)\ndisplay_hv_family_collate"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#analyzing-specific-families",
    "href": "notebooks/2024-07-23-mengyi.html#analyzing-specific-families",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n4.3 Analyzing specific families",
    "text": "4.3 Analyzing specific families\nWe now investigate the composition of specific families that had more than 5 viral reads. In investigating individual viral families, to avoid distortions from a few rare reads, I restricted myself to samples where that family made up at least 10% of human-viral reads:\n\n4.3.1 Hepadnaviridae (Number of reads: 339,427)\n\nCode# Hepadnaviridae\nplot_viral_family_histogram(taxid_chosen=10404)\n\n\n\n\n\n\n\n\nCode# Hepadnaviridae\nplot_viral_family_composition(taxid_chosen=10404, threshold_major_species = 0.1)\n\n\n\n\n\n\n\n\n4.3.2 Parvoviridae (Number of reads: 17,401)\n\nCode# Parvoviridae\nplot_viral_family_histogram(taxid_chosen=10780)\n\n\n\n\n\n\n\n\nCode# Parvoviridae\nplot_viral_family_composition(taxid_chosen=10780, threshold_major_species = 0.1)\n\n\n\n\n\n\n\n\n4.3.3 Anelloviridae (Number of reads: 3001)\n\nCode# Anelloviridae\nplot_viral_family_histogram(taxid_chosen=687329)\n\n\n\n\n\n\n\n\nCode# Anelloviridae\nplot_viral_family_composition(taxid_chosen=687329, threshold_major_species = 0.1)\n\n\n\n\n\n\n\n\n4.3.4 Orthoherpesviridae (Number of reads: 298)\n\nCode# Orthoherpesviridae\nplot_viral_family_histogram(taxid_chosen=3044472)\n\n\n\n\n\n\n\n\nCode# Orthoherpesviridae\nplot_viral_family_composition(taxid_chosen=3044472, threshold_major_species = 0.1)\n\n\n\n\n\n\n\n\n4.3.5 Retroviridae (Number of reads: 115)\n\nCode# Retroviridae\nplot_viral_family_histogram(taxid_chosen=11632)\n\n\n\n\n\n\n\n\nCode# Retroviridae\nplot_viral_family_composition(taxid_chosen=11632, threshold_major_species = 0.1)\n\n\n\n\n\n\n\n\n4.3.6 Microviridae (Number of reads: 61)\n\nCode# Microviridae\nplot_viral_family_histogram(taxid_chosen=10841)\n\n\n\n\n\n\n\n\nCode# Microviridae\nplot_viral_family_composition(taxid_chosen=10841, threshold_major_species = 0.1)\n\n\n\n\n\n\n\n\n4.3.7 Adenoviridae (Number of reads: 28)\n\nCode# Adenoviridae\nplot_viral_family_histogram(taxid_chosen=10508)\n\n\n\n\n\n\n\n\nCode# Adenoviridae\nplot_viral_family_composition(taxid_chosen=10508, threshold_major_species = 0.1)"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#relative-abundance-of-pathogenic-viruses-of-interest",
    "href": "notebooks/2024-07-23-mengyi.html#relative-abundance-of-pathogenic-viruses-of-interest",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n4.4 Relative abundance of pathogenic viruses of interest",
    "text": "4.4 Relative abundance of pathogenic viruses of interest\nEach dot represents a sample, colored by viral family. The x-axis shows the relative abundance of human-infecting viruses, and the y-axis shows the species.\n\nCodespecies_family &lt;- result %&gt;% select(species, family) %&gt;% rename('name' = 'species')\n\nplay &lt;- hv_species_counts %&gt;% \n  ungroup() %&gt;%\n  inner_join(libraries, by = 'sample') %&gt;%\n  inner_join(species_family, by = 'name') %&gt;%\n  mutate(name = ifelse(name == \"Severe acute respiratory syndrome-related coronavirus\", \"SARS-related coronavirus\", name)) %&gt;%\n  filter(!(family %in% c(\"Anelloviridae\", NA, \"Microviridae\", \"Rhabdoviridae\"))) \n\nadjusted_play &lt;- play %&gt;% \n  group_by(name) %&gt;%\n  mutate(virus_prevalence_num = n_distinct(sample)/n_distinct(libraries),\n         total_reads_hv = sum(n_reads_hv)) %&gt;%\n  ungroup() %&gt;%\n  mutate(name = fct_reorder(name, virus_prevalence_num, .desc=TRUE)) %&gt;% \n  select(name, ra_reads_hv, family, location, virus_prevalence_num, total_reads_hv, n_reads_hv)\n\npal &lt;- c(brewer.pal(8, 'Dark2'),brewer.pal(8, 'Accent'))\n\n#, labels = label_log(digits=2)\n\nra_dot &lt;- ggplot(adjusted_play, aes(x = ra_reads_hv, y=name)) +\n  geom_quasirandom(orientation = 'y', aes(color = family)) +\n  scale_color_manual(values = pal) + \n    scale_x_log10(\n    \"Relative abundance human virus reads\",\n    labels=label_log(digits=3)\n  ) +\n  labs(y =  \"\",\n       color = 'Viral family') + \n  guides(color = guide_legend(ncol=2)) +\n  theme_light() + \n    theme(\n    axis.text.y = element_text(size = 10),\n    axis.text.x = element_text(size = 12),\n    axis.ticks.y = element_blank(),axis.line = element_line(colour = \"black\"),\n    axis.title.x = element_text(size = 14),    \n    legend.text = element_text(size = 10),\n    legend.title = element_text(size = 10, face=\"bold\"),\n    legend.position = 'bottom',\n    #legend.position = c(1, 1),  # Move legend to top right\n    #legend.justification = c(1, 1),  # Align legend to top right\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank())\nra_dot\n\n\n\n\n\n\nCode#  geom_text(aes(label = total_reads_hv, y = name), \n#            x = 1e-9, hjust = 0, vjust = 0.5, size = 3, \n#            check_overlap = TRUE)\n\n\nWe can ask Claude to analyze the pathogenicity of these viruses along with their popular names.\n\n\n\n\n\n\n\nScientific Name\nPopular/Well-known Name\nPathogenicity to Humans\n\n\n\nHuman immunodeficiency virus 1\nHIV-1\nVery High\n\n\nSARS-related coronavirus\nSARS-CoV\nHigh\n\n\nHepatitis B virus\nHBV\nHigh\n\n\nHepacivirus hominis\nHepatitis C virus (HCV)\nHigh\n\n\nSimplexvirus humanalpha1\nHerpes simplex virus 1 (HSV-1)\nModerate to High\n\n\nCytomegalovirus humanbeta5\nHuman cytomegalovirus (HCMV)\nModerate to High\n\n\nLymphocryptovirus humangamma4\nEpstein-Barr virus (EBV)\nModerate\n\n\nHuman mastadenovirus C\nAdenovirus C\nModerate\n\n\nHuman mastadenovirus F\nAdenovirus F\nModerate\n\n\nRoseolovirus humanbeta6a\nHuman herpesvirus 6A (HHV-6A)\nLow to Moderate\n\n\nRoseolovirus humanbeta6b\nHuman herpesvirus 6B (HHV-6B)\nLow to Moderate\n\n\nRoseolovirus humanbeta7\nHuman herpesvirus 7 (HHV-7)\nLow to Moderate\n\n\nRhadinovirus humangamma8\nKaposi’s sarcoma-associated herpesvirus (KSHV)\nLow to Moderate\n\n\nMolluscum contagiosum virus\nMCV\nLow\n\n\nErythroparvovirus primate1\nParvovirus B19\nLow\n\n\nHuman erythrovirus V9\nErythrovirus V9\nLow\n\n\nAlphapapillomavirus 4\nHuman papillomavirus 4 (HPV-4)\nLow\n\n\nBetapolyomavirus hominis\nHuman polyomavirus\nLow\n\n\nDependoparvovirus primate1\nAdeno-associated virus (AAV)\nVery Low\n\n\nMurine leukemia virus\nMLV\nVery Low (not a human pathogen)\n\n\nMurine leukemia-related retroviruses\nMLV-related viruses\nVery Low (not typical human pathogens)\n\n\n\nWe get a variety of pathogenic viruses, none of which are a suprise to see in plasma (other than SARS-CoV which we determined was contamination on twist)."
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#human-infecting-virus-families-genera-and-species",
    "href": "notebooks/2024-07-23-mengyi.html#human-infecting-virus-families-genera-and-species",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n6.1 Human-infecting virus families, genera, and species",
    "text": "6.1 Human-infecting virus families, genera, and species\nTo get a good overview of families, genera, and species, we can look at a Sankey plot where the magnitude of relative abundance, averaged over all samples, is shown in parentheses.\n\nCode# Function to create links\ncreate_links &lt;- function(data) {\n  family_to_genus &lt;- data %&gt;%\n    filter(!is.na(genus)) %&gt;%\n    group_by(family, genus) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = genus)\n  \n  genus_to_species &lt;- data %&gt;%\n    group_by(genus, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = genus, target = species)\n\n  family_to_species &lt;- data %&gt;%\n    filter(is.na(genus)) %&gt;%\n    group_by(family, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = species)\n\n  bind_rows(family_to_genus, genus_to_species, family_to_species) %&gt;%\n    filter(!is.na(source))\n}\n\n# Function to create nodes\ncreate_nodes &lt;- function(links) {\n  data.frame(\n    name = c(links$source, links$target) %&gt;% unique()\n  )\n}\n\n# Function to prepare data for Sankey diagram\nprepare_sankey_data &lt;- function(links, nodes) {\n  links$IDsource &lt;- match(links$source, nodes$name) - 1\n  links$IDtarget &lt;- match(links$target, nodes$name) - 1\n  list(links = links, nodes = nodes)\n}\n\n# Function to create Sankey plot\ncreate_sankey_plot &lt;- function(sankey_data) {\n  sankeyNetwork(\n    Links = sankey_data$links, \n    Nodes = sankey_data$nodes,\n    Source = \"IDsource\", \n    Target = \"IDtarget\",\n    Value = \"value\", \n    NodeID = \"name\",\n    sinksRight = TRUE,\n    nodeWidth = 25,\n    fontSize = 14,\n  )\n}\n\nsave_sankey_as_png &lt;- function(sankey_plot, width = 1000, height = 800) {\n  # Save the plot as an HTML file\n  saveWidget(sankey_plot, sprintf('%s/sankey.html',data_dir))\n}\n\nformat_scientific &lt;- function(x, digits=2) {\n  sapply(x, function(val) {\n    if (is.na(val) || abs(val) &lt; 1e-15) {\n      return(\"0\")\n    } else {\n      exponent &lt;- floor(log10(abs(val)))\n      coef &lt;- val / 10^exponent\n      #return(sprintf(\"%.1f × 10^%d\", round(coef, digits), exponent))\n      # May or may not be smart, just keeping magnitude\n      return(sprintf(\"10^%d\", exponent))\n    }\n  })\n}\n\ndata &lt;- result %&gt;% \n  mutate(across(c(genus_n_reads_tot, genus_ra_reads_tot), ~replace_na(., 0)),\n         genus = ifelse(is.na(genus), \"Unknown Genus\", genus)) %&gt;%\n  mutate(\n  species = paste0(species, sprintf(' (%s)', format_scientific(species_ra_reads_tot))),\n  genus = paste0(genus, sprintf(' (%s)', format_scientific(genus_ra_reads_tot))),\n  family = paste0(family, sprintf(' (%s)', format_scientific(family_ra_reads_tot)))\n)\nlinks &lt;- as.data.frame(create_links(data))\nnodes &lt;- create_nodes(links)\nsankey_data &lt;- prepare_sankey_data(links, nodes)\nsankey &lt;- create_sankey_plot(sankey_data)\n\nsankey"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Harmon’s public notebook",
    "section": "",
    "text": "Blog 3: Pre-analysis\n\n\nCombined whole blood and plasma analysis\n\n\n\n\n\n\n\n\nSep 24, 2024\n\n\nHarmon Bhasin\n\n\n\n\n\n\n\n\n\n\n\n\nWorkflow of Aydillo et al. (2022)\n\n\nWhole blood from US (RNA)\n\n\n\n\n\n\n\n\nSep 19, 2024\n\n\nHarmon Bhasin\n\n\n\n\n\n\n\n\n\n\n\n\nWorkflow of Thompson et al. (2023)\n\n\nIndividual whole blood from US (RNA)\n\n\n\n\n\n\n\n\nSep 12, 2024\n\n\nHarmon Bhasin\n\n\n\n\n\n\n\n\n\n\n\n\nWorkflow of O’Connell et al. (2023)\n\n\nWhole blood from US (RNA)\n\n\n\n\n\n\n\n\nSep 5, 2024\n\n\nHarmon Bhasin\n\n\n\n\n\n\n\n\n\n\n\n\nWorkflow of Mengyi et al. (2023)\n\n\nPooled plasma from China (DNA)\n\n\n\n\n\n\n\n\nJul 23, 2024\n\n\nHarmon Bhasin\n\n\n\n\n\n\n\n\n\n\n\n\nWorkflow of Thijssen et al. (2023)\n\n\nPooled plasma from Iran (DNA + RNA)\n\n\n\n\n\n\n\n\nJul 22, 2024\n\n\nHarmon Bhasin\n\n\n\n\n\n\n\n\n\n\n\n\nWorkflow of Cebria-Mendoza et al. (2021)\n\n\nPooled plasma from Spain (DNA + RNA)\n\n\n\n\n\n\n\n\nJul 8, 2024\n\n\nHarmon Bhasin\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notebooks/2024-07-22-thijssen.html",
    "href": "notebooks/2024-07-22-thijssen.html",
    "title": "Workflow of Thijssen et al. (2023)",
    "section": "",
    "text": "This is another potential study of this series. In this post, I analyze Thijssen 2023, a dataset with 20 pooled samples from 100 healthy individuals in Iran.\nThis notebook uses the MGS Workflow v2.2.1 (note that this is old)."
  },
  {
    "objectID": "notebooks/2024-07-22-thijssen.html#about",
    "href": "notebooks/2024-07-22-thijssen.html#about",
    "title": "Workflow of Thijssen et al. (2023)",
    "section": "\n1.1 About",
    "text": "1.1 About\nThis dataset comprises 20 samples, each derived from plasma pools of 5 people from Iran. In total, 100 healthy individuals contributed to these pools. For each pooled sample, a combined DNA and RNA library preparation was performed, resulting in a single sequencing output that captures both nucleic acid types. This approach provides comprehensive genetic information but precludes separate analysis of DNA and RNA from individual samples.\n\nCode# Import libraries and extract metadata from sample names\nlibraries &lt;- read_csv(libraries_path, show_col_types = FALSE)\nmeta_data &lt;- read_csv('/Users/harmonbhasin/work/securebio/nao-harmon/thijssen2023/preprocessing/SraRunTable.txt') %&gt;%\n  select('Library Name', Run) %&gt;% rename(sample = Run, library = 'Library Name')\nlibraries &lt;- libraries %&gt;%\n  left_join(meta_data, by = 'sample') %&gt;%\n  select(sample, library=library.y) %&gt;% \n  filter(library != 'PCL21') %&gt;%\n  mutate(library = factor(library, levels = c(paste0('PCL', 1:20))))\nlibraries\n\n\n  \n\n\n\n\n1.1.1 Sample + library preparation\nParaphrased from the paper:\n\nStudy was conducted from 2017-2018 in the Boushehr Province, Iran. Participants were recruited in one of the five transfusion clinics located in Boushehr. Seven milliliters of blood were collected from each individual during blood transfusion or donation. Immediately after collection, plasma was separated from the samples and stored at −70 °C.\nInitially, the samples were centrifuged and 100 µL of the supernatant was pooled with five samples per pool. The pooled plasma samples were subjected to an adapted version of the NetoVIR protocol for viral particle enrichment and metagenomic sequencing (more information can be found here). Pooled plasma samples were centrifuged for 3 min at 17,000× g and filtered through 0.8 µm polyether sulphone filters. To remove free-floating nucleic acids, the filtered samples were subjected to a nuclease treatment with a cocktail of 1 µL micrococcal nuclease and 2 µL benzonase for 2 h at 37 °C. Both viral DNA and RNA were extracted and randomly amplified (including primary step of reverse transcription) with the Whole Transcriptome Amplification 2 kit for 20 cycles.\nThe amplification product was purified with the MSB SPIN PCRAPACE kit and prepared for sequencing by using the Nextera XT kit. DNA products were quantified with the Qubit fluorometer, and the High-Sensitivity DNA kit for the Bioanalyzer 2100 was used to determine the average library fragment size. Samples were pooled in equimolar ratios, and paired-end sequencing (2 × 150 bp) was performed on a NextSeq 500 Illumina platform with an average of 10 million reads per sample."
  },
  {
    "objectID": "notebooks/2024-07-22-thijssen.html#quality-control",
    "href": "notebooks/2024-07-22-thijssen.html#quality-control",
    "title": "Workflow of Thijssen et al. (2023)",
    "section": "\n1.2 Quality control",
    "text": "1.2 Quality control\nIn total, these 20 samples contained ~116M read pairs. The samples had 1.3M - 11.1M (mean ~5.8M) read pairs each. The number of reads looks pretty good, although a few samples have a much lower number of reads. Considering the authors used these samples, we’ll use the same. The total number of base pairs also looks reasonable, matching the trends of the number of reads. The duplication rate is low.\n\nCode# Prepare data\nbasic_stats_raw_metrics &lt;- basic_stats_raw %&gt;%\n  select(library,\n         `# Read pairs` = n_read_pairs,\n         `Total base pairs\\n(approx)` = n_bases_approx,\n         `% Duplicates\\n(FASTQC)` = percent_duplicates) %&gt;%\n  pivot_longer(-library, names_to = \"metric\", values_to = \"value\") %&gt;%\n  mutate(metric = fct_inorder(metric)) \n\n# Set up plot templates\n\ng_basic &lt;- ggplot(basic_stats_raw_metrics, aes(x = library, y = value)) +\n  geom_col(position = \"dodge\") +\n  scale_x_discrete() +\n  scale_y_continuous(expand = c(0, 0)) +\n  expand_limits(y = c(0, 100)) +\n  facet_grid(metric ~ ., scales = \"free\", space = \"free_x\", switch = \"y\") +\n  theme_kit + theme(\n    axis.title.y = element_blank(),\n    strip.text.y = element_text(face = \"plain\")\n  )\ng_basic\n\n\n\n\n\n\n\nAdapter content is quite high for nextera-transposase-sequence. I believe this is library contamination, I need to look into this TODO. As we’d expect, we see higher quality Q scores near the beginning of the read and a gradual decline towards the end of the read, however all positions seem to have a Q score of 35 which means that our reads are ~99.97% accurate. When looking at the Q score over all sequences, we can see a sharp peak around 35, which corresponds to the previous plot, indicating high read quality.\n\nCode# Set up plotting templates\ng_qual_raw &lt;- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters_raw &lt;- g_qual_raw + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats_raw) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,NA),\n                     breaks = seq(0,100,10), expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0)) +\n  facet_grid(.~adapter)\ng_adapters_raw\n\n\n\n\n\n\nCode# Visualize quality\ng_quality_base_raw &lt;- g_qual_raw +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats_raw) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0))\ng_quality_base_raw\n\n\n\n\n\n\nCodeg_quality_seq_raw &lt;- g_qual_raw +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats_raw) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0))\ng_quality_seq_raw"
  },
  {
    "objectID": "notebooks/2024-07-22-thijssen.html#high-level-metrics",
    "href": "notebooks/2024-07-22-thijssen.html#high-level-metrics",
    "title": "Workflow of Thijssen et al. (2023)",
    "section": "\n2.1 High-level metrics",
    "text": "2.1 High-level metrics\nThe average fraction of reads at each stage in the preprocessing pipeline is shown in the following table. Adapter trimming & filtering doesn’t lose too many reads. Deduplication loses us about 30% of reads on average, then ribodepletion only loses as about 0.7% on average.\n\nCode# TODO: Group by pool size as well\n# Count read losses\nn_reads_rel &lt;- basic_stats %&gt;% \n  select(sample, stage, percent_duplicates, n_read_pairs) %&gt;%\n  group_by(sample) %&gt;% \n  arrange(sample, stage) %&gt;%\n  mutate(p_reads_retained = n_read_pairs / lag(n_read_pairs),\n         p_reads_lost = 1 - p_reads_retained,\n         p_reads_retained_abs = n_read_pairs / n_read_pairs[1],\n         p_reads_lost_abs = 1-p_reads_retained_abs,\n         p_reads_lost_abs_marginal = p_reads_lost_abs - lag(p_reads_lost_abs))\nn_reads_rel_display &lt;- n_reads_rel %&gt;% \n  rename(Stage=stage) %&gt;% \n  group_by(Stage) %&gt;% \n  summarize(`% Total Reads Lost (Cumulative)` = paste0(round(min(p_reads_lost_abs*100),1), \"-\", round(max(p_reads_lost_abs*100),1), \" (mean \", round(mean(p_reads_lost_abs*100),1), \")\"),\n            `% Total Reads Lost (Marginal)` = paste0(round(min(p_reads_lost_abs_marginal*100),1), \"-\", round(max(p_reads_lost_abs_marginal*100),1), \" (mean \", round(mean(p_reads_lost_abs_marginal*100),1), \")\"), .groups=\"drop\") %&gt;% \n  filter(Stage != \"raw_concat\") %&gt;%\n  mutate(Stage = Stage %&gt;% as.numeric %&gt;% factor(labels=c(\"Trimming & filtering\", \"Deduplication\", \"Initial ribodepletion\", \"Secondary ribodepletion\")))\nn_reads_rel_display\n\n\n  \n\n\n\nThese plots below show the trends from above in each sample.\n\nCodeg_stage_trace &lt;- ggplot(basic_stats, aes(x=stage, group=sample)) +\n  theme_kit\n\n# Plot reads over preprocessing\ng_reads_stages &lt;- g_stage_trace +\n  geom_line(aes(y=n_read_pairs)) +\n  scale_y_continuous(\"# Read pairs\", expand=c(0,0), limits=c(0,NA))\ng_reads_stages\n\n\n\n\n\n\nCode# Plot relative read losses during preprocessing\ng_reads_rel &lt;- ggplot(n_reads_rel, \n                      aes(x=stage, group=sample)) +\n  geom_line(aes(y=p_reads_lost_abs_marginal)) +\n  scale_y_continuous(\"% Total Reads Lost\", expand=c(0,0), \n                     labels = function(x) x*100) +\n  theme_kit\ng_reads_rel\n\n\n\n\n\n\n\nHaven’t spent the time to interpret the adapter stuff as yet. Q score remain the same during read cleaning when looking at the positions, with the end of the read actually improving in score. Q scores across all sequences look pretty much the same throughout cleaning.\n\nCodeg_qual &lt;- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters &lt;- g_qual + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,20),\n                     breaks = seq(0,50,10), expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~adapter)\ng_adapters\n\n\n\n\n\n\nCode# Visualize quality\ng_quality_base &lt;- g_qual +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~.)\ng_quality_base\n\n\n\n\n\n\nCodeg_quality_seq &lt;- g_qual +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0)) +\n  facet_grid(stage~., scales = \"free_y\")\ng_quality_seq\n\n\n\n\n\n\n\nAll samples tend to follow similar trends for deduplication, with a large decrease in read length post adapter trimming.\n\nCodestage_dup &lt;- basic_stats %&gt;% group_by(stage) %&gt;% \n  summarize(dmin = min(percent_duplicates), dmax=max(percent_duplicates),\n            dmean=mean(percent_duplicates), .groups = \"drop\")\n\ng_dup_stages &lt;- g_stage_trace +\n  geom_line(aes(y=percent_duplicates)) +\n  scale_y_continuous(\"% Duplicates\", limits=c(0,NA), expand=c(0,0))\ng_dup_stages\n\n\n\n\n\n\nCodeg_readlen_stages &lt;- g_stage_trace + geom_line(aes(y=mean_seq_len)) +\n  scale_y_continuous(\"Mean read length (nt)\", expand=c(0,0), limits=c(0,NA))\ng_readlen_stages\n\n\n\n\n\n\n\nRibosomal reads were quite low, near 1% for every sample.\n\nCode# Calculate reads lost during ribodepletion (approximation for % ribosomal reads)\nreads_ribo &lt;- n_reads_rel %&gt;% \n  filter(stage %in% c(\"dedup\", \"ribo_secondary\")) %&gt;% \n  group_by(sample) %&gt;% \n  summarize(p_reads_ribo=1-n_read_pairs[2]/n_read_pairs[1], .groups = \"drop\") %&gt;%\n  inner_join(libraries, by = 'sample')\nreads_ribo_summ &lt;- reads_ribo %&gt;%\n  group_by(sample) %&gt;%\n  summarize(min=min(p_reads_ribo), max=max(p_reads_ribo),\n            mean=mean(p_reads_ribo), .groups = \"drop\") %&gt;%\n  inner_join(libraries, by = 'sample')\ng_reads_ribo &lt;- ggplot(reads_ribo, \n                       aes(x=library, y=p_reads_ribo)) +\n  geom_point() + \n  scale_y_continuous(name=\"Approx % ribosomal reads\", limits=c(0,1),\n                     breaks=seq(0,1,0.2), expand=c(0,0), labels = function(y) y*100)+\n  theme_kit\ng_reads_ribo"
  },
  {
    "objectID": "notebooks/2024-07-22-thijssen.html#high-level-composition",
    "href": "notebooks/2024-07-22-thijssen.html#high-level-composition",
    "title": "Workflow of Thijssen et al. (2023)",
    "section": "\n3.1 High-level composition",
    "text": "3.1 High-level composition\nTo assess the high-level composition of the reads, I ran the ribodepleted files through Kraken2 and summarized the results with Bracken.\nThe groups listed below were created by Will:\n\nFiltered (removed during cleaning)\nDuplicate (removed during deduplication)\nRibosomal (removed during ribodepletion)\nUnassigned (non-ribosomal reads that were not assigned to any taxon by Kraken/Bracken)\nBacterial (non-ribosomal reads assigned to the Bacteria domain by Kraken/Bracken)\nArchaeal (non-ribosomal reads assigned to the Archaea domain by Kraken/Bracken)\nViral (non-ribosomal reads assigned to the Viruses domain by Kraken/Bracken)\nHuman (non-ribosomal reads assigned to the Eukarya domain by Kraken/Bracken)\n\n\nCode# Prepare plotting templates\ng_comp_base &lt;- ggplot(mapping=aes(x=library, y=p_reads, fill=classification)) +\n  scale_x_discrete(name=\"Plasma pool\") +\n  theme_kit + \n  theme(plot.title = element_text(hjust=0, face=\"plain\", size=rel(1.5)))\nscale_y_pc_reads &lt;- purrr::partial(scale_y_continuous, name = \"% Reads\",\n                                   expand = c(0,0), labels = function(y) y*100)\ngeom_comp &lt;- purrr::partial(geom_col, position = \"stack\", width = 1)\n\n# Define a color palette for the classification\nclassification_colors &lt;- brewer.pal(8, \"Accent\")\nnames(classification_colors) &lt;- c(\"Filtered\", \"Duplicate\", \"Ribosomal\", \"Unassigned\", \"Bacterial\", \"Archaeal\", \"Viral\", \"Human\")\nscale_fill_classification &lt;- function() {\n  scale_fill_manual(values = classification_colors, name = \"Classification\")\n}\n\n# Plot overall composition\ng_comp &lt;- g_comp_base + geom_comp(data = comp) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (all reads, all groups)\")\ng_comp\n\n\n\n\n\n\nCodeg_comp_assigned &lt;- g_comp_base + \n  geom_comp(data = comp_assigned) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (assigned reads, all groups)\")\ng_comp_assigned"
  },
  {
    "objectID": "notebooks/2024-07-22-thijssen.html#total-viral-content",
    "href": "notebooks/2024-07-22-thijssen.html#total-viral-content",
    "title": "Workflow of Thijssen et al. (2023)",
    "section": "\n3.2 Total viral content",
    "text": "3.2 Total viral content\nTotal viral fraction average \\(2.36 \\times 10^{-4}\\) across samples. As a fraction of assigned (rather than total) reads, this jumped to \\(3.19 \\times 10^{-3}\\):\n\nCodep_reads_viral_all &lt;- comp %&gt;% filter(classification == \"Viral\") %&gt;%\n  mutate(read_group = \"All reads\")\np_reads_viral_assigned &lt;- comp_assigned %&gt;% filter(classification == \"Viral\") %&gt;%\n  mutate(read_group = \"Classified reads\")\np_reads_viral &lt;- bind_rows(p_reads_viral_all, p_reads_viral_assigned)\n\n# Plot\ng_viral &lt;- ggplot(p_reads_viral, aes(x=library, y=p_reads, color = read_group, group = library)) +\n  geom_point(size = 5) +\n  geom_line(color = 'black') +\n  scale_x_discrete(name=\"Plasma pool\") +\n  scale_y_log10(name=\"Viral read fraction\", labels = label_log(digits=2), limits = c(1e-6, 1e-2)) +\n  theme_kit + \n  coord_flip()\n\ng_viral"
  },
  {
    "objectID": "notebooks/2024-07-22-thijssen.html#taxonomic-composition-of-viruses",
    "href": "notebooks/2024-07-22-thijssen.html#taxonomic-composition-of-viruses",
    "title": "Workflow of Thijssen et al. (2023)",
    "section": "\n3.3 Taxonomic composition of viruses",
    "text": "3.3 Taxonomic composition of viruses\nThe two dominant viruses we see are Anellovirdae and Phycodnaviridae. The threshold for the label “other” are the set of families that make up less than 5% composition in all samples.\n\nCodemajor_threshold &lt;- 0.05\n\n# Identify major viral families\nviral_families_major_tab &lt;- viral_families %&gt;% \n  group_by(name, taxid) %&gt;%\n  summarize(p_reads_viral_max = max(p_reads_viral), .groups=\"drop\") %&gt;%\n  filter(p_reads_viral_max &gt;= major_threshold)\nviral_families_major_list &lt;- viral_families_major_tab %&gt;% pull(name)\nviral_families_major &lt;- viral_families %&gt;% \n  filter(name %in% viral_families_major_list) %&gt;%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_minor &lt;- viral_families_major %&gt;% \n  group_by(sample) %&gt;%\n  summarize(p_reads_viral_major = sum(p_reads_viral), .groups = \"drop\") %&gt;%\n  mutate(name = \"Other\", taxid=NA, p_reads_viral = 1-p_reads_viral_major) %&gt;%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_display &lt;- viral_families_major %&gt;% \n  bind_rows(viral_families_minor) %&gt;%\n  arrange(desc(p_reads_viral)) %&gt;% \n  mutate(name = factor(name, levels=c(viral_families_major_list, \"Other\"))) %&gt;%\n  rename(p_reads = p_reads_viral, classification=name) %&gt;%\n  inner_join(libraries, by='sample')\n\n# Plot\ng_families &lt;- g_comp_base + \n  geom_comp(data=viral_families_display) +\n  scale_y_continuous(name=\"% Viral Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_brewer(palette = 'Accent')\ng_families"
  },
  {
    "objectID": "notebooks/2024-07-22-thijssen.html#overall-relative-abundance",
    "href": "notebooks/2024-07-22-thijssen.html#overall-relative-abundance",
    "title": "Workflow of Thijssen et al. (2023)",
    "section": "\n4.1 Overall relative abundance",
    "text": "4.1 Overall relative abundance\nI calculated the relative abundance of human-infecting viruses in two ways:\n\nFirst, as the total number of deduplicated human-virus reads in each sample, divided by the number of raw reads (“All reads”). This results in a viral fraction of \\(1.64 \\times 10^{-4}\\) across all samples\nSecond, as a fraction of preprocessed (cleaned, deduplicated, computationally ribodepleted) reads (“Preprocessed reads”). This results in a viral fraction of \\(2.42 \\times 10^{-4}\\) across all samples.\n\n\nCode# Get raw read counts\nread_counts_raw &lt;- filter(basic_stats_raw) %&gt;%\n  select(sample, n_reads_raw = n_read_pairs)\nread_counts_preproc &lt;- basic_stats %&gt;% filter(stage == \"ribo_initial\") %&gt;%\n  select(sample, n_reads_preproc = n_read_pairs)\n\n# Get HV read counts\nread_counts_hv &lt;- mrg_hv %&gt;% filter(hv_status) %&gt;% \n  group_by(sample) %&gt;% \n  count(name=\"n_reads_hv\")\nread_counts &lt;- read_counts_raw %&gt;%\n  left_join(read_counts_hv, by=c(\"sample\")) %&gt;%\n  mutate(n_reads_hv = replace_na(n_reads_hv, 0)) %&gt;%\n  left_join(read_counts_preproc, by=c(\"sample\")) %&gt;%\n  inner_join(libraries, by=c(\"sample\")) %&gt;%\n  select(sample, n_reads_raw, n_reads_preproc, n_reads_hv) %&gt;%\n  mutate(n_samples = 1,\n         p_reads_total = n_reads_hv/n_reads_raw,\n         p_reads_preproc = n_reads_hv/n_reads_preproc)\nread_counts_long &lt;- read_counts %&gt;%\n  pivot_longer(starts_with(\"p_reads\"), names_to=\"read_group\", values_to=\"p_reads\") %&gt;%\n  mutate(read_group = ifelse(read_group == \"p_reads_total\", \"All reads\", \"Preprocessed reads\"))\n\n# Combine for display\nread_counts_agg &lt;- read_counts %&gt;%\n  mutate(p_reads_total = n_reads_hv/n_reads_raw,\n         p_reads_preproc = n_reads_hv/n_reads_preproc) %&gt;%\n  inner_join(libraries, by=c(\"sample\"))\nread_counts_agg_long &lt;- read_counts_agg %&gt;%\n  pivot_longer(starts_with(\"p_reads\"), names_to=\"read_group\", values_to=\"p_reads\") %&gt;%\n  mutate(read_group = ifelse(read_group == \"p_reads_total\", \"All reads (HV)\", \"Preprocessed reads (HV)\")) \n\n# Visualize\ng_read_counts &lt;- ggplot(read_counts_agg_long, aes(x=library, y=p_reads, color = read_group, group = library)) +\n  geom_point(size = 5) +\n  geom_line(color = 'black') +\n  scale_y_log10(name = \"Unique human-viral read fraction\", labels = label_log(digits=2), limits = c(1e-6, 1e-2)) +\n  theme_kit + \n  coord_flip()\ng_read_counts"
  },
  {
    "objectID": "notebooks/2024-07-22-thijssen.html#overall-taxonomy-and-composition",
    "href": "notebooks/2024-07-22-thijssen.html#overall-taxonomy-and-composition",
    "title": "Workflow of Thijssen et al. (2023)",
    "section": "\n4.2 Overall taxonomy and composition",
    "text": "4.2 Overall taxonomy and composition\nComposition of HV reads was changed from when looking at all viral reads. The two dominant viruses we see are Anellovirdae and Microviridae (bacteriophage). The threshold for the label “other” are the set of families that make up less than 5% composition in all samples.\n\nCodethreshold_major_family &lt;- 0.05\n\n# Count reads for each human-viral family\nhv_family_counts &lt;- hv_reads_family %&gt;% \n  group_by(sample, name, taxid) %&gt;%\n  count(name = \"n_reads_hv\") %&gt;%\n  group_by(sample) %&gt;%\n  mutate(p_reads_hv = n_reads_hv/sum(n_reads_hv))\n\n# Identify high-ranking families and group others\nhv_family_major_tab &lt;- hv_family_counts %&gt;% group_by(name) %&gt;% \n  filter(p_reads_hv == max(p_reads_hv)) %&gt;% filter(row_number() == 1) %&gt;%\n  arrange(desc(p_reads_hv)) %&gt;% filter(p_reads_hv &gt; threshold_major_family)\nhv_family_counts_major &lt;- hv_family_counts %&gt;%\n  mutate(name_display = ifelse(name %in% hv_family_major_tab$name, name, \"Other\")) %&gt;%\n  group_by(sample, name_display) %&gt;%\n  summarize(n_reads_hv = sum(n_reads_hv), p_reads_hv = sum(p_reads_hv), \n            .groups=\"drop\") %&gt;%\n  mutate(name_display = factor(name_display, \n                               levels = c(hv_family_major_tab$name, \"Other\")))\nhv_family_counts_display &lt;- hv_family_counts_major %&gt;%\n  rename(p_reads = p_reads_hv, classification = name_display) %&gt;%\n  inner_join(libraries, by = 'sample')\n\n# Plot\ng_hv_family &lt;- g_comp_base + \n  geom_col(data=hv_family_counts_display, position = \"stack\", width=1) +\n  scale_y_continuous(name=\"% HV Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_brewer(palette = 'Accent', name = \"Viral family\") +\n  labs(title=\"Family composition of human-viral reads\") +\n  guides(fill=guide_legend(ncol=4)) +\n  theme(plot.title = element_text(size=rel(1.4), hjust=0, face=\"plain\"))\ng_hv_family\n\n\n\n\n\n\nCode# Get most prominent families for text\nhv_family_collate &lt;- hv_family_counts %&gt;%\n  group_by(name, taxid) %&gt;% \n  summarize(n_reads_tot = sum(n_reads_hv),\n            p_reads_max = max(p_reads_hv), .groups=\"drop\") %&gt;% \n  arrange(desc(n_reads_tot))\nhv_family_collate %&gt;%\n select(name,taxid, n_reads_tot) %&gt;%\n rename(\n  'family' = 'name',\n  '# of total reads' = 'n_reads_tot',\n)"
  },
  {
    "objectID": "notebooks/2024-07-22-thijssen.html#species-analysis",
    "href": "notebooks/2024-07-22-thijssen.html#species-analysis",
    "title": "Workflow of Thijssen et al. (2023)",
    "section": "\n4.3 Species analysis",
    "text": "4.3 Species analysis\nTo get a good overview of families, genera, and species, we can look at a Sankey plot where the magnitude of relative abundance, averaged over all samples, is shown in parentheses.\n\nCode# Function to create links\ncreate_links &lt;- function(data) {\n  family_to_genus &lt;- data %&gt;%\n    filter(!is.na(genus)) %&gt;%\n    group_by(family, genus) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = genus)\n  \n  genus_to_species &lt;- data %&gt;%\n    group_by(genus, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = genus, target = species)\n\n  family_to_species &lt;- data %&gt;%\n    filter(is.na(genus)) %&gt;%\n    group_by(family, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = species)\n\n  bind_rows(family_to_genus, genus_to_species, family_to_species) %&gt;%\n    filter(!is.na(source))\n}\n\n# Function to create nodes\ncreate_nodes &lt;- function(links) {\n  data.frame(\n    name = c(links$source, links$target) %&gt;% unique()\n  )\n}\n\n# Function to prepare data for Sankey diagram\nprepare_sankey_data &lt;- function(links, nodes) {\n  links$IDsource &lt;- match(links$source, nodes$name) - 1\n  links$IDtarget &lt;- match(links$target, nodes$name) - 1\n  list(links = links, nodes = nodes)\n}\n\n# Function to create Sankey plot\ncreate_sankey_plot &lt;- function(sankey_data) {\n  sankeyNetwork(\n    Links = sankey_data$links, \n    Nodes = sankey_data$nodes,\n    Source = \"IDsource\", \n    Target = \"IDtarget\",\n    Value = \"value\", \n    NodeID = \"name\",\n    sinksRight = TRUE,\n    nodeWidth = 25,\n    fontSize = 14,\n  )\n}\n\nsave_sankey_as_png &lt;- function(sankey_plot, width = 1000, height = 800) {\n  # Save the plot as an HTML file\n  saveWidget(sankey_plot, sprintf('%s/sankey.html',data_dir))\n}\n\nformat_scientific &lt;- function(x, digits=2) {\n  sapply(x, function(val) {\n    if (is.na(val) || abs(val) &lt; 1e-15) {\n      return(\"0\")\n    } else {\n      exponent &lt;- floor(log10(abs(val)))\n      coef &lt;- val / 10^exponent\n      #return(sprintf(\"%.1f × 10^%d\", round(coef, digits), exponent))\n      # May or may not be smart, just keeping magnitude\n      return(sprintf(\"10^%d\", exponent))\n    }\n  })\n}\n\ndata &lt;- result %&gt;% \n  mutate(across(c(genus_n_reads_tot, genus_ra_reads_tot), ~replace_na(., 0)),\n         genus = ifelse(is.na(genus), \"Unknown Genus\", genus)) %&gt;%\n  mutate(\n  species = paste0(species, sprintf(' (%s)', format_scientific(species_ra_reads_tot))),\n  genus = paste0(genus, sprintf(' (%s)', format_scientific(genus_ra_reads_tot))),\n  family = paste0(family, sprintf(' (%s)', format_scientific(family_ra_reads_tot)))\n)\nlinks &lt;- as.data.frame(create_links(data))\nnodes &lt;- create_nodes(links)\nsankey_data &lt;- prepare_sankey_data(links, nodes)\nsankey &lt;- create_sankey_plot(sankey_data)\n\nsankey\n\n\n\n\n\nTo get a better idea of the relative abundance of species, we can create a dot plot where each dot represents the relative abundance of a particular species in a sample.\n\nCodespecies_family &lt;- result %&gt;% select(species, family) %&gt;% rename('name' = 'species')\n\nplay &lt;- hv_species_counts %&gt;% \n  ungroup() %&gt;%\n  inner_join(libraries, by = 'sample') %&gt;%\n  inner_join(species_family, by = 'name')\n\nplay$family &lt;- factor(play$family, levels=hv_family_collate %&gt;% pull(family))\nplay &lt;- play %&gt;%\n  arrange(family, name) %&gt;%\n  mutate(name = factor(name, levels = unique(name)))\n#name_order &lt;- play %&gt;% arrange(family) %&gt;% pull(name)\n#play$name &lt;- factor(play$name, levels = name_order)\n\npal &lt;- c(brewer.pal(8, 'Dark2'),brewer.pal(8, 'Accent'))\n\nra_dot &lt;- ggplot(play, aes(x = ra_reads_hv, y=name)) +\n  geom_quasirandom(orientation = 'y', aes(color = family)) +\n  scale_color_manual(values = pal) + \n    scale_x_log10(\n    \"Relative abundance human virus reads\",\n    labels = function(x) parse(text = paste0(\"10^\", round(log10(x)))),\n    limits = c(1e-7, 1),\n    n.breaks = 8\n  ) +\n  labs(y = 'Human virus',\n       color = 'Viral family') + \n  theme_light() + \n    theme(\n    axis.text.y = element_text(size = 8),\n    axis.text.x = element_text(size = 14),\n    axis.ticks.y = element_blank(),axis.line = element_line(colour = \"black\"),\n    axis.title.x = element_text(size = 15),    \n    axis.title.y = element_text(size = 15),  \n    legend.text = element_text(size = 13),\n    legend.title = element_text(size = 16),\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank())\nra_dot\n\n\n\n\n\n\n\nWe now exclude Anelloviridae from the plot.\n\nCodeplay_special &lt;- play %&gt;% filter(family != 'Anelloviridae')\n\npal &lt;- c(brewer.pal(8, 'Dark2'),brewer.pal(8, 'Accent'))\n\nra_dot &lt;- ggplot(play_special, aes(x = ra_reads_hv, y=name)) +\n  geom_quasirandom(orientation = 'y', aes(color = family)) +\n  scale_color_manual(values = pal) + \n    scale_x_log10(\n    \"Relative abundance human virus reads\",\n    labels = function(x) parse(text = paste0(\"10^\", round(log10(x)))),\n    limits = c(1e-7, 1),\n    n.breaks = 8\n  ) +\n  labs(y = 'Human virus',\n       color = 'Viral family') + \n  theme_light() + \n    theme(\n    axis.text.y = element_text(size = 8),\n    axis.text.x = element_text(size = 14),\n    axis.ticks.y = element_blank(),axis.line = element_line(colour = \"black\"),\n    axis.title.x = element_text(size = 15),    \n    axis.title.y = element_text(size = 15),  \n    legend.text = element_text(size = 13),\n    legend.title = element_text(size = 16),\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank())\nra_dot\n\n\n\n\n\n\n\nI can then take all of the viruses that we found and look up what they’re responsible for and whether they’re dangerous.\n\n\n\n\n\n\n\nVirus Name\nCommon Name\nPathogenic Potential\n\n\n\nRotavirus A\nRotavirus\nHigh, causes severe diarrhea in children\n\n\nEnterovirus C\nIncludes poliovirus and some coxsackieviruses\nHigh, can cause various diseases including polio\n\n\nSevere acute respiratory syndrome-related coronavirus\nSARS coronavirus\nHigh, causes severe respiratory illness\n\n\nSapporo virus\nSapporo virus or Sapovirus\nModerate, causes gastroenteritis\n\n\nHuman mastadenovirus F\nAdenovirus F\nModerate, can cause gastroenteritis\n\n\nAlphapolyomavirus quintihominis\nNot widely known\nLow, but some polyomaviruses can cause disease in immunocompromised individuals\n\n\nAlphapapillomavirus 4\nHuman papillomavirus (HPV) type 4\nLow to moderate, can cause warts\n\n\nGokushovirus WZ-2015a\nNot widely known\nLow, typically infects bacteria\n\n\nHuman gut gokushovirus\nNot widely known\nLow, typically infects bacteria in human gut\n\n\nMicroviridae sp.\nNot widely known\nLow, typically infects bacteria\n\n\nMicrovirus sp.\nNot widely known\nLow, typically infects bacteria\n\n\nAmbidensovirus sp.\nNot widely known\nLow for humans, can be pathogenic to insects\n\n\nDependoparvovirus primate1\nAdeno-associated virus (AAV)\nLow, not known to cause disease in humans\n\n\nVaccinia virus\nVaccinia virus\nLow to moderate, used as smallpox vaccine\n\n\nCrAssphage ZA\nNot widely known\nLow, typically infects bacteria in human gut\n\n\nInovirus D_HF3_19\nNot widely known\nLow, typically infects bacteria\n\n\nInovirus D_HF5_49\nNot widely known\nLow, typically infects bacteria\n\n\nCardiovirus D\nNot widely known\nUnknown, some cardioviruses can cause disease in animals\n\n\nCosavirus A\nNot widely known\nUnknown, potentially associated with gastroenteritis\n\n\n\nI’ve ordered these from pathogenic potential to not. We do get coronavirus, however when we look up the taxid on NCBI, we get the following which seems to be an id for general corona and not SARS-CoV-2.\nI’d like to BLAST some of these reads against the NCBI nt database to see if we can get some more info on them."
  },
  {
    "objectID": "notebooks/2024-07-22-thijssen.html#quality-control-metrics",
    "href": "notebooks/2024-07-22-thijssen.html#quality-control-metrics",
    "title": "Workflow of Thijssen et al. (2023)",
    "section": "\n1.2 Quality control metrics",
    "text": "1.2 Quality control metrics\nIn total, these 20 samples contained ~116M read pairs. The samples had 1.3M - 11.1M (mean ~5.8M) read pairs each.\nThe number of reads looks pretty good, although a few samples have a much lower number of reads. The total number of base pairs also looks reasonable, matching the trends of the number of reads. The duplication rate is low. Adapter content is quite high for nextera-transposase-sequence (library contamination).\nAs we’d expect, we see higher quality Q scores near the beginning of the read and a gradual decline towards the end of the read, however all positions seem to have a Q score of 35 which means that our reads are ~99.97% accurate. When looking at the Q score over all sequences, we can see a sharp peak around 35, which corresponds to the previous plot, indicating high read quality.\n\nCode# Prepare data\nbasic_stats_raw_metrics &lt;- basic_stats_raw %&gt;%\n  select(library,\n         `# Read pairs` = n_read_pairs,\n         `Total base pairs\\n(approx)` = n_bases_approx,\n         `% Duplicates\\n(FASTQC)` = percent_duplicates) %&gt;%\n  pivot_longer(-library, names_to = \"metric\", values_to = \"value\") %&gt;%\n  mutate(metric = fct_inorder(metric)) \n\n# Set up plot templates\n\ng_basic &lt;- ggplot(basic_stats_raw_metrics, aes(x = library, y = value)) +\n  geom_col(position = \"dodge\") +\n  scale_x_discrete() +\n  scale_y_continuous(expand = c(0, 0)) +\n  expand_limits(y = c(0, 100)) +\n  facet_grid(metric ~ ., scales = \"free\", space = \"free_x\", switch = \"y\") +\n  theme_kit + theme(\n    axis.title.y = element_blank(),\n    strip.text.y = element_text(face = \"plain\")\n  )\ng_basic\n\n\n\n\n\n\n\n\nCode# Set up plotting templates\ng_qual_raw &lt;- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters_raw &lt;- g_qual_raw + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats_raw) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,NA),\n                     breaks = seq(0,100,10), expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0)) +\n  facet_grid(.~adapter)\ng_adapters_raw\n\n\n\n\n\n\nCode# Visualize quality\ng_quality_base_raw &lt;- g_qual_raw +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats_raw) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0))\ng_quality_base_raw\n\n\n\n\n\n\nCodeg_quality_seq_raw &lt;- g_qual_raw +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats_raw) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0))\ng_quality_seq_raw"
  },
  {
    "objectID": "notebooks/2024-07-22-thijssen.html#summary",
    "href": "notebooks/2024-07-22-thijssen.html#summary",
    "title": "Workflow of Thijssen et al. (2023)",
    "section": "\n2.1 Summary",
    "text": "2.1 Summary\nThe average fraction of reads at each stage in the preprocessing pipeline is shown in the following table. Adapter trimming & filtering doesn’t lose too many reads. Deduplication loses us about 30% of reads on average, then ribodepletion only loses as about 0.7% on average.\n\nCode# TODO: Group by pool size as well\n# Count read losses\nn_reads_rel &lt;- basic_stats %&gt;% \n  select(sample, stage, percent_duplicates, n_read_pairs) %&gt;%\n  group_by(sample) %&gt;% \n  arrange(sample, stage) %&gt;%\n  mutate(p_reads_retained = n_read_pairs / lag(n_read_pairs),\n         p_reads_lost = 1 - p_reads_retained,\n         p_reads_retained_abs = n_read_pairs / n_read_pairs[1],\n         p_reads_lost_abs = 1-p_reads_retained_abs,\n         p_reads_lost_abs_marginal = p_reads_lost_abs - lag(p_reads_lost_abs))\nn_reads_rel_display &lt;- n_reads_rel %&gt;% \n  rename(Stage=stage) %&gt;% \n  group_by(Stage) %&gt;% \n  summarize(`% Total Reads Lost (Cumulative)` = paste0(round(min(p_reads_lost_abs*100),1), \"-\", round(max(p_reads_lost_abs*100),1), \" (mean \", round(mean(p_reads_lost_abs*100),1), \")\"),\n            `% Total Reads Lost (Marginal)` = paste0(round(min(p_reads_lost_abs_marginal*100),1), \"-\", round(max(p_reads_lost_abs_marginal*100),1), \" (mean \", round(mean(p_reads_lost_abs_marginal*100),1), \")\"), .groups=\"drop\") %&gt;% \n  filter(Stage != \"raw_concat\") %&gt;%\n  mutate(Stage = Stage %&gt;% as.numeric %&gt;% factor(labels=c(\"Trimming & filtering\", \"Deduplication\", \"Initial ribodepletion\", \"Secondary ribodepletion\")))\nn_reads_rel_display"
  },
  {
    "objectID": "notebooks/2024-07-22-thijssen.html#quality-control-metrics-1",
    "href": "notebooks/2024-07-22-thijssen.html#quality-control-metrics-1",
    "title": "Workflow of Thijssen et al. (2023)",
    "section": "\n2.2 Quality control metrics",
    "text": "2.2 Quality control metrics\nAdapter trimming gets rid of nextera_transposase_sequenece and poly_g, although there is still a bit of poly_a adapter contamination (overivew of fastqc adapters). Not sure how to interpret the poly_a contamination, but it’s not that high so I’m not going to worry about it for now. Q score remain the same during read cleaning when looking at the positions, with the end of the read actually improving in score. Q scores across all sequences look pretty much the same throughout cleaning.\n\nCodeg_qual &lt;- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters &lt;- g_qual + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,20),\n                     breaks = seq(0,50,10), expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~adapter)\ng_adapters\n\n\n\n\n\n\nCode# Visualize quality\ng_quality_base &lt;- g_qual +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~.)\ng_quality_base\n\n\n\n\n\n\nCodeg_quality_seq &lt;- g_qual +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0)) +\n  facet_grid(stage~., scales = \"free_y\")\ng_quality_seq\n\n\n\n\n\n\n\nThese plots below show the trends from above in each sample. All samples tend to follow similar trends for deduplication, with a large decrease in read length post adapter trimming. Ribosomal reads were quite low, near 1% for every sample.\n\nCodeg_stage_trace &lt;- ggplot(basic_stats, aes(x=stage, group=sample)) +\n  theme_kit\n\n# Plot reads over preprocessing\ng_reads_stages &lt;- g_stage_trace +\n  geom_line(aes(y=n_read_pairs)) +\n  scale_y_continuous(\"# Read pairs\", expand=c(0,0), limits=c(0,NA))\ng_reads_stages\n\n\n\n\n\n\nCode# Plot relative read losses during preprocessing\ng_reads_rel &lt;- ggplot(n_reads_rel, \n                      aes(x=stage, group=sample)) +\n  geom_line(aes(y=p_reads_lost_abs_marginal)) +\n  scale_y_continuous(\"% Total Reads Lost\", expand=c(0,0), \n                     labels = function(x) x*100) +\n  theme_kit\ng_reads_rel\n\n\n\n\n\n\n\n\nCodestage_dup &lt;- basic_stats %&gt;% group_by(stage) %&gt;% \n  summarize(dmin = min(percent_duplicates), dmax=max(percent_duplicates),\n            dmean=mean(percent_duplicates), .groups = \"drop\")\n\ng_dup_stages &lt;- g_stage_trace +\n  geom_line(aes(y=percent_duplicates)) +\n  scale_y_continuous(\"% Duplicates\", limits=c(0,NA), expand=c(0,0))\ng_dup_stages\n\n\n\n\n\n\nCodeg_readlen_stages &lt;- g_stage_trace + geom_line(aes(y=mean_seq_len)) +\n  scale_y_continuous(\"Mean read length (nt)\", expand=c(0,0), limits=c(0,NA))\ng_readlen_stages\n\n\n\n\n\n\n\n\nCode# Calculate reads lost during ribodepletion (approximation for % ribosomal reads)\nreads_ribo &lt;- n_reads_rel %&gt;% \n  filter(stage %in% c(\"dedup\", \"ribo_secondary\")) %&gt;% \n  group_by(sample) %&gt;% \n  summarize(p_reads_ribo=1-n_read_pairs[2]/n_read_pairs[1], .groups = \"drop\") %&gt;%\n  inner_join(libraries, by = 'sample')\nreads_ribo_summ &lt;- reads_ribo %&gt;%\n  group_by(sample) %&gt;%\n  summarize(min=min(p_reads_ribo), max=max(p_reads_ribo),\n            mean=mean(p_reads_ribo), .groups = \"drop\") %&gt;%\n  inner_join(libraries, by = 'sample')\ng_reads_ribo &lt;- ggplot(reads_ribo, \n                       aes(x=library, y=p_reads_ribo)) +\n  geom_point() + \n  scale_y_continuous(name=\"Approx % ribosomal reads\", limits=c(0,1),\n                     breaks=seq(0,1,0.2), expand=c(0,0), labels = function(y) y*100)+\n  theme_kit\ng_reads_ribo"
  },
  {
    "objectID": "notebooks/2024-07-22-thijssen.html#analyzing-specific-families",
    "href": "notebooks/2024-07-22-thijssen.html#analyzing-specific-families",
    "title": "Workflow of Thijssen et al. (2023)",
    "section": "\n4.3 Analyzing specific families",
    "text": "4.3 Analyzing specific families\nWe now investigate the composition of specific families that had more than 5 viral reads. In investigating individual viral families, to avoid distortions from a few rare reads, I restricted myself to samples where that family made up at least 1% of human-viral reads:\n\n4.3.1 Anelloviridae (Number of reads: 12,804)\n\nCode# Anelloviridae\nplot_viral_family_histogram(taxid_chosen=687329)\n\n\n\n\n\n\n\n\nCode# Anelloviridae\nplot_viral_family_composition(taxid_chosen=687329, threshold_major_species = 0.01)\n\n\n\n\n\n\n\n\n4.3.2 Microviridae (Number of reads: 5,194)\n\nCode# Microviridae\nplot_viral_family_histogram(taxid_chosen=10841)\n\n\n\n\n\n\n\n\nCode# Microviridae\nplot_viral_family_composition(taxid_chosen=10841, threshold_major_species = 0.01)\n\n\n\n\n\n\n\n\n4.3.3 Sedreoviridae (Number of reads: 278)\n\nCode# Sedreoviridae\nplot_viral_family_histogram(taxid_chosen=2946186)\n\n\n\n\n\n\n\n\nCode# Sedreoviridae\nplot_viral_family_composition(taxid_chosen=2946186, threshold_major_species = 0.01)\n\n\n\n\n\n\n\n\n4.3.4 Parvoviridae (Number of reads: 266)\n\nCode# Parvoviridae\nplot_viral_family_histogram(taxid_chosen=10780)\n\n\n\n\n\n\n\n\nCode# Parvoviridae\nplot_viral_family_composition(taxid_chosen=10780, threshold_major_species = 0.01)\n\n\n\n\n\n\n\n\n4.3.5 Adenoviridae (Number of reads: 104)\n\nCode# Adenoviridae\nplot_viral_family_histogram(taxid_chosen=10508)\n\n\n\n\n\n\n\nNone of these reads made up more than 1% of the total reads of any sample.\n\n4.3.6 Polyomaviridae (Number of reads: 95)\n\nCode# Polyomaviridae\nplot_viral_family_histogram(taxid_chosen=151341)\n\n\n\n\n\n\n\nNone of these reads made up more than 1% of the total reads of any sample.\n\n4.3.7 Papillomaviridae (Number of reads: 16)\n\nCode# Polyomaviridae\nplot_viral_family_histogram(taxid_chosen=151340)\n\n\n\n\n\n\n\nNone of these reads made up more than 1% of the total reads of any sample."
  },
  {
    "objectID": "notebooks/2024-07-22-thijssen.html#human-infecting-virus-families-genera-and-species",
    "href": "notebooks/2024-07-22-thijssen.html#human-infecting-virus-families-genera-and-species",
    "title": "Workflow of Thijssen et al. (2023)",
    "section": "\n6.1 Human-infecting virus families, genera, and species",
    "text": "6.1 Human-infecting virus families, genera, and species\nTo get a good overview of families, genera, and species, we can look at a Sankey plot where the magnitude of relative abundance, averaged over all samples, is shown in parentheses.\n\nCode# Function to create links\ncreate_links &lt;- function(data) {\n  family_to_genus &lt;- data %&gt;%\n    filter(!is.na(genus)) %&gt;%\n    group_by(family, genus) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = genus)\n  \n  genus_to_species &lt;- data %&gt;%\n    group_by(genus, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = genus, target = species)\n\n  family_to_species &lt;- data %&gt;%\n    filter(is.na(genus)) %&gt;%\n    group_by(family, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = species)\n\n  bind_rows(family_to_genus, genus_to_species, family_to_species) %&gt;%\n    filter(!is.na(source))\n}\n\n# Function to create nodes\ncreate_nodes &lt;- function(links) {\n  data.frame(\n    name = c(links$source, links$target) %&gt;% unique()\n  )\n}\n\n# Function to prepare data for Sankey diagram\nprepare_sankey_data &lt;- function(links, nodes) {\n  links$IDsource &lt;- match(links$source, nodes$name) - 1\n  links$IDtarget &lt;- match(links$target, nodes$name) - 1\n  list(links = links, nodes = nodes)\n}\n\n# Function to create Sankey plot\ncreate_sankey_plot &lt;- function(sankey_data) {\n  sankeyNetwork(\n    Links = sankey_data$links, \n    Nodes = sankey_data$nodes,\n    Source = \"IDsource\", \n    Target = \"IDtarget\",\n    Value = \"value\", \n    NodeID = \"name\",\n    sinksRight = TRUE,\n    nodeWidth = 25,\n    fontSize = 14,\n  )\n}\n\nsave_sankey_as_png &lt;- function(sankey_plot, width = 1000, height = 800) {\n  # Save the plot as an HTML file\n  saveWidget(sankey_plot, sprintf('%s/sankey.html',data_dir))\n}\n\nformat_scientific &lt;- function(x, digits=2) {\n  sapply(x, function(val) {\n    if (is.na(val) || abs(val) &lt; 1e-15) {\n      return(\"0\")\n    } else {\n      exponent &lt;- floor(log10(abs(val)))\n      coef &lt;- val / 10^exponent\n      #return(sprintf(\"%.1f × 10^%d\", round(coef, digits), exponent))\n      # May or may not be smart, just keeping magnitude\n      return(sprintf(\"10^%d\", exponent))\n    }\n  })\n}\n\ndata &lt;- result %&gt;% \n  mutate(across(c(genus_n_reads_tot, genus_ra_reads_tot), ~replace_na(., 0)),\n         genus = ifelse(is.na(genus), \"Unknown Genus\", genus)) %&gt;%\n  mutate(\n  species = paste0(species, sprintf(' (%s)', format_scientific(species_ra_reads_tot))),\n  genus = paste0(genus, sprintf(' (%s)', format_scientific(genus_ra_reads_tot))),\n  family = paste0(family, sprintf(' (%s)', format_scientific(family_ra_reads_tot)))\n)\nlinks &lt;- as.data.frame(create_links(data))\nnodes &lt;- create_nodes(links)\nsankey_data &lt;- prepare_sankey_data(links, nodes)\nsankey &lt;- create_sankey_plot(sankey_data)\n\nsankey"
  },
  {
    "objectID": "notebooks/2024-07-22-thijssen.html#relative-abundance-of-pathogenic-viruses-of-interest",
    "href": "notebooks/2024-07-22-thijssen.html#relative-abundance-of-pathogenic-viruses-of-interest",
    "title": "Workflow of Thijssen et al. (2023)",
    "section": "\n4.4 Relative abundance of pathogenic viruses of interest",
    "text": "4.4 Relative abundance of pathogenic viruses of interest\nEach dot represents a sample, colored by viral family. The x-axis shows the relative abundance of human-infecting viruses, and the y-axis shows the species.\n\nCodespecies_family &lt;- result %&gt;% select(species, family) %&gt;% rename('name' = 'species')\n\nplay &lt;- hv_species_counts %&gt;% \n  ungroup() %&gt;%\n  inner_join(libraries, by = 'sample') %&gt;%\n  inner_join(species_family, by = 'name') %&gt;%\n  mutate(name = ifelse(name == \"Severe acute respiratory syndrome-related coronavirus\", \"SARS-related coronavirus\", name)) %&gt;%\n  filter(family %in% c(\"Sedoreoviridae\", \"Parvoviridae\", \"Adenoviridae\", \"Papillomaviridae\", \"Polyomaviridae\", \"Coronaviridae\", \"Caliciviridae\", \"Picornaviridae\")) \n\nadjusted_play &lt;- play %&gt;% \n  group_by(name) %&gt;%\n  mutate(virus_prevalence_num = n_distinct(sample)/n_distinct(libraries),\n         total_reads_hv = sum(n_reads_hv)) %&gt;%\n  ungroup() %&gt;%\n  mutate(name = fct_reorder(name, virus_prevalence_num, .desc=TRUE)) %&gt;% \n  select(name, ra_reads_hv, family, virus_prevalence_num, total_reads_hv, n_reads_hv)\n\npal &lt;- c(brewer.pal(8, 'Dark2'),brewer.pal(8, 'Accent'))\n\n#, labels = label_log(digits=2)\n\nra_dot &lt;- ggplot(adjusted_play, aes(x = ra_reads_hv, y=name)) +\n  geom_quasirandom(orientation = 'y', aes(color = family)) +\n  scale_color_manual(values = pal) + \n    scale_x_log10(\n    \"Relative abundance human virus reads\",\n    labels=label_log(digits=3)\n  ) +\n  labs(y =  \"\",\n       color = 'Viral family') + \n  guides(color = guide_legend(ncol=2)) +\n  theme_light() + \n    theme(\n    axis.text.y = element_text(size = 10),\n    axis.text.x = element_text(size = 12),\n    axis.ticks.y = element_blank(),axis.line = element_line(colour = \"black\"),\n    axis.title.x = element_text(size = 14),    \n    legend.text = element_text(size = 10),\n    legend.title = element_text(size = 10, face=\"bold\"),\n    #legend.position = 'bottom',\n    legend.position = c(1, 1),  # Move legend to top right\n    legend.justification = c(1, 1),  # Align legend to top right\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank())\nra_dot\n\n\n\n\n\n\nCode#  geom_text(aes(label = total_reads_hv, y = name), \n#            x = 1e-9, hjust = 0, vjust = 0.5, size = 3, \n#            check_overlap = TRUE)\n\n\nI can then take all of the viruses that we found and look up what they’re responsible for and whether they’re dangerous.\n\n\n\n\n\n\n\nVirus Name\nCommon Name\nPathogenic Potential\n\n\n\nRotavirus A\nRotavirus\nHigh, causes severe diarrhea in children\n\n\nEnterovirus C\nIncludes poliovirus and some coxsackieviruses\nHigh, can cause various diseases including polio\n\n\nSevere acute respiratory syndrome-related coronavirus\nSARS coronavirus\nHigh, causes severe respiratory illness\n\n\nSapporo virus\nSapporo virus or Sapovirus\nModerate, causes gastroenteritis\n\n\nHuman mastadenovirus F\nAdenovirus F\nModerate, can cause gastroenteritis\n\n\nAlphapolyomavirus quintihominis\nNot widely known\nLow, but some polyomaviruses can cause disease in immunocompromised individuals\n\n\nAlphapapillomavirus 4\nHuman papillomavirus (HPV) type 4\nLow to moderate, can cause warts\n\n\n\nNone of these viruses are too suprising to see other than the Severe acute respiratory syndrome-related coronavirus, which when BLASTED, comes up as SARS-CoV-2. We believe that this is due to contamination with the COVID-19 pandemic since these samples were taken pre-pandemic."
  },
  {
    "objectID": "notebooks/2024-07-22-thijssen.html#comparison-of-viral-and-hv-reads",
    "href": "notebooks/2024-07-22-thijssen.html#comparison-of-viral-and-hv-reads",
    "title": "Workflow of Thijssen et al. (2023)",
    "section": "\n4.2 Comparison of viral and HV reads",
    "text": "4.2 Comparison of viral and HV reads\n\nCodecombine_viruses &lt;- rbind(p_reads_viral  %&gt;% group_by(read_group) %&gt;% summarize(mean=mean(p_reads)) %&gt;% mutate(type = \"Viral reads\"), read_counts_agg_long  %&gt;% group_by(read_group) %&gt;% summarize(mean=mean(p_reads))%&gt;% mutate(type = \"HV reads\"))\n# Format the mean values in scientific notation\ncombine_viruses &lt;- combine_viruses %&gt;%\n  mutate(mean_formatted = sprintf(\"%.2e\", mean))\n\ncombine_viruses %&gt;% select(type, read_group, mean=mean_formatted)\n\n\n  \n\n\nCode#g_read_counts +\n#  geom_point(data = p_reads_viral, aes(x = library, y = p_reads, color = read_group), size = 5) +\n#  geom_line(data = p_reads_viral, aes(x = library, y = p_reads, group = library), color = 'grey') +\n#  scale_color_brewer(palette = 'Accent')\n\n#ggarrange(g_viral, g_read_counts, ncol=2)"
  },
  {
    "objectID": "notebooks/2024-07-22-thijssen.html#comparison-of-viral-and-hv-reads-remove",
    "href": "notebooks/2024-07-22-thijssen.html#comparison-of-viral-and-hv-reads-remove",
    "title": "Workflow of Thijssen et al. (2023)",
    "section": "\n4.2 Comparison of viral and HV reads (remove)",
    "text": "4.2 Comparison of viral and HV reads (remove)\n\nCodecombine_viruses &lt;- rbind(p_reads_viral  %&gt;% group_by(read_group) %&gt;% summarize(mean=mean(p_reads)) %&gt;% mutate(type = \"Viral reads\"), read_counts_agg_long  %&gt;% group_by(read_group) %&gt;% summarize(mean=mean(p_reads))%&gt;% mutate(type = \"HV reads\"))\n# Format the mean values in scientific notation\ncombine_viruses &lt;- combine_viruses %&gt;%\n  mutate(mean_formatted = sprintf(\"%.2e\", mean))\n\ncombine_viruses %&gt;% select(type, read_group, mean=mean_formatted)\n\n\n  \n\n\nCode#g_read_counts +\n#  geom_point(data = p_reads_viral, aes(x = library, y = p_reads, color = read_group), size = 5) +\n#  geom_line(data = p_reads_viral, aes(x = library, y = p_reads, group = library), color = 'grey') +\n#  scale_color_brewer(palette = 'Accent')\n\n#ggarrange(g_viral, g_read_counts, ncol=2)"
  },
  {
    "objectID": "notebooks/2024-07-08_cebria-mendoza.html",
    "href": "notebooks/2024-07-08_cebria-mendoza.html",
    "title": "Workflow of Cebria-Mendoza et al. (2021)",
    "section": "",
    "text": "As a part of my time here, I’m exploring blood-based surveillance for novel viral pathogen detection. We’ve decided to make three blog posts. The first blog post will cover the physical and biological characteristics of blood, the second blog post will cover the blood sampling strategies, and the last blog post will look at the metagenomic profile of blood (which is what we’re doing here, and will do for the next few posts).\nThis is the first of many studies that I’ll be analyzing. however I don’t expect all of them to be used in the last blog post. In this post, I analyze Cebria-Mendoza 2021, a dataset with 60 samples where each sample is a pool of 8-13 unique healthy donors, with a total of ~600 donors from Spain.\nThis notebook uses the MGS Workflow v2.2.1 (note that this is old)."
  },
  {
    "objectID": "notebooks/2024-07-08_cebria-mendoza.html#about",
    "href": "notebooks/2024-07-08_cebria-mendoza.html#about",
    "title": "Workflow of Cebria-Mendoza et al. (2021)",
    "section": "\n1.1 About",
    "text": "1.1 About\nThis dataset comprises 60 samples from plasma pools of 8-13 people from Spain. In total, 567 healthy individuals contributed to these pools. For each pooled sample, a combined DNA and RNA library preparation was performed, resulting in a single sequencing output that captures both nucleic acid types. This approach provides comprehensive genetic information but precludes separate analysis of DNA and RNA from individual samples.\n\n1.1.1 Sample + library preparation\nParaphrased from the paper:\n\nA total of 587 plasma samples from healthy donors were collected from Valencia, Spain from 15 September 2018 to 30 March 2019 and stored at −80 °C until use.\nEach of the 60 pools (SP1-SP60) was obtained by mixing 1 mL of plasma from a variable number of donors (between 8- and 13-mL total). To assess viral recovery, each pool was spiked with 103 PFU of ϕX174 [Microviridae] and 104 PFU of vesicular stomatitis virus (VSV) [Rhabdoviridae]. Briefly, plasma pools were processed with 1.0 µM filters to remove cells and other non-viral particles and the filtered fractions were subject to high-speed centrifugation (87,000 g, 2 h, 4 °C), washed with PBS 1X (87,000 g, 1 h, 4 °C), and resuspended in 245 µL 1X digestion buffer. Then, 5 µL of Turbo DNase, 2 µL of Benzonase and 2 µL of micrococcal nuclease (NEB) were added to the sample to remove unprotected nucleic acids. After incubation (1 h, 37 °C), 20 µL of stop reagent was added, following the manufacturer’s instructions. Then, 240 µL supernatant was transferred to a new tube and split into two fractions: 200 µL fraction was used for RNA extraction using TRIzol LS reagent, followed by purification with the QIAamp Viral RNA Mini kit and amplification with the QuantiTect Whole Transcriptome kit (Qiagen), and 40 µL fraction was used for DNA extraction with the QIAamp Viral RNA Mini kit and amplification with the TruePrime WGA kit.\nFor each pool, DNA and RNA amplification products were mixed in equimolar concentration before library preparation, which was carried out using Nextera XT DNA library preparation kit with 15 amplification cycles (Illumina, San Diego, USA), and subject to pair-end sequencing in a NextSeq device.\n\nMore details can be found in their original paper which outlined this protocol."
  },
  {
    "objectID": "notebooks/2024-07-08_cebria-mendoza.html#quality-control",
    "href": "notebooks/2024-07-08_cebria-mendoza.html#quality-control",
    "title": "Workflow of Cebria-Mendoza et al. (2021)",
    "section": "\n1.2 Quality control",
    "text": "1.2 Quality control\nIn total, these 60 samples contained 230M read pairs. The samples had 2.3M - 4.8M (mean 3.8M) read pairs each.\nThe number of read pairs and total base pairs looks good, however the duplication rate is quite high (this can be attributed to their sample preparation). Adapter content is low (the upper limit on the plot is 1%). Read quality seems good both over all the positions as well as over the number of sequences.\n\nCode# Prepare data\nbasic_stats_raw_metrics &lt;- basic_stats_raw %&gt;%\n  select(library,\n         pool_size,\n         `# Read pairs` = n_read_pairs,\n         `Total base pairs\\n(approx)` = n_bases_approx,\n         `% Duplicates\\n(FASTQC)` = percent_duplicates) %&gt;%\n  pivot_longer(-(library:pool_size), names_to = \"metric\", values_to = \"value\") %&gt;%\n  mutate(metric = fct_inorder(metric)) \n\n# Set up plot templates\n\ng_basic &lt;- ggplot(basic_stats_raw_metrics, aes(x = library, y = value, fill = pool_size)) +\n  geom_col(position = \"dodge\") +\n  scale_x_discrete() +\n  scale_y_continuous(expand = c(0, 0)) +\n  expand_limits(y = c(0, 100)) +\n  scale_fill_brewer(palette = \"Accent\") + \n  facet_grid(metric ~ ., scales = \"free\", space = \"free_x\", switch = \"y\") +\n  theme_kit + theme(\n    axis.title.y = element_blank(),\n    strip.text.y = element_text(face = \"plain\")\n  )\ng_basic\n\n\n\n\n\n\n\n\nCode# Set up plotting templates\ng_qual_raw &lt;- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters_raw &lt;- g_qual_raw + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats_raw) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,1),\n                     expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0)) +\n  facet_grid(.~adapter)\ng_adapters_raw\n\n\n\n\n\n\nCode# Visualize quality\ng_quality_base_raw &lt;- g_qual_raw +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats_raw) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0))\ng_quality_base_raw\n\n\n\n\n\n\nCodeg_quality_seq_raw &lt;- g_qual_raw +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats_raw) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0))\ng_quality_seq_raw"
  },
  {
    "objectID": "notebooks/2024-07-08_cebria-mendoza.html#high-level-metrics",
    "href": "notebooks/2024-07-08_cebria-mendoza.html#high-level-metrics",
    "title": "Workflow of Cebria-Mendoza et al. (2021)",
    "section": "\n2.1 High-level metrics",
    "text": "2.1 High-level metrics\nThe average fraction of reads at each stage in the preprocessing pipeline is shown in the following table. On average, cleaning & deduplication removed about 57% of total read pairs, primarily during duplication which makes sense given that the raw metrics show that the samples are quite high in duplication. Ribodepletion removed about 6-8% during each round.\n\nCode# TODO: Group by pool size as well\n# Count read losses\nn_reads_rel &lt;- basic_stats %&gt;% \n  select(sample, pool_size, stage, percent_duplicates, n_read_pairs) %&gt;%\n  group_by(sample, pool_size) %&gt;% \n  arrange(sample, stage) %&gt;%\n  mutate(p_reads_retained = n_read_pairs / lag(n_read_pairs),\n         p_reads_lost = 1 - p_reads_retained,\n         p_reads_retained_abs = n_read_pairs / n_read_pairs[1],\n         p_reads_lost_abs = 1-p_reads_retained_abs,\n         p_reads_lost_abs_marginal = p_reads_lost_abs - lag(p_reads_lost_abs))\nn_reads_rel_display &lt;- n_reads_rel %&gt;% \n  rename(Stage=stage) %&gt;% \n  group_by(Stage) %&gt;% \n  summarize(`% Total Reads Lost (Cumulative)` = paste0(round(min(p_reads_lost_abs*100),1), \"-\", round(max(p_reads_lost_abs*100),1), \" (mean \", round(mean(p_reads_lost_abs*100),1), \")\"),\n            `% Total Reads Lost (Marginal)` = paste0(round(min(p_reads_lost_abs_marginal*100),1), \"-\", round(max(p_reads_lost_abs_marginal*100),1), \" (mean \", round(mean(p_reads_lost_abs_marginal*100),1), \")\"), .groups=\"drop\") %&gt;% \n  filter(Stage != \"raw_concat\") %&gt;%\n  mutate(Stage = Stage %&gt;% as.numeric %&gt;% factor(labels=c(\"Trimming & filtering\", \"Deduplication\", \"Initial ribodepletion\", \"Secondary ribodepletion\")))\nn_reads_rel_display\n\n\n  \n\n\n\nAdapter content stays low (it’s quite strange that FASTQC shows there being library contamination post ribosomal depletion and not anytime before that, but considering how small it is, I’m inclined to ignore it). Read quality stays pretty similar over the positions, but improves over the number of sequences (predominantly from cleaning) throughout the pipeline. Duplication rates are still quite high which is a bit concerning. Mean read length stays close to expected 150. The % of ribosomal reads vary a good amount, some samples had anywhere as low as 10% ribosomal reads whereas others had up to 60% ribosomal reads. This is probably an indication that I need to do more ribosomal read removal, but I’m going to hold off on doing this.\n\nCodeg_qual &lt;- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters &lt;- g_qual + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,1),\n                     , expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~adapter)\ng_adapters\n\n\n\n\n\n\nCode# Visualize quality\ng_quality_base &lt;- g_qual +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~.)\ng_quality_base\n\n\n\n\n\n\nCodeg_quality_seq &lt;- g_qual +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0)) +\n  facet_grid(stage~., scales = \"free_y\")\ng_quality_seq\n\n\n\n\n\n\n\n\nCodeg_stage_trace &lt;- ggplot(basic_stats, aes(x=stage, group=sample)) +\n  theme_kit\n\n# Plot reads over preprocessing\ng_reads_stages &lt;- g_stage_trace +\n  geom_line(aes(y=n_read_pairs)) +\n  scale_y_continuous(\"# Read pairs\", expand=c(0,0), limits=c(0,NA))\ng_reads_stages\n\n\n\n\n\n\nCode# Plot relative read losses during preprocessing\ng_reads_rel &lt;- ggplot(n_reads_rel, \n                      aes(x=stage, group=sample)) +\n  geom_line(aes(y=p_reads_lost_abs_marginal)) +\n  scale_y_continuous(\"% Total Reads Lost\", expand=c(0,0), \n                     labels = function(x) x*100) +\n  theme_kit\ng_reads_rel\n\n\n\n\n\n\n\n\nCodestage_dup &lt;- basic_stats %&gt;% group_by(stage) %&gt;% \n  summarize(dmin = min(percent_duplicates), dmax=max(percent_duplicates),\n            dmean=mean(percent_duplicates), .groups = \"drop\")\n\ng_dup_stages &lt;- g_stage_trace +\n  geom_line(aes(y=percent_duplicates)) +\n  scale_y_continuous(\"% Duplicates\", limits=c(0,NA), expand=c(0,0))\ng_dup_stages\n\n\n\n\n\n\nCodeg_readlen_stages &lt;- g_stage_trace + geom_line(aes(y=mean_seq_len)) +\n  scale_y_continuous(\"Mean read length (nt)\", expand=c(0,0), limits=c(0,NA))\ng_readlen_stages\n\n\n\n\n\n\n\n\nCode# Calculate reads lost during ribodepletion (approximation for % ribosomal reads)\nreads_ribo &lt;- n_reads_rel %&gt;% \n  filter(stage %in% c(\"dedup\", \"ribo_secondary\")) %&gt;% \n  group_by(sample) %&gt;% \n  summarize(p_reads_ribo=1-n_read_pairs[2]/n_read_pairs[1], .groups = \"drop\") %&gt;%\n  inner_join(libraries, by = 'sample')\nreads_ribo_summ &lt;- reads_ribo %&gt;%\n  group_by(sample) %&gt;%\n  summarize(min=min(p_reads_ribo), max=max(p_reads_ribo),\n            mean=mean(p_reads_ribo), .groups = \"drop\") %&gt;%\n  inner_join(libraries, by = 'sample')\ng_reads_ribo &lt;- ggplot(reads_ribo, \n                       aes(x=library, y=p_reads_ribo)) +\n  geom_point() + \n  scale_y_continuous(name=\"Approx % ribosomal reads\", limits=c(0,1),\n                     breaks=seq(0,1,0.2), expand=c(0,0), labels = function(y) y*100)+\n  theme_kit\ng_reads_ribo"
  },
  {
    "objectID": "notebooks/2024-07-08_cebria-mendoza.html#high-level-composition",
    "href": "notebooks/2024-07-08_cebria-mendoza.html#high-level-composition",
    "title": "Workflow of Cebria-Mendoza et al. (2021)",
    "section": "\n3.1 High-level composition",
    "text": "3.1 High-level composition\nTo assess the high-level composition of the reads, I ran the ribodepleted files through Kraken2 and summarized the results with Bracken.\nThe groups listed below were created by Will:\n\nFiltered (removed during cleaning)\nDuplicate (removed during deduplication)\nRibosomal (removed during ribodepletion)\nUnassigned (non-ribosomal reads that were not assigned to any taxon by Kraken/Bracken)\nBacterial (non-ribosomal reads assigned to the Bacteria domain by Kraken/Bracken)\nArchaeal (non-ribosomal reads assigned to the Archaea domain by Kraken/Bracken)\nViral (non-ribosomal reads assigned to the Viruses domain by Kraken/Bracken)\nHuman (non-ribosomal reads assigned to the Eukarya domain by Kraken/Bracken)\n\n\nCodeclassifications &lt;- c(\"Filtered\", \"Duplicate\", \"Ribosomal\", \"Unassigned\",\n                     \"Bacterial\", \"Archaeal\", \"Viral\", \"Human\")\n\n# Import composition data\ntax_final_dir &lt;- file.path(results_dir, \"taxonomy_final\")\ncomp_path &lt;- file.path(tax_final_dir, \"taxonomic_composition.tsv.gz\")\ncomp &lt;- read_tsv(comp_path) %&gt;% left_join(libraries, by = \"sample\") \n\nRows: 480 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (2): sample, classification\ndbl (2): n_reads, p_reads\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nCodecomp_minor &lt;- comp %&gt;% \n  filter(classification %in% c(\"Archaeal\", \"Viral\", \"Human\", \"Other\"))\ncomp_assigned &lt;- comp %&gt;%\n  filter(! classification %in% c(\"Filtered\", \"Duplicate\", \n                                 \"Ribosomal\", \"Unassigned\")) %&gt;%\n  group_by(sample) %&gt;%\n  mutate(p_reads = n_reads/sum(n_reads))\ncomp_assigned_minor &lt;- comp_assigned %&gt;% \n  filter(classification %in% c(\"Archaeal\", \"Viral\", \"Human\", \"Other\"))\n\n# Summarize composition\nread_comp_summ &lt;- comp %&gt;% \n  group_by(classification) %&gt;%\n  summarize(n_reads = sum(n_reads), .groups = \"drop_last\") %&gt;%\n  mutate(n_reads = replace_na(n_reads,0),\n         p_reads = n_reads/sum(n_reads),\n         pc_reads = p_reads*100) %&gt;%\n  mutate(classification = factor(classification, levels=classifications)) %&gt;%\n  select(classification, n_reads, pc_reads) %&gt;%\n  rename(`# of reads` = n_reads, \"% of reads\" = pc_reads) %&gt;%\n  mutate(`% of reads` = sprintf(\"%.2f\", `% of reads`))\nread_comp_summ\n\n\n  \n\n\n\n\nCode# Prepare plotting templates\ng_comp_base &lt;- ggplot(mapping=aes(x=library, y=p_reads, fill=classification)) +\n  scale_x_discrete(name=\"Plasma pool\") +\n  theme_kit + \n  theme(plot.title = element_text(hjust=0, face=\"plain\", size=rel(1.5)))\nscale_y_pc_reads &lt;- purrr::partial(scale_y_continuous, name = \"% Reads\",\n                                   expand = c(0,0), labels = function(y) y*100)\ngeom_comp &lt;- purrr::partial(geom_col, position = \"stack\", width = 1)\n\n# Define a color palette for the classification\nclassification_colors &lt;- brewer.pal(8, \"Accent\")\nnames(classification_colors) &lt;- c(\"Filtered\", \"Duplicate\", \"Ribosomal\", \"Unassigned\", \"Bacterial\", \"Archaeal\", \"Viral\", \"Human\")\nscale_fill_classification &lt;- function() {\n  scale_fill_manual(values = classification_colors, name = \"Classification\")\n}\n\n# Plot overall composition\ng_comp &lt;- g_comp_base + geom_comp(data = comp) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (all reads, all groups)\")\ng_comp\n\n\n\n\n\n\nCodeg_comp_assigned &lt;- g_comp_base + \n  geom_comp(data = comp_assigned) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (assigned reads, all groups)\")\ng_comp_assigned"
  },
  {
    "objectID": "notebooks/2024-07-08_cebria-mendoza.html#total-viral-content",
    "href": "notebooks/2024-07-08_cebria-mendoza.html#total-viral-content",
    "title": "Workflow of Cebria-Mendoza et al. (2021)",
    "section": "\n3.2 Total viral content",
    "text": "3.2 Total viral content\nTotal viral fraction average \\(1.81 \\times 10^{-2}\\) across samples. As a fraction of assigned (rather than total) reads, this jumped to \\(1.60 \\times 10^{-1}\\)."
  },
  {
    "objectID": "notebooks/2024-07-08_cebria-mendoza.html#taxonomic-composition-of-viruses",
    "href": "notebooks/2024-07-08_cebria-mendoza.html#taxonomic-composition-of-viruses",
    "title": "Workflow of Cebria-Mendoza et al. (2021)",
    "section": "\n3.3 Taxonomic composition of viruses",
    "text": "3.3 Taxonomic composition of viruses\nThe two dominant viruses we see are Anellovirdae and Rhabdovirdae (spike-in). Followed by these two viral families is Flavivirdae, and lastly, also by a much smaller percent, Microviridae (spike-in). The threshold for the label “other” are the set of families that make up less than 1% composition in all samples.\n\nCode# Get viral taxonomy\nviral_taxa_path &lt;- file.path(data_dir, \"total-virus-db.tsv.gz\")\nviral_taxa &lt;- read_tsv(viral_taxa_path, show_col_types = FALSE)\n\n# Get Kraken reports\nreports_path &lt;- file.path(tax_final_dir, \"kraken_reports.tsv.gz\")\nreports &lt;- read_tsv(reports_path, show_col_types = FALSE) %&gt;%\n  inner_join(libraries, by=\"sample\") %&gt;% arrange(sample)\n\n# Filter to viral taxa\nkraken_reports_viral &lt;- filter(reports, taxid %in% viral_taxa$taxid) %&gt;%\n  group_by(sample) %&gt;%\n  mutate(p_reads_viral = n_reads_clade/n_reads_clade[1])\nkraken_reports_viral_cleaned &lt;- kraken_reports_viral %&gt;%\n  select(-pc_reads_total, -n_reads_direct, -contains(\"minimizers\")) %&gt;%\n  select(name, taxid, p_reads_viral, n_reads_clade, everything()) %&gt;% ungroup\n\nviral_classes &lt;- kraken_reports_viral_cleaned %&gt;% filter(rank == \"C\")\nviral_families &lt;- kraken_reports_viral_cleaned %&gt;% filter(rank == \"F\")\n\n\n\nCodemajor_threshold &lt;- 0.01\n\n# Identify major viral families\nviral_families_major_tab &lt;- viral_families %&gt;% \n  group_by(name, taxid) %&gt;%\n  summarize(p_reads_viral_max = max(p_reads_viral), .groups=\"drop\") %&gt;%\n  filter(p_reads_viral_max &gt;= major_threshold)\nviral_families_major_list &lt;- viral_families_major_tab %&gt;% pull(name)\nviral_families_major &lt;- viral_families %&gt;% \n  filter(name %in% viral_families_major_list) %&gt;%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_minor &lt;- viral_families_major %&gt;% \n  group_by(sample) %&gt;%\n  summarize(p_reads_viral_major = sum(p_reads_viral), .groups = \"drop\") %&gt;%\n  mutate(name = \"Other\", taxid=NA, p_reads_viral = 1-p_reads_viral_major) %&gt;%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_display &lt;- viral_families_major %&gt;% \n  bind_rows(viral_families_minor) %&gt;%\n  arrange(desc(p_reads_viral)) %&gt;% \n  mutate(name = factor(name, levels=c(viral_families_major_list, \"Other\"))) %&gt;%\n  rename(p_reads = p_reads_viral, classification=name) %&gt;%\n  inner_join(libraries, by='sample')\n\n# Plot\ng_families &lt;- g_comp_base + \n  geom_comp(data=viral_families_display) +\n  scale_y_continuous(name=\"% Viral Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_brewer(palette = 'Accent')\ng_families\n\n\n\n\n\n\n\nExcluding Microviridae and Rhabdovirdae (spike-ins), remaining viral sequences are distributed across a wide variety:\n\nCodemajor_threshold_adj &lt;- 0.05\n\n# Adjust viral family counts\nviral_families_adj &lt;- viral_families %&gt;%\n  filter(!(name %in% c(\"Rhabdoviridae\",\"Microviridae\"))) %&gt;%\n  group_by(sample) %&gt;%\n  mutate(p_reads_viral = p_reads_viral/sum(p_reads_viral))\n\n# Identify major viral families\nviral_families_major_tab &lt;- viral_families_adj %&gt;% \n  group_by(name, taxid) %&gt;%\n  summarize(p_reads_viral_max = max(p_reads_viral), .groups=\"drop\") %&gt;%\n  filter(p_reads_viral_max &gt;= major_threshold)\nviral_families_major_list &lt;- viral_families_major_tab %&gt;% pull(name)\nviral_families_major &lt;- viral_families_adj %&gt;% \n  filter(name %in% viral_families_major_list) %&gt;%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_minor &lt;- viral_families_major %&gt;% \n  group_by(sample) %&gt;%\n  summarize(p_reads_viral_major = sum(p_reads_viral), .groups = \"drop\") %&gt;%\n  mutate(name = \"Other\", taxid=NA, p_reads_viral = 1-p_reads_viral_major) %&gt;%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_display &lt;- viral_families_major %&gt;% \n  bind_rows(viral_families_minor) %&gt;%\n  arrange(desc(p_reads_viral)) %&gt;% \n  mutate(name = factor(name, levels=c(viral_families_major_list, \"Other\"))) %&gt;%\n  rename(p_reads = p_reads_viral, classification=name) %&gt;%\n  inner_join(libraries, by = 'sample')\n\n# Plot\npalette_viral &lt;- c(brewer.pal(12, \"Set3\"), brewer.pal(8, \"Dark2\"), brewer.pal(9, \"Set1\"))\ng_families_adj &lt;- g_comp_base + \n  geom_comp(data=viral_families_display) +\n  scale_y_continuous(name=\"% Viral Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_manual(values=palette_viral, name = \"Viral class\")\ng_families_adj"
  },
  {
    "objectID": "notebooks/2024-07-08_cebria-mendoza.html#overall-relative-abundance",
    "href": "notebooks/2024-07-08_cebria-mendoza.html#overall-relative-abundance",
    "title": "Workflow of Cebria-Mendoza et al. (2021)",
    "section": "\n4.1 Overall relative abundance",
    "text": "4.1 Overall relative abundance\nI calculated the relative abundance of human-infecting viruses in two ways:\n\nFirst, as the total number of deduplicated human-virus reads in each sample, divided by the number of raw reads (“All reads”). This results in a viral fraction of \\(4.06 \\times 10^{-2}\\) across all samples\nSecond, as a fraction of preprocessed (cleaned, deduplicated, computationally ribodepleted) reads (“Preprocessed reads”). This results in a viral fraction of \\(1.11 \\times 10^{-1}\\) across all samples."
  },
  {
    "objectID": "notebooks/2024-07-08_cebria-mendoza.html#overall-taxonomy-and-composition",
    "href": "notebooks/2024-07-08_cebria-mendoza.html#overall-taxonomy-and-composition",
    "title": "Workflow of Cebria-Mendoza et al. (2021)",
    "section": "\n4.2 Overall taxonomy and composition",
    "text": "4.2 Overall taxonomy and composition\nComposition of HV reads was not greatly changed from when looking at all viral reads. The two dominant viruses we see are Anellovirdae and Rhabdovirdae. Followed by these two viral families is Flavivirdae, and lastly, also by a much smaller percent, Microviridae. The threshold for the label “other” are the set of families that make up less than 5% composition in all samples.\n\nCodethreshold_major_family &lt;- 0.05\n\n# Count reads for each human-viral family\nhv_family_counts &lt;- hv_reads_family %&gt;% \n  group_by(sample, name, taxid) %&gt;%\n  count(name = \"n_reads_hv\") %&gt;%\n  group_by(sample) %&gt;%\n  mutate(p_reads_hv = n_reads_hv/sum(n_reads_hv))\n\n# Identify high-ranking families and group others\nhv_family_major_tab &lt;- hv_family_counts %&gt;% group_by(name) %&gt;% \n  filter(p_reads_hv == max(p_reads_hv)) %&gt;% filter(row_number() == 1) %&gt;%\n  arrange(desc(p_reads_hv)) %&gt;% filter(p_reads_hv &gt; threshold_major_family)\nhv_family_counts_major &lt;- hv_family_counts %&gt;%\n  mutate(name_display = ifelse(name %in% hv_family_major_tab$name, name, \"Other\")) %&gt;%\n  group_by(sample, name_display) %&gt;%\n  summarize(n_reads_hv = sum(n_reads_hv), p_reads_hv = sum(p_reads_hv), \n            .groups=\"drop\") %&gt;%\n  mutate(name_display = factor(name_display, \n                               levels = c(hv_family_major_tab$name, \"Other\")))\nhv_family_counts_display &lt;- hv_family_counts_major %&gt;%\n  rename(p_reads = p_reads_hv, classification = name_display) %&gt;%\n  inner_join(libraries, by = 'sample')\n\n# Plot\ng_hv_family &lt;- g_comp_base + \n  geom_col(data=hv_family_counts_display, position = \"stack\", width=1) +\n  scale_y_continuous(name=\"% HV Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_brewer(palette = 'Accent', name = \"Viral family\") +\n  labs(title=\"Family composition of human-viral reads\") +\n  guides(fill=guide_legend(ncol=4)) +\n  theme(plot.title = element_text(size=rel(1.4), hjust=0, face=\"plain\"))\ng_hv_family\n\n\n\n\n\n\nCode# Get most prominent families for text\nhv_family_collate &lt;- hv_family_counts %&gt;%\n  group_by(name, taxid) %&gt;% \n  summarize(n_reads_tot = sum(n_reads_hv),\n            p_reads_max = max(p_reads_hv), .groups=\"drop\") %&gt;% \n  arrange(desc(n_reads_tot))\nhv_family_collate %&gt;%\n select(name,taxid, n_reads_tot) %&gt;%\n rename(\n  'family' = 'name',\n  '# of total reads' = 'n_reads_tot',\n)"
  },
  {
    "objectID": "notebooks/2024-07-08_cebria-mendoza.html#species-analysis",
    "href": "notebooks/2024-07-08_cebria-mendoza.html#species-analysis",
    "title": "Workflow of Cebria-Mendoza et al. (2021)",
    "section": "\n4.3 Species analysis",
    "text": "4.3 Species analysis\nTo get a good overview of families, genera, and species, we can look at a Sankey plot where the magnitude of relative abundance, averaged over all samples, is shown in parentheses.\n\nCode# Function to create links\ncreate_links &lt;- function(data) {\n  family_to_genus &lt;- data %&gt;%\n    filter(!is.na(genus)) %&gt;%\n    group_by(family, genus) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = genus)\n  \n  genus_to_species &lt;- data %&gt;%\n    group_by(genus, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = genus, target = species)\n\n  family_to_species &lt;- data %&gt;%\n    filter(is.na(genus)) %&gt;%\n    group_by(family, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = species)\n\n  bind_rows(family_to_genus, genus_to_species, family_to_species) %&gt;%\n    filter(!is.na(source))\n}\n\n# Function to create nodes\ncreate_nodes &lt;- function(links) {\n  data.frame(\n    name = c(links$source, links$target) %&gt;% unique()\n  )\n}\n\n# Function to prepare data for Sankey diagram\nprepare_sankey_data &lt;- function(links, nodes) {\n  links$IDsource &lt;- match(links$source, nodes$name) - 1\n  links$IDtarget &lt;- match(links$target, nodes$name) - 1\n  list(links = links, nodes = nodes)\n}\n\n# Function to create Sankey plot\ncreate_sankey_plot &lt;- function(sankey_data) {\n  sankeyNetwork(\n    Links = sankey_data$links, \n    Nodes = sankey_data$nodes,\n    Source = \"IDsource\", \n    Target = \"IDtarget\",\n    Value = \"value\", \n    NodeID = \"name\",\n    sinksRight = TRUE,\n    nodeWidth = 50,\n    fontSize = 14,\n    height = 800,\n    width = 1000\n  )\n}\n\nsave_sankey_as_png &lt;- function(sankey_plot, width = 1000, height = 800) {\n  # Save the plot as an HTML file\n  saveWidget(sankey_plot, sprintf('%s/sankey.html',image_dir))\n}\n\nformat_scientific &lt;- function(x, digits=2) {\n  sapply(x, function(val) {\n    if (is.na(val) || abs(val) &lt; 1e-15) {\n      return(\"0\")\n    } else {\n      exponent &lt;- floor(log10(abs(val)))\n      coef &lt;- val / 10^exponent\n      return(sprintf(\"%.1f × 10^%d\", round(coef, digits), exponent))\n    }\n  })\n}\n\ndata &lt;- result %&gt;% \n  mutate(across(c(genus_n_reads_tot, genus_ra_reads_tot), ~replace_na(., 0)),\n         genus = ifelse(is.na(genus), \"Unknown Genus\", genus)) %&gt;%\n  mutate(\n  species = paste0(species, sprintf(' (%s)', format_scientific(species_ra_reads_tot))),\n  genus = paste0(genus, sprintf(' (%s)', format_scientific(genus_ra_reads_tot))),\n  family = paste0(family, sprintf(' (%s)', format_scientific(family_ra_reads_tot)))\n)\nlinks &lt;- as.data.frame(create_links(data))\nnodes &lt;- create_nodes(links)\nsankey_data &lt;- prepare_sankey_data(links, nodes)\nsankey &lt;- create_sankey_plot(sankey_data)\n\nsankey\n\n\n\n\nCode#save_sankey_as_png(sankey)\n\n\nTo get a better idea of the relative abundance of species, we can create a dot plot where each dot represents the relative abundance of a particular species in a sample.\n\nCodespecies_family &lt;- result %&gt;% select(species, family) %&gt;% rename('name' = 'species')\n\nplay &lt;- hv_species_counts %&gt;% \n  ungroup() %&gt;%\n  inner_join(libraries, by = 'sample') %&gt;%\n  inner_join(species_family, by = 'name')\n\nplay$family &lt;- factor(play$family, levels=hv_family_collate %&gt;% pull(family))\nplay &lt;- play %&gt;%\n  arrange(family, name) %&gt;%\n  mutate(name = factor(name, levels = unique(name)))\n#name_order &lt;- play %&gt;% arrange(family) %&gt;% pull(name)\n#play$name &lt;- factor(play$name, levels = name_order)\n\nra_dot &lt;- ggplot(play, aes(x = ra_reads_hv, y=name)) +\n  geom_quasirandom(orientation = 'y', aes(color = family)) +\n   scale_color_brewer(palette = \"Accent\") +\n    scale_x_log10(\n    \"Relative abundance human virus reads\",\n    labels = function(x) parse(text = paste0(\"10^\", round(log10(x)))),\n    limits = c(1e-7, 1),\n    n.breaks = 8\n  ) +\n  labs(y = 'Human virus',\n       color = 'Viral family') + \n  theme_light() + \n    theme(\n    axis.text.y = element_text(size = 8),\n    axis.text.x = element_text(size = 14),\n    axis.ticks.y = element_blank(),axis.line = element_line(colour = \"black\"),\n    axis.title.x = element_text(size = 15),    \n    axis.title.y = element_text(size = 15),  \n    legend.text = element_text(size = 13),\n    legend.title = element_text(size = 16),\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank())\nra_dot\n\n\n\n\n\n\nCode#ggsave(sprintf('%s/ra_viral_dot.jpg',image_dir), ra_dot, height = 8 ,width = 12)\n\n\nI’d like to BLAST some of these reads against the NCBI nt database to see if we can get some more info on them."
  },
  {
    "objectID": "notebooks/2024-07-08_cebria-mendoza.html#quality-control-metrics",
    "href": "notebooks/2024-07-08_cebria-mendoza.html#quality-control-metrics",
    "title": "Workflow of Cebria-Mendoza et al. (2021)",
    "section": "\n2.2 Quality control metrics",
    "text": "2.2 Quality control metrics\nAdapter content stays low. Read quality stays pretty similar over the positions, but improves over the number of sequences (predominantly from cleaning) throughout the pipeline.\n\nCodeg_qual &lt;- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters &lt;- g_qual + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,1),\n                     , expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~adapter)\ng_adapters\n\n\n\n\n\n\nCode# Visualize quality\ng_quality_base &lt;- g_qual +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~.)\ng_quality_base\n\n\n\n\n\n\nCodeg_quality_seq &lt;- g_qual +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0)) +\n  facet_grid(stage~., scales = \"free_y\")\ng_quality_seq\n\n\n\n\n\n\n\nDuplication rates are still quite high which is a bit concerning. Mean read length stays close to expected 150. Some samples had anywhere as low as 10% all the way up to 60% ribosomal reads.\n\nCodeg_stage_trace &lt;- ggplot(basic_stats, aes(x=stage, group=sample)) +\n  theme_kit\n\n# Plot reads over preprocessing\ng_reads_stages &lt;- g_stage_trace +\n  geom_line(aes(y=n_read_pairs)) +\n  scale_y_continuous(\"# Read pairs\", expand=c(0,0), limits=c(0,NA))\ng_reads_stages\n\n\n\n\n\n\nCode# Plot relative read losses during preprocessing\ng_reads_rel &lt;- ggplot(n_reads_rel, \n                      aes(x=stage, group=sample)) +\n  geom_line(aes(y=p_reads_lost_abs_marginal)) +\n  scale_y_continuous(\"% Total Reads Lost\", expand=c(0,0), \n                     labels = function(x) x*100) +\n  theme_kit\ng_reads_rel\n\n\n\n\n\n\n\n\nCodestage_dup &lt;- basic_stats %&gt;% group_by(stage) %&gt;% \n  summarize(dmin = min(percent_duplicates), dmax=max(percent_duplicates),\n            dmean=mean(percent_duplicates), .groups = \"drop\")\n\ng_dup_stages &lt;- g_stage_trace +\n  geom_line(aes(y=percent_duplicates)) +\n  scale_y_continuous(\"% Duplicates\", limits=c(0,NA), expand=c(0,0))\ng_dup_stages\n\n\n\n\n\n\nCodeg_readlen_stages &lt;- g_stage_trace + geom_line(aes(y=mean_seq_len)) +\n  scale_y_continuous(\"Mean read length (nt)\", expand=c(0,0), limits=c(0,NA))\ng_readlen_stages\n\n\n\n\n\n\n\n\nCode# Calculate reads lost during ribodepletion (approximation for % ribosomal reads)\nreads_ribo &lt;- n_reads_rel %&gt;% \n  filter(stage %in% c(\"dedup\", \"ribo_secondary\")) %&gt;% \n  group_by(sample) %&gt;% \n  summarize(p_reads_ribo=1-n_read_pairs[2]/n_read_pairs[1], .groups = \"drop\") %&gt;%\n  inner_join(libraries, by = 'sample')\nreads_ribo_summ &lt;- reads_ribo %&gt;%\n  group_by(sample) %&gt;%\n  summarize(min=min(p_reads_ribo), max=max(p_reads_ribo),\n            mean=mean(p_reads_ribo), .groups = \"drop\") %&gt;%\n  inner_join(libraries, by = 'sample')\ng_reads_ribo &lt;- ggplot(reads_ribo, \n                       aes(x=library, y=p_reads_ribo)) +\n  geom_point() + \n  scale_y_continuous(name=\"Approx % ribosomal reads\", limits=c(0,1),\n                     breaks=seq(0,1,0.2), expand=c(0,0), labels = function(y) y*100)+\n  theme_kit\ng_reads_ribo"
  },
  {
    "objectID": "notebooks/2024-07-08_cebria-mendoza.html#analyzing-specific-families",
    "href": "notebooks/2024-07-08_cebria-mendoza.html#analyzing-specific-families",
    "title": "Workflow of Cebria-Mendoza et al. (2021)",
    "section": "\n4.3 Analyzing specific families",
    "text": "4.3 Analyzing specific families\nWe now investigate the composition of specific families that had more than 5 viral reads. In investigating individual viral families, to avoid distortions from a few rare reads, I restricted myself to samples where that family made up at least 1% of human-viral reads:\n\n4.3.1 Anelloviridae (Number of reads: 8,323,297)\n\nCode# Anelloviridae\nplot_viral_family_histogram(taxid_chosen=687329)\n\n\n\n\n\n\n\n\nCode# Anelloviridae\nplot_viral_family_composition(taxid_chosen=687329, threshold_major_species = 0.1)\n\n\n\n\n\n\n\n\n4.3.2 Rhabdoviridae (Number of reads: 935,461) [SPIKE-IN]\n\nCodeplot_viral_family_histogram(taxid_chosen=11270)\n\n\n\n\n\n\n\n\nCodeplot_viral_family_composition(taxid_chosen=11270, threshold_major_species = 0.1)\n\n\n\n\n\n\n\n\n4.3.3 Flaviviridae (Number of reads: 94,741)\n\nCodeplot_viral_family_histogram(taxid_chosen=11050)\n\n\n\n\n\n\n\n\nCodeplot_viral_family_composition(taxid_chosen=11050, threshold_major_species = 0.1)\n\n\n\n\n\n\n\n\n4.3.4 Microviridae (Number of reads: 10,841) [SPIKE-IN]\n\nCodeplot_viral_family_histogram(taxid_chosen=10841)\n\n\n\n\n\n\n\n\nCodeplot_viral_family_composition(taxid_chosen=10841, threshold_major_species = 0.1)"
  },
  {
    "objectID": "notebooks/2024-07-08_cebria-mendoza.html#relative-abundance-of-pathogenic-viruses-of-interest",
    "href": "notebooks/2024-07-08_cebria-mendoza.html#relative-abundance-of-pathogenic-viruses-of-interest",
    "title": "Workflow of Cebria-Mendoza et al. (2021)",
    "section": "\n4.4 Relative abundance of pathogenic viruses of interest",
    "text": "4.4 Relative abundance of pathogenic viruses of interest\nEach dot represents a sample, colored by viral family. The x-axis shows the relative abundance of human-infecting viruses, and the y-axis shows the species. I’ve removed the species relating to the spiked-in family (Microviridae and Rhabdoviridae).\n\nCodespecies_family &lt;- result %&gt;% select(species, family) %&gt;% rename('name' = 'species')\n\nplay &lt;- hv_species_counts %&gt;% \n  ungroup() %&gt;%\n  inner_join(libraries, by = 'sample') %&gt;%\n  inner_join(species_family, by = 'name') %&gt;%\n  filter(!(family %in% c(\"Microviridae\", \"Rhabdoviridae\"))) \n\nadjusted_play &lt;- play %&gt;% \n  group_by(name) %&gt;%\n  mutate(virus_prevalence_num = n_distinct(sample)/n_distinct(libraries),\n         total_reads_hv = sum(n_reads_hv)) %&gt;%\n  ungroup() %&gt;%\n  mutate(name = fct_reorder(name, virus_prevalence_num, .desc=TRUE)) %&gt;% \n  select(name, ra_reads_hv, family, virus_prevalence_num, total_reads_hv, n_reads_hv)\n\npal &lt;- c(brewer.pal(8, 'Dark2'),brewer.pal(8, 'Accent'))\n\n#, labels = label_log(digits=2)\n\nra_dot &lt;- ggplot(adjusted_play, aes(x = ra_reads_hv, y=name)) +\n  geom_quasirandom(orientation = 'y', aes(color = family)) +\n  scale_color_manual(values = pal) + \n    scale_x_log10(\n    \"Relative abundance human virus reads\",\n    labels=label_log(digits=3)\n  ) +\n  labs(y =  \"\",\n       color = 'Viral family') + \n  guides(color = guide_legend(ncol=2)) +\n  theme_light() + \n    theme(\n    axis.text.y = element_text(size = 10),\n    axis.text.x = element_text(size = 12),\n    axis.ticks.y = element_blank(),axis.line = element_line(colour = \"black\"),\n    axis.title.x = element_text(size = 14),    \n    legend.text = element_text(size = 10),\n    legend.title = element_text(size = 10, face=\"bold\"),\n    #legend.position = 'bottom',\n    legend.position = c(1, 1),  # Move legend to top right\n    legend.justification = c(1, 1),  # Align legend to top right\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank())\nra_dot\n\n\n\n\n\n\n\nAll of the viruses found above are known to be non-pathogenic in healthy humans."
  },
  {
    "objectID": "notebooks/2024-07-08_cebria-mendoza.html#human-infecting-virus-families-genera-and-species",
    "href": "notebooks/2024-07-08_cebria-mendoza.html#human-infecting-virus-families-genera-and-species",
    "title": "Workflow of Cebria-Mendoza et al. (2021)",
    "section": "\n6.1 Human-infecting virus families, genera, and species",
    "text": "6.1 Human-infecting virus families, genera, and species\nTo get a good overview of families, genera, and species, we can look at a Sankey plot where the magnitude of relative abundance, averaged over all samples, is shown in parentheses.\n\nCode# Function to create links\ncreate_links &lt;- function(data) {\n  family_to_genus &lt;- data %&gt;%\n    filter(!is.na(genus)) %&gt;%\n    group_by(family, genus) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = genus)\n  \n  genus_to_species &lt;- data %&gt;%\n    group_by(genus, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = genus, target = species)\n\n  family_to_species &lt;- data %&gt;%\n    filter(is.na(genus)) %&gt;%\n    group_by(family, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = species)\n\n  bind_rows(family_to_genus, genus_to_species, family_to_species) %&gt;%\n    filter(!is.na(source))\n}\n\n# Function to create nodes\ncreate_nodes &lt;- function(links) {\n  data.frame(\n    name = c(links$source, links$target) %&gt;% unique()\n  )\n}\n\n# Function to prepare data for Sankey diagram\nprepare_sankey_data &lt;- function(links, nodes) {\n  links$IDsource &lt;- match(links$source, nodes$name) - 1\n  links$IDtarget &lt;- match(links$target, nodes$name) - 1\n  list(links = links, nodes = nodes)\n}\n\n# Function to create Sankey plot\ncreate_sankey_plot &lt;- function(sankey_data) {\n  sankeyNetwork(\n    Links = sankey_data$links, \n    Nodes = sankey_data$nodes,\n    Source = \"IDsource\", \n    Target = \"IDtarget\",\n    Value = \"value\", \n    NodeID = \"name\",\n    sinksRight = TRUE,\n    nodeWidth = 25,\n    fontSize = 14,\n  )\n}\n\nsave_sankey_as_png &lt;- function(sankey_plot, width = 1000, height = 800) {\n  # Save the plot as an HTML file\n  saveWidget(sankey_plot, sprintf('%s/sankey.html',data_dir))\n}\n\nformat_scientific &lt;- function(x, digits=2) {\n  sapply(x, function(val) {\n    if (is.na(val) || abs(val) &lt; 1e-15) {\n      return(\"0\")\n    } else {\n      exponent &lt;- floor(log10(abs(val)))\n      coef &lt;- val / 10^exponent\n      #return(sprintf(\"%.1f × 10^%d\", round(coef, digits), exponent))\n      # May or may not be smart, just keeping magnitude\n      return(sprintf(\"10^%d\", exponent))\n    }\n  })\n}\n\ndata &lt;- result %&gt;% \n  mutate(across(c(genus_n_reads_tot, genus_ra_reads_tot), ~replace_na(., 0)),\n         genus = ifelse(is.na(genus), \"Unknown Genus\", genus)) %&gt;%\n  mutate(\n  species = paste0(species, sprintf(' (%s)', format_scientific(species_ra_reads_tot))),\n  genus = paste0(genus, sprintf(' (%s)', format_scientific(genus_ra_reads_tot))),\n  family = paste0(family, sprintf(' (%s)', format_scientific(family_ra_reads_tot)))\n)\nlinks &lt;- as.data.frame(create_links(data))\nnodes &lt;- create_nodes(links)\nsankey_data &lt;- prepare_sankey_data(links, nodes)\nsankey &lt;- create_sankey_plot(sankey_data)\n\nsankey"
  },
  {
    "objectID": "notebooks/2024-07-08_cebria-mendoza.html#relative-abundance-assuming-perfect-human-read-removal",
    "href": "notebooks/2024-07-08_cebria-mendoza.html#relative-abundance-assuming-perfect-human-read-removal",
    "title": "Workflow of Cebria-Mendoza et al. (2021)",
    "section": "\n4.5 Relative abundance assuming perfect human read removal",
    "text": "4.5 Relative abundance assuming perfect human read removal\nAssuming we’re able to perfectly remove all human reads, the average relative abundance of known human infecting virus is \\(4.08 \\times 10^{-2}\\) pre-viral spike removal and \\(3.64 \\times 10^{-2}\\) post-viral spike removal."
  },
  {
    "objectID": "notebooks/2024-07-22-thijssen.html#relative-abundance-assuming-perfect-human-read-removal",
    "href": "notebooks/2024-07-22-thijssen.html#relative-abundance-assuming-perfect-human-read-removal",
    "title": "Workflow of Thijssen et al. (2023)",
    "section": "\n4.5 Relative abundance assuming perfect human read removal",
    "text": "4.5 Relative abundance assuming perfect human read removal\nAssuming we’re able to perfectly remove all human reads, the average relative abundance of known human infecting virus is \\(1.87 \\times 10^{-4}\\)."
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#relative-abundance-assuming-perfect-human-read-removal",
    "href": "notebooks/2024-07-23-mengyi.html#relative-abundance-assuming-perfect-human-read-removal",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n4.5 Relative abundance assuming perfect human read removal",
    "text": "4.5 Relative abundance assuming perfect human read removal\nAssuming we’re able to perfectly remove all human reads, the average relative abundance of known human infecting virus is \\(5.37 \\times 10^{-4}\\)."
  },
  {
    "objectID": "notebooks/2024-09-05-oconnell.html",
    "href": "notebooks/2024-09-05-oconnell.html",
    "title": "Workflow of O’Connell et al. (2023)",
    "section": "",
    "text": "This is the first whole blood study of this series. In this post, I analyze O’Connell 2023, a dataset with 138 adult whole blood donors from Austin, TX.\nThis notebook uses the MGS Workflow v2.2.1 (note that this is old)."
  },
  {
    "objectID": "notebooks/2024-09-05-oconnell.html#about",
    "href": "notebooks/2024-09-05-oconnell.html#about",
    "title": "Workflow of O’Connell et al. (2023)",
    "section": "1.1 About",
    "text": "1.1 About\nThis dataset is composed of 138 samples which come from 138 individuals in Austin, TX. They performed RNA sequencing on whole blood samples.\n\n\nCode\n# Import libraries and extract metadata from sample names\nlibraries &lt;- read_csv(libraries_path, show_col_types = FALSE)\n#meta_data &lt;- read_csv('/Users/harmonbhasin/work/securebio/nao-harmon/thijssen2023/preprocessing/SraRunTable.txt') %&gt;%\n#  select('Library Name', Run) %&gt;% rename(sample = Run, library = 'Library Name')\n#libraries &lt;- libraries %&gt;%\n#  left_join(meta_data, by = 'sample') %&gt;%\n#  select(sample, library=library.y) %&gt;% \n#  filter(library != 'PCL21') %&gt;%\n#  mutate(library = factor(library, levels = c(paste0('PCL', 1:20))))\n#libraries\n\n\n\n1.1.1 Sample + library preparation\nParaphrased from the paper:\n\nWhole blood specimens were collected from 138 adult donors via PAXgene vacutainers at admission to the Emergency Department at Dell-Seton Medical Center (Austin, TX). Total RNA was isolated from archived PAXgene-stabilized whole blood using the PAXgene IVD Blood RNA Kit. Ribosomal RNA and globin mRNA-depleted cDNA libraries were prepared from 500 ng of total RNA using the Illumina TruSeq Stranded Total RNA Ribo-Zero Globin kit. Paired-end 150 bp sequencing was performed on the Illumina NovaSeq 6000 platform.\n\nMore details can be found here."
  },
  {
    "objectID": "notebooks/2024-09-05-oconnell.html#quality-control-metrics",
    "href": "notebooks/2024-09-05-oconnell.html#quality-control-metrics",
    "title": "Workflow of O’Connell et al. (2023)",
    "section": "1.2 Quality control metrics",
    "text": "1.2 Quality control metrics\nIn total, these 138 samples contained ~3B read pairs. The samples had ~20.1M - 46.9M (mean ~22.5M) read pairs each. The number of reads looks pretty good, with a few samples having a much higher count. The total number of base pairs also looks reasonable, matching the trends of the number of reads. The duplication rate is high. Adapter content is quite low, although we can see library contamination (illumina_universal_adapter), and polya/polyg contamination. As we’d expect, we see higher quality Q scores near the beginning of the read and a gradual decline towards the end of the read, however all positions seem to have a Q score of around 35 which means that our reads are ~99.97% accurate. When looking at the Q score over all sequences, we can see a sharp peak around 35, which corresponds to the previous plot, indicating high read quality.\n\n\nCode\n# Prepare data\nbasic_stats_raw_metrics &lt;- basic_stats_raw %&gt;%\n  select(library,\n         `# Read pairs` = n_read_pairs,\n         `Total base pairs\\n(approx)` = n_bases_approx,\n         `% Duplicates\\n(FASTQC)` = percent_duplicates) %&gt;%\n  pivot_longer(-library, names_to = \"metric\", values_to = \"value\") %&gt;%\n  mutate(metric = fct_inorder(metric)) \n\n# Set up plot templates\n\ng_basic &lt;- ggplot(basic_stats_raw_metrics, aes(x = library, y = value)) +\n  geom_col(position = \"dodge\") +\n  scale_x_discrete() +\n  scale_y_continuous(expand = c(0, 0)) +\n  expand_limits(y = c(0, 100)) +\n  facet_grid(metric ~ ., scales = \"free\", space = \"free_x\", switch = \"y\") +\n  theme_kit + theme(\n    axis.title.y = element_blank(),\n    strip.text.y = element_text(face = \"plain\"),\n    axis.text.x = element_blank()\n  )\ng_basic\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Set up plotting templates\ng_qual_raw &lt;- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters_raw &lt;- g_qual_raw + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats_raw) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,NA),\n                     breaks = seq(0,10,1), expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0)) +\n  facet_grid(.~adapter)\ng_adapters_raw\n\n\n\n\n\n\n\n\n\nCode\n# Visualize quality\ng_quality_base_raw &lt;- g_qual_raw +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats_raw) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0))\ng_quality_base_raw\n\n\n\n\n\n\n\n\n\nCode\ng_quality_seq_raw &lt;- g_qual_raw +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats_raw) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0))\ng_quality_seq_raw"
  },
  {
    "objectID": "notebooks/2024-09-05-oconnell.html#summary",
    "href": "notebooks/2024-09-05-oconnell.html#summary",
    "title": "Workflow of O’Connell et al. (2023)",
    "section": "2.1 Summary",
    "text": "2.1 Summary\nThe average fraction of reads at each stage in the preprocessing pipeline is shown in the following table. Adapter trimming & filtering doesn’t lose too many reads. Deduplication loses us about 27% of reads on average, then ribodepletion only loses as about 1% on average.\n\n\nCode\n# TODO: Group by pool size as well\n# Count read losses\nn_reads_rel &lt;- basic_stats %&gt;% \n  select(sample, stage, percent_duplicates, n_read_pairs) %&gt;%\n  group_by(sample) %&gt;% \n  arrange(sample, stage) %&gt;%\n  mutate(p_reads_retained = n_read_pairs / lag(n_read_pairs),\n         p_reads_lost = 1 - p_reads_retained,\n         p_reads_retained_abs = n_read_pairs / n_read_pairs[1],\n         p_reads_lost_abs = 1-p_reads_retained_abs,\n         p_reads_lost_abs_marginal = p_reads_lost_abs - lag(p_reads_lost_abs))\nn_reads_rel_display &lt;- n_reads_rel %&gt;% \n  rename(Stage=stage) %&gt;% \n  group_by(Stage) %&gt;% \n  summarize(`% Total Reads Lost (Cumulative)` = paste0(round(min(p_reads_lost_abs*100),1), \"-\", round(max(p_reads_lost_abs*100),1), \" (mean \", round(mean(p_reads_lost_abs*100),1), \")\"),\n            `% Total Reads Lost (Marginal)` = paste0(round(min(p_reads_lost_abs_marginal*100),1), \"-\", round(max(p_reads_lost_abs_marginal*100),1), \" (mean \", round(mean(p_reads_lost_abs_marginal*100),1), \")\"), .groups=\"drop\") %&gt;% \n  filter(Stage != \"raw_concat\") %&gt;%\n  mutate(Stage = Stage %&gt;% as.numeric %&gt;% factor(labels=c(\"Trimming & filtering\", \"Deduplication\", \"Initial ribodepletion\", \"Secondary ribodepletion\")))\nn_reads_rel_display"
  },
  {
    "objectID": "notebooks/2024-09-05-oconnell.html#quality-control-metrics-1",
    "href": "notebooks/2024-09-05-oconnell.html#quality-control-metrics-1",
    "title": "Workflow of O’Connell et al. (2023)",
    "section": "2.2 Quality control metrics",
    "text": "2.2 Quality control metrics\nTrimming + cleaning gets rid of the library contamination, however there is still some polya + polyg contamination, however given that it makes a small portion of adapter content, I think we’re fine ignoring it. Read quality slightly improves after preprocessing + cleaning, this is noticable near the end positions. When looking at the q score over all reads, we see that cleaning gives us most of our improvement.\n\n\nCode\ng_qual &lt;- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters &lt;- g_qual + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,20),\n                     breaks = seq(0,50,10), expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~adapter)\ng_adapters\n\n\n\n\n\n\n\n\n\nCode\n# Visualize quality\ng_quality_base &lt;- g_qual +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~.)\ng_quality_base\n\n\n\n\n\n\n\n\n\nCode\ng_quality_seq &lt;- g_qual +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0)) +\n  facet_grid(stage~., scales = \"free_y\")\ng_quality_seq\n\n\n\n\n\n\n\n\n\nThese plots below show the trends from above in each sample. Everything looks pretty good.\n\n\nCode\ng_stage_trace &lt;- ggplot(basic_stats, aes(x=stage, group=sample)) +\n  theme_kit\n\n# Plot reads over preprocessing\ng_reads_stages &lt;- g_stage_trace +\n  geom_line(aes(y=n_read_pairs)) +\n  scale_y_continuous(\"# Read pairs\", expand=c(0,0), limits=c(0,NA))\ng_reads_stages\n\n\n\n\n\n\n\n\n\nCode\n# Plot relative read losses during preprocessing\ng_reads_rel &lt;- ggplot(n_reads_rel, \n                      aes(x=stage, group=sample)) +\n  geom_line(aes(y=p_reads_lost_abs_marginal)) +\n  scale_y_continuous(\"% Total Reads Lost\", expand=c(0,0), \n                     labels = function(x) x*100) +\n  theme_kit\ng_reads_rel\n\n\n\n\n\n\n\n\n\n\n\nCode\nstage_dup &lt;- basic_stats %&gt;% group_by(stage) %&gt;% \n  summarize(dmin = min(percent_duplicates), dmax=max(percent_duplicates),\n            dmean=mean(percent_duplicates), .groups = \"drop\")\n\ng_dup_stages &lt;- g_stage_trace +\n  geom_line(aes(y=percent_duplicates)) +\n  scale_y_continuous(\"% Duplicates\", limits=c(0,NA), expand=c(0,0))\ng_dup_stages\n\n\n\n\n\n\n\n\n\nCode\ng_readlen_stages &lt;- g_stage_trace + geom_line(aes(y=mean_seq_len)) +\n  scale_y_continuous(\"Mean read length (nt)\", expand=c(0,0), limits=c(0,NA))\ng_readlen_stages\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Calculate reads lost during ribodepletion (approximation for % ribosomal reads)\nreads_ribo &lt;- n_reads_rel %&gt;% \n  filter(stage %in% c(\"dedup\", \"ribo_secondary\")) %&gt;% \n  group_by(sample) %&gt;% \n  summarize(p_reads_ribo=1-n_read_pairs[2]/n_read_pairs[1], .groups = \"drop\") %&gt;%\n  inner_join(libraries, by = 'sample')\nreads_ribo_summ &lt;- reads_ribo %&gt;%\n  group_by(sample) %&gt;%\n  summarize(min=min(p_reads_ribo), max=max(p_reads_ribo),\n            mean=mean(p_reads_ribo), .groups = \"drop\") %&gt;%\n  inner_join(libraries, by = 'sample')\ng_reads_ribo &lt;- ggplot(reads_ribo, \n                       aes(x=library, y=p_reads_ribo)) +\n  geom_point() + \n  scale_y_continuous(name=\"Approx % ribosomal reads\", limits=c(0,1),\n                     breaks=seq(0,1,0.2), expand=c(0,0), labels = function(y) y*100)+\n  theme_kit\ng_reads_ribo"
  },
  {
    "objectID": "notebooks/2024-09-05-oconnell.html#high-level-composition",
    "href": "notebooks/2024-09-05-oconnell.html#high-level-composition",
    "title": "Workflow of O’Connell et al. (2023)",
    "section": "3.1 High-level composition",
    "text": "3.1 High-level composition\nTo assess the high-level composition of the reads, I ran the ribodepleted files through Kraken2 and summarized the results with Bracken.\nThe groups listed below were created by Will:\n\nFiltered (removed during cleaning)\nDuplicate (removed during deduplication)\nRibosomal (removed during ribodepletion)\nUnassigned (non-ribosomal reads that were not assigned to any taxon by Kraken/Bracken)\nBacterial (non-ribosomal reads assigned to the Bacteria domain by Kraken/Bracken)\nArchaeal (non-ribosomal reads assigned to the Archaea domain by Kraken/Bracken)\nViral (non-ribosomal reads assigned to the Viruses domain by Kraken/Bracken)\nHuman (non-ribosomal reads assigned to the Eukarya domain by Kraken/Bracken)\n\n\n\nCode\nclassifications &lt;- c(\"Filtered\", \"Duplicate\", \"Ribosomal\", \"Unassigned\",\n                     \"Bacterial\", \"Archaeal\", \"Viral\", \"Human\")\n\n# Import composition data\ntax_final_dir &lt;- file.path(results_dir, \"taxonomy_final\")\ncomp_path &lt;- file.path(tax_final_dir, \"taxonomic_composition.tsv.gz\")\ncomp &lt;- read_tsv(comp_path, show_col_types = FALSE) %&gt;% left_join(libraries, by=\"sample\")\ncomp_minor &lt;- comp %&gt;% \n  filter(classification %in% c(\"Archaeal\", \"Viral\", \"Human\", \"Other\"))\ncomp_assigned &lt;- comp %&gt;%\n  filter(! classification %in% c(\"Filtered\", \"Duplicate\", \n                                 \"Ribosomal\", \"Unassigned\")) %&gt;%\n  group_by(sample) %&gt;%\n  mutate(p_reads = n_reads/sum(n_reads))\ncomp_assigned_minor &lt;- comp_assigned %&gt;% \n  filter(classification %in% c(\"Archaeal\", \"Viral\", \"Human\", \"Other\"))\n\n# Summarize composition\nread_comp_summ &lt;- comp %&gt;% \n  group_by(classification) %&gt;%\n  summarize(n_reads = sum(n_reads), .groups = \"drop_last\") %&gt;%\n  mutate(n_reads = replace_na(n_reads,0),\n         p_reads = n_reads/sum(n_reads),\n         pc_reads = p_reads*100) %&gt;%\n  mutate(classification = factor(classification, levels=classifications)) %&gt;%\n  select(classification, n_reads, pc_reads) %&gt;%\n  rename(`# of reads` = n_reads, \"% of reads\" = pc_reads) %&gt;%\n  mutate(`% of reads` = sprintf(\"%.2f\", `% of reads`))\nread_comp_summ\n\n\n\n  \n\n\n\n\n\nCode\n# Prepare plotting templates\ng_comp_base &lt;- ggplot(mapping=aes(x=library, y=p_reads, fill=classification)) +\n  scale_x_discrete(name=\"Plasma pool\") +\n  theme_kit + \n  theme(plot.title = element_text(hjust=0, face=\"plain\", size=rel(1.5)))\nscale_y_pc_reads &lt;- purrr::partial(scale_y_continuous, name = \"% Reads\",\n                                   expand = c(0,0), labels = function(y) y*100)\ngeom_comp &lt;- purrr::partial(geom_col, position = \"stack\", width = 1)\n\n# Define a color palette for the classification\nclassification_colors &lt;- brewer.pal(8, \"Accent\")\nnames(classification_colors) &lt;- c(\"Filtered\", \"Duplicate\", \"Ribosomal\", \"Unassigned\", \"Bacterial\", \"Archaeal\", \"Viral\", \"Human\")\nscale_fill_classification &lt;- function() {\n  scale_fill_manual(values = classification_colors, name = \"Classification\")\n}\n\n# Plot overall composition\ng_comp &lt;- g_comp_base + geom_comp(data = comp) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (all reads, all groups)\")\ng_comp\n\n\n\n\n\n\n\n\n\nCode\ng_comp_assigned &lt;- g_comp_base + \n  geom_comp(data = comp_assigned) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (assigned reads, all groups)\")\ng_comp_assigned"
  },
  {
    "objectID": "notebooks/2024-09-05-oconnell.html#total-viral-content",
    "href": "notebooks/2024-09-05-oconnell.html#total-viral-content",
    "title": "Workflow of O’Connell et al. (2023)",
    "section": "3.2 Total viral content",
    "text": "3.2 Total viral content\nTotal viral fraction average \\(7.70 \\times 10^{-7}\\) across samples. As a fraction of assigned (rather than total) reads, this jumped to \\(1.18 \\times 10^{-6}\\):"
  },
  {
    "objectID": "notebooks/2024-09-05-oconnell.html#taxonomic-composition-of-viruses",
    "href": "notebooks/2024-09-05-oconnell.html#taxonomic-composition-of-viruses",
    "title": "Workflow of O’Connell et al. (2023)",
    "section": "3.3 Taxonomic composition of viruses",
    "text": "3.3 Taxonomic composition of viruses\nThe two dominant viruses we see are Anellovirdae and Phycodnaviridae. The threshold for the label “other” are the set of families that make up less than 30% composition in all samples.\n\n\nCode\nmajor_threshold &lt;- 0.3\n\n# Identify major viral families\nviral_families_major_tab &lt;- viral_families %&gt;% \n  group_by(name, taxid) %&gt;%\n  summarize(p_reads_viral_max = max(p_reads_viral), .groups=\"drop\") %&gt;%\n  filter(p_reads_viral_max &gt;= major_threshold)\nviral_families_major_list &lt;- viral_families_major_tab %&gt;% pull(name)\nviral_families_major &lt;- viral_families %&gt;% \n  filter(name %in% viral_families_major_list) %&gt;%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_minor &lt;- viral_families_major %&gt;% \n  group_by(sample) %&gt;%\n  summarize(p_reads_viral_major = sum(p_reads_viral), .groups = \"drop\") %&gt;%\n  mutate(name = \"Other\", taxid=NA, p_reads_viral = 1-p_reads_viral_major) %&gt;%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_display &lt;- viral_families_major %&gt;% \n  bind_rows(viral_families_minor) %&gt;%\n  arrange(desc(p_reads_viral)) %&gt;% \n  mutate(name = factor(name, levels=c(viral_families_major_list, \"Other\"))) %&gt;%\n  rename(p_reads = p_reads_viral, classification=name) %&gt;%\n  inner_join(libraries, by='sample')\n\n\npal &lt;- c(brewer.pal(8, 'Dark2'),brewer.pal(8, 'Accent'), brewer.pal(8, 'Set1'), brewer.pal(8, 'Pastel1'), brewer.pal(8, 'Pastel2'))\n\nn_classifications &lt;- length(unique(viral_families_display$classification)) - 1\n\ncustom_palette_with_black &lt;- c(\n  pal[1:n_classifications],\n  \"black\"\n)\n\ng_families &lt;- ggplot(data = viral_families_display, aes(x = library, y = p_reads, fill = classification)) +\n  geom_col(position = \"stack\", width = 1) +\n  scale_y_continuous(name = \"% Viral Reads\", \n                     limits = c(0, 1.01), \n                     breaks = seq(0, 1, 0.2),\n                     expand = c(0, 0), \n                     labels = function(y) y * 100) +\n  scale_fill_manual(values = custom_palette_with_black) +\n  scale_x_discrete(name = \"\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    legend.position = \"bottom\"\n  ) +\n  labs(title = \"Viral Family Composition\",\n       fill = \"Classification\")\n\ng_families"
  },
  {
    "objectID": "notebooks/2024-09-05-oconnell.html#overall-relative-abundance",
    "href": "notebooks/2024-09-05-oconnell.html#overall-relative-abundance",
    "title": "Workflow of O’Connell et al. (2023)",
    "section": "4.1 Overall relative abundance",
    "text": "4.1 Overall relative abundance\nI calculated the relative abundance of human-infecting viruses in two ways:\n\nFirst, as the total number of deduplicated human-virus reads in each sample, divided by the number of raw reads (“All reads”). This results in a viral fraction of \\(2.62 \\times 10^{-8}\\) across all samples\nSecond, as a fraction of preprocessed (cleaned, deduplicated, computationally ribodepleted) reads (“Preprocessed reads”). This results in a viral fraction of \\(3.73 \\times 10^{-8}\\) across all samples."
  },
  {
    "objectID": "notebooks/2024-09-05-oconnell.html#comparison-of-viral-and-hv-reads-remove",
    "href": "notebooks/2024-09-05-oconnell.html#comparison-of-viral-and-hv-reads-remove",
    "title": "Workflow of O’Connell et al. (2023)",
    "section": "\n4.2 Comparison of viral and HV reads (remove)",
    "text": "4.2 Comparison of viral and HV reads (remove)"
  },
  {
    "objectID": "notebooks/2024-09-05-oconnell.html#overall-taxonomy-and-composition",
    "href": "notebooks/2024-09-05-oconnell.html#overall-taxonomy-and-composition",
    "title": "Workflow of O’Connell et al. (2023)",
    "section": "4.2 Overall taxonomy and composition",
    "text": "4.2 Overall taxonomy and composition\nComposition of HV reads was changed from when looking at all viral reads. Only 1 out of the 137 samples had reads for human infecting viruses, with read composition coming from well established viral families in whole blood.\n\n\nCode\nthreshold_major_family &lt;- 0.01\n\n# Count reads for each human-viral family\nhv_family_counts &lt;- hv_reads_family %&gt;% \n  group_by(sample, name, taxid) %&gt;%\n  count(name = \"n_reads_hv\") %&gt;%\n  group_by(sample) %&gt;%\n  mutate(p_reads_hv = n_reads_hv/sum(n_reads_hv))\n\n# Identify high-ranking families and group others\nhv_family_major_tab &lt;- hv_family_counts %&gt;% group_by(name) %&gt;% \n  filter(p_reads_hv == max(p_reads_hv)) %&gt;% filter(row_number() == 1) %&gt;%\n  arrange(desc(p_reads_hv)) %&gt;% filter(p_reads_hv &gt; threshold_major_family)\nhv_family_counts_major &lt;- hv_family_counts %&gt;%\n  mutate(name_display = ifelse(name %in% hv_family_major_tab$name, name, \"Other\")) %&gt;%\n  group_by(sample, name_display) %&gt;%\n  summarize(n_reads_hv = sum(n_reads_hv), p_reads_hv = sum(p_reads_hv), \n            .groups=\"drop\") %&gt;%\n  mutate(name_display = factor(name_display, \n                               levels = c(hv_family_major_tab$name, \"Other\")))\nhv_family_counts_display &lt;- hv_family_counts_major %&gt;%\n  rename(p_reads = p_reads_hv, classification = name_display) %&gt;%\n  inner_join(libraries, by = 'sample')\n\n# Plot\ng_hv_family &lt;- g_comp_base + \n  geom_col(data=hv_family_counts_display, position = \"stack\", width=1) +\n  scale_y_continuous(name=\"% HV Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_brewer(palette = 'Accent', name = \"Viral family\") +\n  labs(title=\"Family composition of human-viral reads\") +\n  guides(fill=guide_legend(ncol=4)) +\n  theme(plot.title = element_text(size=rel(1.4), hjust=0, face=\"plain\"))\ng_hv_family\n\n\n\n\n\n\n\n\n\nCode\n# Get most prominent families for text\nhv_family_collate &lt;- hv_family_counts %&gt;%\n  group_by(name, taxid) %&gt;% \n  summarize(n_reads_tot = sum(n_reads_hv),\n            p_reads_max = max(p_reads_hv), .groups=\"drop\") %&gt;% \n  arrange(desc(n_reads_tot))\nhv_family_collate"
  },
  {
    "objectID": "notebooks/2024-09-05-oconnell.html#relative-abundance-of-pathogenic-viruses-of-interest",
    "href": "notebooks/2024-09-05-oconnell.html#relative-abundance-of-pathogenic-viruses-of-interest",
    "title": "Workflow of O’Connell et al. (2023)",
    "section": "4.3 Relative abundance of pathogenic viruses of interest",
    "text": "4.3 Relative abundance of pathogenic viruses of interest\nEach dot represents a sample, colored by viral family. The x-axis shows the relative abundance of human-infecting viruses, and the y-axis shows the species.\n\n\nCode\nspecies_family &lt;- result %&gt;% select(species, family) %&gt;% rename('name' = 'species')\n\nplay &lt;- hv_species_counts %&gt;% \n  ungroup() %&gt;%\n  inner_join(libraries, by = 'sample') %&gt;%\n  inner_join(species_family, by = 'name')\n\nadjusted_play &lt;- play %&gt;% \n  group_by(name) %&gt;%\n  mutate(virus_prevalence_num = n_distinct(sample)/n_distinct(libraries),\n         total_reads_hv = sum(n_reads_hv)) %&gt;%\n  ungroup() %&gt;%\n  mutate(name = fct_reorder(name, virus_prevalence_num, .desc=TRUE)) %&gt;% \n  select(name, ra_reads_hv, family, virus_prevalence_num, total_reads_hv, n_reads_hv)\n\npal &lt;- c(brewer.pal(8, 'Dark2'),brewer.pal(8, 'Accent'))\n\n#, labels = label_log(digits=2)\n\nra_dot &lt;- ggplot(adjusted_play, aes(x = ra_reads_hv, y=name)) +\n  geom_quasirandom(orientation = 'y', aes(color = family)) +\n  scale_color_manual(values = pal) + \n    scale_x_log10(\n    \"Relative abundance human virus reads\",\n    labels=label_log(digits=3)\n  ) +\n  labs(y =  \"\",\n       color = 'Viral family') + \n  guides(color = guide_legend(ncol=2)) +\n  theme_light() + \n    theme(\n    axis.text.y = element_text(size = 10),\n    axis.text.x = element_text(size = 12),\n    axis.ticks.y = element_blank(),axis.line = element_line(colour = \"black\"),\n    axis.title.x = element_text(size = 14),    \n    legend.text = element_text(size = 10),\n    legend.title = element_text(size = 10, face=\"bold\"),\n    #legend.position = 'bottom',\n    legend.position = c(1, 1),  # Move legend to top right\n    legend.justification = c(1, 1),  # Align legend to top right\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank())\nra_dot\n\n\n\n\n\n\n\n\n\nCode\n#  geom_text(aes(label = total_reads_hv, y = name), \n#            x = 1e-9, hjust = 0, vjust = 0.5, size = 3, \n#            check_overlap = TRUE)\n\n\nWe see EBV, MPX (most likely contamination), and unclassified Anelloviridae, all of what are viruses we’d expect to see in whole blood."
  },
  {
    "objectID": "notebooks/2024-09-05-oconnell.html#relative-abundance-assuming-perfect-human-read-removal",
    "href": "notebooks/2024-09-05-oconnell.html#relative-abundance-assuming-perfect-human-read-removal",
    "title": "Workflow of O’Connell et al. (2023)",
    "section": "4.4 Relative abundance assuming perfect human read removal",
    "text": "4.4 Relative abundance assuming perfect human read removal\nAssuming we’re able to perfectly remove all human reads, the average relative abundance of known human infecting virus is \\(9.89 \\times 10^{-7}\\)."
  },
  {
    "objectID": "notebooks/2024-09-05-oconnell.html#human-infecting-virus-families-genera-and-species",
    "href": "notebooks/2024-09-05-oconnell.html#human-infecting-virus-families-genera-and-species",
    "title": "Workflow of O’Connell et al. (2023)",
    "section": "6.1 Human-infecting virus families, genera, and species",
    "text": "6.1 Human-infecting virus families, genera, and species\nTo get a good overview of families, genera, and species, we can look at a Sankey plot where the magnitude of relative abundance, averaged over all samples, is shown in parentheses.\n\n\nCode\n# Function to create links\ncreate_links &lt;- function(data) {\n  family_to_genus &lt;- data %&gt;%\n    filter(!is.na(genus)) %&gt;%\n    group_by(family, genus) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = genus)\n  \n  genus_to_species &lt;- data %&gt;%\n    group_by(genus, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = genus, target = species)\n\n  family_to_species &lt;- data %&gt;%\n    filter(is.na(genus)) %&gt;%\n    group_by(family, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = species)\n\n  bind_rows(family_to_genus, genus_to_species, family_to_species) %&gt;%\n    filter(!is.na(source))\n}\n\n# Function to create nodes\ncreate_nodes &lt;- function(links) {\n  data.frame(\n    name = c(links$source, links$target) %&gt;% unique()\n  )\n}\n\n# Function to prepare data for Sankey diagram\nprepare_sankey_data &lt;- function(links, nodes) {\n  links$IDsource &lt;- match(links$source, nodes$name) - 1\n  links$IDtarget &lt;- match(links$target, nodes$name) - 1\n  list(links = links, nodes = nodes)\n}\n\n# Function to create Sankey plot\ncreate_sankey_plot &lt;- function(sankey_data) {\n  sankeyNetwork(\n    Links = sankey_data$links, \n    Nodes = sankey_data$nodes,\n    Source = \"IDsource\", \n    Target = \"IDtarget\",\n    Value = \"value\", \n    NodeID = \"name\",\n    sinksRight = TRUE,\n    nodeWidth = 25,\n    fontSize = 14,\n  )\n}\n\nsave_sankey_as_png &lt;- function(sankey_plot, width = 1000, height = 800) {\n  # Save the plot as an HTML file\n  saveWidget(sankey_plot, sprintf('%s/sankey.html',data_dir))\n}\n\nformat_scientific &lt;- function(x, digits=2) {\n  sapply(x, function(val) {\n    if (is.na(val) || abs(val) &lt; 1e-15) {\n      return(\"0\")\n    } else {\n      exponent &lt;- floor(log10(abs(val)))\n      coef &lt;- val / 10^exponent\n      #return(sprintf(\"%.1f × 10^%d\", round(coef, digits), exponent))\n      # May or may not be smart, just keeping magnitude\n      return(sprintf(\"10^%d\", exponent))\n    }\n  })\n}\n\ndata &lt;- result %&gt;% \n  mutate(across(c(genus_n_reads_tot, genus_ra_reads_tot), ~replace_na(., 0)),\n         genus = ifelse(is.na(genus), \"Unknown Genus\", genus)) %&gt;%\n  mutate(\n  species = paste0(species, sprintf(' (%s)', format_scientific(species_ra_reads_tot))),\n  genus = paste0(genus, sprintf(' (%s)', format_scientific(genus_ra_reads_tot))),\n  family = paste0(family, sprintf(' (%s)', format_scientific(family_ra_reads_tot)))\n)\nlinks &lt;- as.data.frame(create_links(data))\nnodes &lt;- create_nodes(links)\nsankey_data &lt;- prepare_sankey_data(links, nodes)\nsankey &lt;- create_sankey_plot(sankey_data)\n\nsankey"
  },
  {
    "objectID": "notebooks/2024-09-12-thompson.html",
    "href": "notebooks/2024-09-12-thompson.html",
    "title": "Workflow of Thompson et al. (2023)",
    "section": "",
    "text": "This is another potential study of this series. In this post, I analyze Thompson 2023, a dataset with 417 samples of whole blood from healthy and SARS-CoV-2 infected individuals in the US.\nI’d like to thank Lenni for giving me feedback on the notebook and Will for providing me with a boilerplate rmarkdown file. This notebook uses the MGS Workflow v2.2.1 (note that this is old)."
  },
  {
    "objectID": "notebooks/2024-09-12-thompson.html#about",
    "href": "notebooks/2024-09-12-thompson.html#about",
    "title": "Workflow of Thompson et al. (2023)",
    "section": "1.1 About",
    "text": "1.1 About\nThis dataset is composed of 417 samples of whole blood from the US. In total, there were 353 SARS-CoV-2 infected individuals and 64 healthy individuals that contributed to this study. For each sample, they performed RNA-sequencing, with Illumina NovaSeq 6000, producing 2x100 bp reads.\n\n\nCode\nlow_sample_number &lt;- c('SRR21924256')\n# Import libraries and extract metadata from sample names\nlibraries &lt;- read_csv(libraries_path, show_col_types = FALSE) %&gt;% filter(!sample %in% low_sample_number)\n#meta_data &lt;- read_csv('/Users/harmonbhasin/work/securebio/nao-harmon/thijssen2023/preprocessing/SraRunTable.txt') %&gt;%\n#  select('Library Name', Run) %&gt;% rename(sample = Run, library = 'Library Name')\n#libraries &lt;- libraries %&gt;%\n#  left_join(meta_data, by = 'sample') %&gt;%\n#  select(sample, library=library.y) %&gt;% \n#  filter(library != 'PCL21') %&gt;%\n#  mutate(library = factor(library, levels = c(paste0('PCL', 1:20))))\n#libraries\n\n\n\n1.1.1 Sample + library preparation\nThis is paraphrased from the paper:\n\nPatients were seen between April and June 2020 for COVID-19. The whole blood used for RNA-seq was collected in Tempus RNA Blood Tubes (Thermo Fisher Scientific, 4342792). As soon as possible after blood collection, tubes were shaken and stored at −80 °C.\nRNA extraction, library preparation and sequencing were performed as described previously 28. In brief, frozen blood samples were thawed, and total RNA was extracted using a modification of the MagMax protocol for Stabilized Blood Tubes RNA Isolation Kit. Samples yielding sufficient RNA (&gt;50 ng) were barcoded and prepared for pooled whole transcriptome sequencing using the TruSeq Stranded Total RNA Library Prep Gold, which is designed to remove ribosomal, globin and mitochondrial RNA. Libraries were amplified with 15 cycles of PCR, pooled and sequenced on a NovaSeq 6000 (Illumina) using Sprime flow cells with 100-bp paired-end reads, targeting a mean of 50 million read pairs per sample."
  },
  {
    "objectID": "notebooks/2024-09-12-thompson.html#quality-control-metrics",
    "href": "notebooks/2024-09-12-thompson.html#quality-control-metrics",
    "title": "Workflow of Thompson et al. (2023)",
    "section": "1.2 Quality control metrics",
    "text": "1.2 Quality control metrics\nIn total, these 417 samples contained 27.7B read pairs. The samples had 30.7M - 133.9M (mean ~66.4M) read pairs each. The number of reads looks pretty good, although a few samples have a much lower number of reads. The total number of base pairs also looks reasonable, matching the trends of the number of reads. The duplication rate is very high. Adapter content is variable, but most samples have a low adapter content (below 5%). As we’d expect, we see higher quality Q scores near the beginning of the read and a gradual decline towards the end of the read, however all positions seem to have a Q score of 35 which means that our reads are ~99.97% accurate. When looking at the Q score over all sequences, we can see a sharp peak around 35, which corresponds to the previous plot, indicating high read quality.\n\n\nCode\n# Prepare data\nbasic_stats_raw_metrics &lt;- basic_stats_raw %&gt;%\n  select(library,\n         `# Read pairs` = n_read_pairs,\n         `Total base pairs\\n(approx)` = n_bases_approx,\n         `% Duplicates\\n(FASTQC)` = percent_duplicates) %&gt;%\n  pivot_longer(-library, names_to = \"metric\", values_to = \"value\") %&gt;%\n  mutate(metric = fct_inorder(metric)) \n\n# Set up plot templates\n\ng_basic &lt;- ggplot(basic_stats_raw_metrics, aes(x = library, y = value)) +\n  geom_col(position = \"dodge\") +\n  scale_x_discrete() +\n  scale_y_continuous(expand = c(0, 0)) +\n  expand_limits(y = c(0, 100)) +\n  facet_grid(metric ~ ., scales = \"free\", space = \"free_x\", switch = \"y\") +\n  theme_kit + theme(\n    axis.title.y = element_blank(),\n    strip.text.y = element_text(face = \"plain\")\n  )\ng_basic\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Set up plotting templates\ng_qual_raw &lt;- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters_raw &lt;- g_qual_raw + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats_raw) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,NA),\n                     breaks = seq(0,10,1), expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0)) +\n  facet_grid(.~adapter)\ng_adapters_raw\n\n\n\n\n\n\n\n\n\nCode\n# Visualize quality\ng_quality_base_raw &lt;- g_qual_raw +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats_raw) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0))\ng_quality_base_raw\n\n\n\n\n\n\n\n\n\nCode\ng_quality_seq_raw &lt;- g_qual_raw +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats_raw) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0))\ng_quality_seq_raw"
  },
  {
    "objectID": "notebooks/2024-09-12-thompson.html#summary",
    "href": "notebooks/2024-09-12-thompson.html#summary",
    "title": "Workflow of Thompson et al. (2023)",
    "section": "2.1 Summary",
    "text": "2.1 Summary\nThe average fraction of reads at each stage in the preprocessing pipeline is shown in the following table. Adapter trimming & filtering doesn’t lose too many reads. Deduplication loses us about 55% of reads on average, which is good considering the high duplication content seen earlier. Ribodepletion only removes about 2% of reads in total, which makes sense as they did ribosomal depletion during sample preparation.\n\n\nCode\n# TODO: Group by pool size as well\n# Count read losses\nn_reads_rel &lt;- basic_stats %&gt;% \n  select(sample, stage, percent_duplicates, n_read_pairs) %&gt;%\n  group_by(sample) %&gt;% \n  arrange(sample, stage) %&gt;%\n  mutate(p_reads_retained = n_read_pairs / lag(n_read_pairs),\n         p_reads_lost = 1 - p_reads_retained,\n         p_reads_retained_abs = n_read_pairs / n_read_pairs[1],\n         p_reads_lost_abs = 1-p_reads_retained_abs,\n         p_reads_lost_abs_marginal = p_reads_lost_abs - lag(p_reads_lost_abs))\nn_reads_rel_display &lt;- n_reads_rel %&gt;% \n  rename(Stage=stage) %&gt;% \n  group_by(Stage) %&gt;% \n  summarize(`% Total Reads Lost (Cumulative)` = paste0(round(min(p_reads_lost_abs*100),1), \"-\", round(max(p_reads_lost_abs*100),1), \" (mean \", round(mean(p_reads_lost_abs*100),1), \")\"),\n            `% Total Reads Lost (Marginal)` = paste0(round(min(p_reads_lost_abs_marginal*100),1), \"-\", round(max(p_reads_lost_abs_marginal*100),1), \" (mean \", round(mean(p_reads_lost_abs_marginal*100),1), \")\"), .groups=\"drop\") %&gt;% \n  filter(Stage != \"raw_concat\") %&gt;%\n  mutate(Stage = Stage %&gt;% as.numeric %&gt;% factor(labels=c(\"Trimming & filtering\", \"Deduplication\", \"Initial ribodepletion\", \"Secondary ribodepletion\")))\nn_reads_rel_display"
  },
  {
    "objectID": "notebooks/2024-09-12-thompson.html#quality-control-metrics-1",
    "href": "notebooks/2024-09-12-thompson.html#quality-control-metrics-1",
    "title": "Workflow of Thompson et al. (2023)",
    "section": "2.2 Quality control metrics",
    "text": "2.2 Quality control metrics\nCleaning seems to get rid of the library contamination and the polyg contamination. Polya contamination still is present, but I don’t think we’ve found a solution to remove it as yet. Q score remain the same during read cleaning when looking at the positions, with the end of the read actually improving in score. Q scores across all sequences look pretty much the same throughout cleaning.\n\n\nCode\ng_qual &lt;- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters &lt;- g_qual + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,20),\n                     breaks = seq(0,50,10), expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~adapter)\ng_adapters\n\n\n\n\n\n\n\n\n\nCode\n# Visualize quality\ng_quality_base &lt;- g_qual +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~.)\ng_quality_base\n\n\n\n\n\n\n\n\n\nCode\ng_quality_seq &lt;- g_qual +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0)) +\n  facet_grid(stage~., scales = \"free_y\")\ng_quality_seq\n\n\n\n\n\n\n\n\n\nThese plots below show the trends from above in each sample. Deduplication seems to drop by a lot post deduplication,which is a good thing given it was so high earlier. Mean read length remains relatively constant throuhgout. Some samples still seem to have high ribosomal content, however I’m not too worried about this.\n\n\nCode\ng_stage_trace &lt;- ggplot(basic_stats, aes(x=stage, group=sample)) +\n  theme_kit\n\n# Plot reads over preprocessing\ng_reads_stages &lt;- g_stage_trace +\n  geom_line(aes(y=n_read_pairs)) +\n  scale_y_continuous(\"# Read pairs\", expand=c(0,0), limits=c(0,NA))\ng_reads_stages\n\n\n\n\n\n\n\n\n\nCode\n# Plot relative read losses during preprocessing\ng_reads_rel &lt;- ggplot(n_reads_rel, \n                      aes(x=stage, group=sample)) +\n  geom_line(aes(y=p_reads_lost_abs_marginal)) +\n  scale_y_continuous(\"% Total Reads Lost\", expand=c(0,0), \n                     labels = function(x) x*100) +\n  theme_kit\ng_reads_rel\n\n\n\n\n\n\n\n\n\n\n\nCode\nstage_dup &lt;- basic_stats %&gt;% group_by(stage) %&gt;% \n  summarize(dmin = min(percent_duplicates), dmax=max(percent_duplicates),\n            dmean=mean(percent_duplicates), .groups = \"drop\")\n\ng_dup_stages &lt;- g_stage_trace +\n  geom_line(aes(y=percent_duplicates)) +\n  scale_y_continuous(\"% Duplicates\", limits=c(0,NA), expand=c(0,0))\ng_dup_stages\n\n\n\n\n\n\n\n\n\nCode\ng_readlen_stages &lt;- g_stage_trace + geom_line(aes(y=mean_seq_len)) +\n  scale_y_continuous(\"Mean read length (nt)\", expand=c(0,0), limits=c(0,NA))\ng_readlen_stages\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Calculate reads lost during ribodepletion (approximation for % ribosomal reads)\nreads_ribo &lt;- n_reads_rel %&gt;% \n  filter(stage %in% c(\"dedup\", \"ribo_secondary\")) %&gt;% \n  group_by(sample) %&gt;% \n  summarize(p_reads_ribo=1-n_read_pairs[2]/n_read_pairs[1], .groups = \"drop\") %&gt;%\n  inner_join(libraries, by = 'sample')\nreads_ribo_summ &lt;- reads_ribo %&gt;%\n  group_by(sample) %&gt;%\n  summarize(min=min(p_reads_ribo), max=max(p_reads_ribo),\n            mean=mean(p_reads_ribo), .groups = \"drop\") %&gt;%\n  inner_join(libraries, by = 'sample')\ng_reads_ribo &lt;- ggplot(reads_ribo, \n                       aes(x=library, y=p_reads_ribo)) +\n  geom_point() + \n  scale_y_continuous(name=\"Approx % ribosomal reads\", limits=c(0,1),\n                     breaks=seq(0,1,0.2), expand=c(0,0), labels = function(y) y*100)+\n  theme_kit\ng_reads_ribo"
  },
  {
    "objectID": "notebooks/2024-09-12-thompson.html#high-level-composition",
    "href": "notebooks/2024-09-12-thompson.html#high-level-composition",
    "title": "Workflow of Thompson et al. (2023)",
    "section": "3.1 High-level composition",
    "text": "3.1 High-level composition\nTo assess the high-level composition of the reads, I ran the ribodepleted files through Kraken2 and summarized the results with Bracken.\nThe groups listed below were created by Will:\n\nFiltered (removed during cleaning)\nDuplicate (removed during deduplication)\nRibosomal (removed during ribodepletion)\nUnassigned (non-ribosomal reads that were not assigned to any taxon by Kraken/Bracken)\nBacterial (non-ribosomal reads assigned to the Bacteria domain by Kraken/Bracken)\nArchaeal (non-ribosomal reads assigned to the Archaea domain by Kraken/Bracken)\nViral (non-ribosomal reads assigned to the Viruses domain by Kraken/Bracken)\nHuman (non-ribosomal reads assigned to the Eukarya domain by Kraken/Bracken)\n\n\n\nCode\n# Prepare plotting templates\ng_comp_base &lt;- ggplot(mapping=aes(x=library, y=p_reads, fill=classification)) +\n  scale_x_discrete(name=\"Plasma pool\") +\n  theme_kit + \n  theme(plot.title = element_text(hjust=0, face=\"plain\", size=rel(1.5)))\nscale_y_pc_reads &lt;- purrr::partial(scale_y_continuous, name = \"% Reads\",\n                                   expand = c(0,0), labels = function(y) y*100)\ngeom_comp &lt;- purrr::partial(geom_col, position = \"stack\", width = 1)\n\n# Define a color palette for the classification\nclassification_colors &lt;- brewer.pal(8, \"Accent\")\nnames(classification_colors) &lt;- c(\"Filtered\", \"Duplicate\", \"Ribosomal\", \"Unassigned\", \"Bacterial\", \"Archaeal\", \"Viral\", \"Human\")\nscale_fill_classification &lt;- function() {\n  scale_fill_manual(values = classification_colors, name = \"Classification\")\n}\n\n# Plot overall composition\ng_comp &lt;- g_comp_base + geom_comp(data = comp) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (all reads, all groups)\")\ng_comp\n\n\n\n\n\n\n\n\n\nCode\ng_comp_assigned &lt;- g_comp_base + \n  geom_comp(data = comp_assigned) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (assigned reads, all groups)\")\ng_comp_assigned"
  },
  {
    "objectID": "notebooks/2024-09-12-thompson.html#total-viral-content",
    "href": "notebooks/2024-09-12-thompson.html#total-viral-content",
    "title": "Workflow of Thompson et al. (2023)",
    "section": "3.2 Total viral content",
    "text": "3.2 Total viral content\nTotal viral fraction average \\(1.12 \\times 10^{-6}\\) across samples. As a fraction of assigned (rather than total) reads, this jumped to \\(2.96 \\times 10^{-6}\\):"
  },
  {
    "objectID": "notebooks/2024-09-12-thompson.html#taxonomic-composition-of-viruses",
    "href": "notebooks/2024-09-12-thompson.html#taxonomic-composition-of-viruses",
    "title": "Workflow of Thompson et al. (2023)",
    "section": "3.3 Taxonomic composition of viruses",
    "text": "3.3 Taxonomic composition of viruses\nThere seems to be no dominant virus in the samples. Specifically, this seems to be the dataset with the most viral diversity (when compared to the previous plasma datasets). The threshold for the label “other” are the set of families that make up less than 30% composition in all samples.\n\n\nCode\nmajor_threshold &lt;- 0.3\n\n# Identify major viral families\nviral_families_major_tab &lt;- viral_families %&gt;% \n  group_by(name, taxid) %&gt;%\n  summarize(p_reads_viral_max = max(p_reads_viral), .groups=\"drop\") %&gt;%\n  filter(p_reads_viral_max &gt;= major_threshold)\nviral_families_major_list &lt;- viral_families_major_tab %&gt;% pull(name)\nviral_families_major &lt;- viral_families %&gt;% \n  filter(name %in% viral_families_major_list) %&gt;%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_minor &lt;- viral_families_major %&gt;% \n  group_by(sample) %&gt;%\n  summarize(p_reads_viral_major = sum(p_reads_viral), .groups = \"drop\") %&gt;%\n  mutate(name = \"Other\", taxid=NA, p_reads_viral = 1-p_reads_viral_major) %&gt;%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_display &lt;- viral_families_major %&gt;% \n  bind_rows(viral_families_minor) %&gt;%\n  arrange(desc(p_reads_viral)) %&gt;% \n  mutate(name = factor(name, levels=c(viral_families_major_list, \"Other\"))) %&gt;%\n  rename(p_reads = p_reads_viral, classification=name) %&gt;%\n  inner_join(libraries, by='sample')\n\n\npal &lt;- c(brewer.pal(8, 'Dark2'),brewer.pal(8, 'Accent'), brewer.pal(8, 'Set1'), brewer.pal(8, 'Pastel1'), brewer.pal(8, 'Pastel2'))\n\nn_classifications &lt;- length(unique(viral_families_display$classification)) - 1\n\ncustom_palette_with_black &lt;- c(\n  pal[1:n_classifications],\n  \"black\"\n)\n\n# Plot\ng_families &lt;- g_comp_base + \n  geom_comp(data=viral_families_display) +\n  scale_y_continuous(name=\"% Viral Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_manual(values = custom_palette_with_black)\ng_families"
  },
  {
    "objectID": "notebooks/2024-09-12-thompson.html#overall-relative-abundance",
    "href": "notebooks/2024-09-12-thompson.html#overall-relative-abundance",
    "title": "Workflow of Thompson et al. (2023)",
    "section": "4.1 Overall relative abundance",
    "text": "4.1 Overall relative abundance\nI calculated the relative abundance of human-infecting viruses in two ways:\n\nFirst, as the total number of deduplicated human-virus reads in each sample, divided by the number of raw reads (“All reads”). This results in a viral fraction of \\(1.5 \\times 10^{-6}\\) across all samples\nSecond, as a fraction of preprocessed (cleaned, deduplicated, computationally ribodepleted) reads (“Preprocessed reads”). This results in a viral fraction of \\(3.2 \\times 10^{-6}\\) across all samples."
  },
  {
    "objectID": "notebooks/2024-09-12-thompson.html#overall-taxonomy-and-composition",
    "href": "notebooks/2024-09-12-thompson.html#overall-taxonomy-and-composition",
    "title": "Workflow of Thompson et al. (2023)",
    "section": "4.2 Overall taxonomy and composition",
    "text": "4.2 Overall taxonomy and composition\nComposition of HV reads was changed from when looking at all viral reads. First, only 15% of the individuals in this dataset had human infecting viruses detectable in their blood. Second, individuals seem to be dominated by a single viral family. The threshold for the label “other” are the set of families that make up less than 5% composition in all samples.\n\n\nCode\nthreshold_major_family &lt;- 0.05\n\n# Count reads for each human-viral family\nhv_family_counts &lt;- hv_reads_family %&gt;% \n  group_by(sample, name, taxid) %&gt;%\n  count(name = \"n_reads_hv\") %&gt;%\n  group_by(sample) %&gt;%\n  mutate(p_reads_hv = n_reads_hv/sum(n_reads_hv))\n\n# Identify high-ranking families and group others\nhv_family_major_tab &lt;- hv_family_counts %&gt;% group_by(name) %&gt;% \n  filter(p_reads_hv == max(p_reads_hv)) %&gt;% filter(row_number() == 1) %&gt;%\n  arrange(desc(p_reads_hv)) %&gt;% filter(p_reads_hv &gt; threshold_major_family)\nhv_family_counts_major &lt;- hv_family_counts %&gt;%\n  mutate(name_display = ifelse(name %in% hv_family_major_tab$name, name, \"Other\")) %&gt;%\n  group_by(sample, name_display) %&gt;%\n  summarize(n_reads_hv = sum(n_reads_hv), p_reads_hv = sum(p_reads_hv), \n            .groups=\"drop\") %&gt;%\n  mutate(name_display = factor(name_display, \n                               levels = c(hv_family_major_tab$name, \"Other\")))\nhv_family_counts_display &lt;- hv_family_counts_major %&gt;%\n  rename(p_reads = p_reads_hv, classification = name_display) %&gt;%\n  inner_join(libraries, by = 'sample')\n\n# Plot\ng_hv_family &lt;- g_comp_base + \n  geom_col(data=hv_family_counts_display, position = \"stack\", width=1) +\n  scale_y_continuous(name=\"% HV Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_brewer(palette = 'Accent', name = \"Viral family\") +\n  labs(title=\"Family composition of human-viral reads\") +\n  guides(fill=guide_legend(ncol=4)) +\n  theme(plot.title = element_text(size=rel(1.4), hjust=0, face=\"plain\"))\ng_hv_family\n\n\n\n\n\n\n\n\n\nCode\n# Get most prominent families for text\nhv_family_collate &lt;- hv_family_counts %&gt;%\n  group_by(name, taxid) %&gt;% \n  summarize(n_reads_tot = sum(n_reads_hv),\n            p_reads_max = max(p_reads_hv), .groups=\"drop\") %&gt;% \n  arrange(desc(n_reads_tot))\nhv_family_collate"
  },
  {
    "objectID": "notebooks/2024-09-12-thompson.html#analyzing-specific-families",
    "href": "notebooks/2024-09-12-thompson.html#analyzing-specific-families",
    "title": "Workflow of Thompson et al. (2023)",
    "section": "4.3 Analyzing specific families",
    "text": "4.3 Analyzing specific families\nWe now investigate the composition of specific families that had more than 5 viral reads. In investigating individual viral families, to avoid distortions from a few rare reads, I restricted myself to samples where that family made up at least 1% of human-viral reads:\n\n4.3.1 Flaviviridae (Number of reads: 25,997)\n\n\nCode\n# Flaviviridae\nplot_viral_family_histogram(taxid_chosen=11050)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Flaviviridae\nplot_viral_family_composition(taxid_chosen=11050, threshold_major_species = 0.01)\n\n\n\n\n\n\n\n\n\n\n\n4.3.2 Anelloviridae (Number of reads: 10,103)\n\n\nCode\n# Anelloviridae\nplot_viral_family_histogram(taxid_chosen=687329)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Anelloviridae\nplot_viral_family_composition(taxid_chosen=687329, threshold_major_species = 0.01)\n\n\n\n\n\n\n\n\n\n\n\n4.3.3 Coronaviridae (Number of reads: 1,104)\n\n\nCode\n# Coronaviridae\nplot_viral_family_histogram(taxid_chosen=11118)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Coronaviridae\nplot_viral_family_composition(taxid_chosen=11118, threshold_major_species = 0.01)\n\n\n\n\n\n\n\n\n\n\n\n4.3.4 Orthoherpesviridae (Number of reads: 534)\n\n\nCode\n# Orthoherpesviridae\nplot_viral_family_histogram(taxid_chosen=3044472)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Orthoherpesviridae\nplot_viral_family_composition(taxid_chosen=3044472, threshold_major_species = 0.01)\n\n\n\n\n\n\n\n\n\n\n\n4.3.5 Parvoviridae (Number of reads: 335)\n\n\nCode\n# Parvoviridae\nplot_viral_family_histogram(taxid_chosen=10780)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Parvoviridae\nplot_viral_family_composition(taxid_chosen=10780, threshold_major_species = 0.01)\n\n\n\n\n\n\n\n\n\n\n\n4.3.6 Retroviridae (Number of reads: 224)\n\n\nCode\n# Retroviridae\nplot_viral_family_histogram(taxid_chosen=11632)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Retroviridae\nplot_viral_family_composition(taxid_chosen=11632, threshold_major_species = 0.01)"
  },
  {
    "objectID": "notebooks/2024-09-12-thompson.html#relative-abundance-of-pathogenic-viruses-of-interest",
    "href": "notebooks/2024-09-12-thompson.html#relative-abundance-of-pathogenic-viruses-of-interest",
    "title": "Workflow of Thompson et al. (2023)",
    "section": "4.4 Relative abundance of pathogenic viruses of interest",
    "text": "4.4 Relative abundance of pathogenic viruses of interest\nEach dot represents a sample, colored by viral family. The x-axis shows the relative abundance of human-infecting viruses, and the y-axis shows the species.\n\n\nCode\nspecies_family &lt;- result %&gt;% select(species, family) %&gt;% rename('name' = 'species')\n\nplay &lt;- hv_species_counts %&gt;% \n  ungroup() %&gt;%\n  inner_join(libraries, by = 'sample') %&gt;%\n  inner_join(species_family, by = 'name') %&gt;%\n  mutate(name = ifelse(name == \"Severe acute respiratory syndrome-related coronavirus\", \"SARS-related coronavirus\", name))\n\nadjusted_play &lt;- play %&gt;% \n  group_by(name) %&gt;%\n  mutate(virus_prevalence_num = n_distinct(sample)/n_distinct(libraries),\n         total_reads_hv = sum(n_reads_hv)) %&gt;%\n  ungroup() %&gt;%\n  mutate(name = fct_reorder(name, virus_prevalence_num, .desc=TRUE)) %&gt;% \n  select(name, ra_reads_hv, family, virus_prevalence_num, total_reads_hv, n_reads_hv)\n\npal &lt;- c(brewer.pal(8, 'Dark2'),brewer.pal(8, 'Accent'))\n\n#, labels = label_log(digits=2)\n\nra_dot &lt;- ggplot(adjusted_play, aes(x = ra_reads_hv, y=name)) +\n  geom_quasirandom(orientation = 'y', aes(color = family)) +\n  scale_color_manual(values = pal) + \n    scale_x_log10(\n    \"Relative abundance human virus reads\",\n    labels=label_log(digits=3)\n  ) +\n  labs(y =  \"\",\n       color = 'Viral family') + \n  guides(color = guide_legend(ncol=2)) +\n  theme_light() + \n    theme(\n    axis.text.y = element_text(size = 10),\n    axis.text.x = element_text(size = 12),\n    axis.ticks.y = element_blank(),axis.line = element_line(colour = \"black\"),\n    axis.title.x = element_text(size = 14),    \n    legend.text = element_text(size = 10),\n    legend.title = element_text(size = 10, face=\"bold\"),\n    #legend.position = 'bottom',\n    legend.position = c(1, 1),  # Move legend to top right\n    legend.justification = c(1, 1),  # Align legend to top right\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank())\nra_dot\n\n\n\n\n\n\n\n\n\nI can then take all of the viruses that we found and look up what they’re responsible for and whether they’re dangerous.\n\n\n\n\n\n\n\n\nVirus Name\nCommon Name\nPathogenic Potential\n\n\n\n\nHuman immunodeficiency virus 1\nHIV-1\nVery high, causes AIDS if left untreated, leading to severe immunodeficiency\n\n\nSARS-related coronavirus\nSARS-CoV\nHigh, causes severe acute respiratory syndrome with potentially fatal outcomes\n\n\nHepacivirus hominis\nHepatitis C Virus\nHigh, causes chronic liver disease and can lead to cirrhosis and liver cancer\n\n\nCytomegalovirus humanbeta5\nHuman Cytomegalovirus\nModerate to high, can cause severe disease in immunocompromised individuals and congenital infections\n\n\nLymphocryptovirus humangamma4\nEpstein-Barr Virus\nModerate, causes infectious mononucleosis and associated with certain cancers\n\n\nErythroparvovirus primate1\nHuman Parvovirus B19\nModerate, causes fifth disease and can be serious in certain populations (pregnant women, immunocompromised)\n\n\nRoseolovirus humanbeta6a\nHuman Herpesvirus 6A\nLow to moderate, can cause roseola in children and occasionally more severe complications\n\n\nRoseolovirus humanbeta6b\nHuman Herpesvirus 6B\nLow to moderate, can cause roseola in children and occasionally more severe complications\n\n\nAlphapapillomavirus 2\nHuman Papillomavirus 2\nLow to moderate, can cause common warts and rarely progress to cancer\n\n\nBetapapillomavirus 5\nHuman Papillomavirus 5\nLow to moderate, associated with skin lesions in immunosuppressed individuals\n\n\nBetapapillomavirus 2\nHuman Papillomavirus 9\nLow to moderate, associated with cutaneous lesions and rarely with non-melanoma skin cancer\n\n\nPrimate T-lymphotropic virus 2\nHuman T-cell Lymphotropic Virus 2\nLow, rarely associated with neurological disorders\n\n\nNupapillomavirus 1\nHuman Papillomavirus 41\nLow, can cause benign cutaneous lesions\n\n\nAlphapolyomavirus quintihominis\nHuman Polyomavirus 5\nLow, not known to cause significant disease in healthy individuals\n\n\nPegivirus hominis\nHuman Pegivirus\nVery low, not known to cause disease in humans\n\n\nPegivirus columbiaense\nPegivirus C\nVery low, not known to cause disease in humans\n\n\n\nThis was interesting to see. This is the first study where we’ve seen signficant numbers of human-infecting viruses in whole blood."
  },
  {
    "objectID": "notebooks/2024-09-12-thompson.html#relative-abundance-assuming-perfect-human-read-removal",
    "href": "notebooks/2024-09-12-thompson.html#relative-abundance-assuming-perfect-human-read-removal",
    "title": "Workflow of Thompson et al. (2023)",
    "section": "4.5 Relative abundance assuming perfect human read removal",
    "text": "4.5 Relative abundance assuming perfect human read removal\nAssuming we’re able to perfectly remove all human reads, the average relative abundance of known human infecting virus is \\(1.91 \\times 10^{-5}\\)."
  },
  {
    "objectID": "notebooks/2024-09-12-thompson.html#human-infecting-virus-families-genera-and-species",
    "href": "notebooks/2024-09-12-thompson.html#human-infecting-virus-families-genera-and-species",
    "title": "Workflow of Thompson et al. (2023)",
    "section": "6.1 Human-infecting virus families, genera, and species",
    "text": "6.1 Human-infecting virus families, genera, and species\nTo get a good overview of families, genera, and species, we can look at a Sankey plot where the magnitude of relative abundance, averaged over all samples, is shown in parentheses.\n\n\nCode\n# Function to create links\ncreate_links &lt;- function(data) {\n  family_to_genus &lt;- data %&gt;%\n    filter(!is.na(genus)) %&gt;%\n    group_by(family, genus) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = genus)\n  \n  genus_to_species &lt;- data %&gt;%\n    group_by(genus, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = genus, target = species)\n\n  family_to_species &lt;- data %&gt;%\n    filter(is.na(genus)) %&gt;%\n    group_by(family, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = species)\n\n  bind_rows(family_to_genus, genus_to_species, family_to_species) %&gt;%\n    filter(!is.na(source))\n}\n\n# Function to create nodes\ncreate_nodes &lt;- function(links) {\n  data.frame(\n    name = c(links$source, links$target) %&gt;% unique()\n  )\n}\n\n# Function to prepare data for Sankey diagram\nprepare_sankey_data &lt;- function(links, nodes) {\n  links$IDsource &lt;- match(links$source, nodes$name) - 1\n  links$IDtarget &lt;- match(links$target, nodes$name) - 1\n  list(links = links, nodes = nodes)\n}\n\n# Function to create Sankey plot\ncreate_sankey_plot &lt;- function(sankey_data) {\n  sankeyNetwork(\n    Links = sankey_data$links, \n    Nodes = sankey_data$nodes,\n    Source = \"IDsource\", \n    Target = \"IDtarget\",\n    Value = \"value\", \n    NodeID = \"name\",\n    sinksRight = TRUE,\n    nodeWidth = 25,\n    fontSize = 14,\n  )\n}\n\nsave_sankey_as_png &lt;- function(sankey_plot, width = 1000, height = 800) {\n  # Save the plot as an HTML file\n  saveWidget(sankey_plot, sprintf('%s/sankey.html',data_dir))\n}\n\nformat_scientific &lt;- function(x, digits=2) {\n  sapply(x, function(val) {\n    if (is.na(val) || abs(val) &lt; 1e-15) {\n      return(\"0\")\n    } else {\n      exponent &lt;- floor(log10(abs(val)))\n      coef &lt;- val / 10^exponent\n      #return(sprintf(\"%.1f × 10^%d\", round(coef, digits), exponent))\n      # May or may not be smart, just keeping magnitude\n      return(sprintf(\"10^%d\", exponent))\n    }\n  })\n}\n\ndata &lt;- result %&gt;% \n  mutate(across(c(genus_n_reads_tot, genus_ra_reads_tot), ~replace_na(., 0)),\n         genus = ifelse(is.na(genus), \"Unknown Genus\", genus)) %&gt;%\n  mutate(\n  species = paste0(species, sprintf(' (%s)', format_scientific(species_ra_reads_tot))),\n  genus = paste0(genus, sprintf(' (%s)', format_scientific(genus_ra_reads_tot))),\n  family = paste0(family, sprintf(' (%s)', format_scientific(family_ra_reads_tot)))\n)\nlinks &lt;- as.data.frame(create_links(data))\nnodes &lt;- create_nodes(links)\nsankey_data &lt;- prepare_sankey_data(links, nodes)\nsankey &lt;- create_sankey_plot(sankey_data)\n\nsankey"
  },
  {
    "objectID": "notebooks/2024-09-24-blog3-preanalysis.html",
    "href": "notebooks/2024-09-24-blog3-preanalysis.html",
    "title": "Blog 3: Pre-analysis",
    "section": "",
    "text": "In our previous post, we identfied four sampling strategies, each coming from either whole blood or plasma. To take this analysis a step further, we analyze the metagenomic sequencing data from various whole blood and plasma based studies. This analysis will help us understand the last piece missing from the puzzle: what viruses are present and detectable in whole blood and plasma using metagenomic sequencing and how do both sample types compare to each other.\nWe performed a literature search for large (&gt;100M read pairs), untargeted whole blood and plasma metagenomic studies. We identified 6 such datasets (Table 1), obtained the raw sequencing data, and processed it with a Kraken2-based computational pipeline to estimate the relative abundance of human-infecting viruses (Methods)."
  },
  {
    "objectID": "notebooks/2024-09-24-blog3-preanalysis.html#plasma",
    "href": "notebooks/2024-09-24-blog3-preanalysis.html#plasma",
    "title": "Blog 3: Pre-analysis",
    "section": "2.1 Plasma",
    "text": "2.1 Plasma\n\n2.1.1 Cebria-Mendoza et al. (2021)\nThis dataset from Spain has 60 samples, each derived from plasma pools of 8-13 people from Spain. In total, 567 healthy individuals contributed to these pools. For each pooled sample, a combined DNA and RNA library preparation was performed, resulting in a single sequencing output that captures both nucleic acid types. This approach provides comprehensive genetic information but precludes separate analysis of DNA and RNA from individual samples.\nTODO: Cebria-Mendoza does viral enrichment. Briefly … . More information can be found here.\nFull analysis can be found here\n\n\n2.1.2 Thijssen et al. (2023)\nThis dataset from Iran has 21 samples, each derived from plasma pools of 5 people from Iran. In total, 100 healthy individuals contributed to these pools. For each pooled sample, a combined DNA and RNA library preparation was performed, resulting in a single sequencing output that captures both nucleic acid types, with Illumina NextSeq 500, producing 2x150 bp reads.\nTODO: Thijseen does viral enrichment. Briefly … . More information can be found here\nFull analysis can be found here\n\n\n2.1.3 Mengyi et al. (2023)\nThis dataset from China has 201 samples, each derived from plasma pools of 160 donations from 7 different locations between 2012-2018. In total, 10,720 donations contributed to these pools (we do not know the number of individuals). They did DNA-sequencing for each pool, with Illumina HiSeq 4500, producing 2x150 bp reads.\nDisclaimer: When going through the sample preparation protocol, we noticed that the authors mentioned centrifuging whole blood and sequencing the supernatant, however to get plasma you would have to sequence the precipitate. We tried contacting the authors, but were unable to get a response. Given that the paper references plasma everywhere else, we’ve decided to consider this a plasma dataset.\nFull analysis can be found here"
  },
  {
    "objectID": "notebooks/2024-09-24-blog3-preanalysis.html#whole-blood",
    "href": "notebooks/2024-09-24-blog3-preanalysis.html#whole-blood",
    "title": "Blog 3: Pre-analysis",
    "section": "2.2 Whole blood",
    "text": "2.2 Whole blood\n\n2.2.1 Thompson et al. (2023)\nThis dataset from the USA has 417 samples, with 353 individuals positive for SARS-CoV-2 and 64 individuals negative, for a total of 417 individuals. They did RNA-sequencing for each sample, with Illumina NovaSeq 6000, producing 2x100 bp reads.\nFull analysis can be found here\n\n\n2.2.2 O’Connell et al. (2023)\nThis dataset from the USA has 138 samples, with 138 individuals presenting to the emergency department with symptoms or complications. They did RNA-sequencing for each sample using Illumina NovaSeq 6000, producing 2x150 bp reads.\nFull analysis can be found here\n\n\n2.2.3 Aydillo et al. (2022)\nThis dataset from the USA has 53 samples, with 53 healthy individuals. They did RNA-sequencing for each sample, with Illumina NovaSeq 6000, producing 2 x 95 bp reads.\nFull analysis can be found here"
  },
  {
    "objectID": "notebooks/2024-09-24-blog3-preanalysis.html#kingdom-composition",
    "href": "notebooks/2024-09-24-blog3-preanalysis.html#kingdom-composition",
    "title": "Blog 3: Pre-analysis",
    "section": "4.1 Kingdom composition",
    "text": "4.1 Kingdom composition\n\n\n\n\n\nFigure 1: Kingdom composition.\n\n\n\n\nOn average, whole blood datasets have higher human fractions than plasma datasets (Figure 1, Table 2). Choice of viral enrichment tends to have an impact on kingdom composition, as we can see that Cebria-Mendoza and Thijssen, both of which did viral enrichment, have significanlty lower human read fractions than Mengyi, despite all datasets coming from plasma. Even comparing viral enrichment methods, we can see that Cebria-Mendoza has a much higher fraction of viral reads compared to Thijssen.\nSample prep can lead to large variations in how many human reads end up in your sample. Cebria Mendoza is an example of highly efficient human read removal in plasma. Probably this is more challenging in whole blood, but may still be possible particularly if looking at the extracellular content. All of the whole blood studies were not focused on detecting non-human microbes. We can try to get a better understanding of the performance of whole blood by controlling for human reads (Table 3). The number of viral reads becomes much higher when we control for human reads, making it comparable to the plasma datasets.\n\n\n\n\n\n\nsample_type\n\n\ndataset\n\n\nUnassigned\n\n\nBacterial\n\n\nArchaeal\n\n\nViral\n\n\nHuman\n\n\n\n\n\n\nplasma\n\n\nCebria-Mendoza et al. (2021)\n\n\n42.16360 %\n\n\n49.89189 %\n\n\n0.03311 %\n\n\n5.98442 %\n\n\n1.92698 %\n\n\n\n\nplasma\n\n\nThijssen et al. (2023)\n\n\n73.12558 %\n\n\n4.51508 %\n\n\n0.01280 %\n\n\n0.03373 %\n\n\n22.31281 %\n\n\n\n\nplasma\n\n\nMengyi et al. (2023)\n\n\n1.33651 %\n\n\n0.26607 %\n\n\n0.00096 %\n\n\n0.01302 %\n\n\n98.38344 %\n\n\n\n\nwhole-blood\n\n\nThompson et al. (2023)\n\n\n0.11189 %\n\n\n0.01282 %\n\n\n0.00007 %\n\n\n0.00027 %\n\n\n99.87494 %\n\n\n\n\nwhole-blood\n\n\nO’Connell et al. (2023)\n\n\n0.08717 %\n\n\n0.05051 %\n\n\n0.00004 %\n\n\n0.00011 %\n\n\n99.86217 %\n\n\n\n\nwhole-blood\n\n\nAydillo et al. (2022)\n\n\n0.34940 %\n\n\n0.10959 %\n\n\n0.00061 %\n\n\n0.00028 %\n\n\n99.54011 %\n\n\n\n\nAverage\n\n\n\n\nplasma\n\n\n—-\n\n\n38.87523 %\n\n\n18.22435 %\n\n\n0.01562 %\n\n\n2.01039 %\n\n\n40.87441 %\n\n\n\n\nwhole-blood\n\n\n—-\n\n\n0.18282 %\n\n\n0.05764 %\n\n\n0.00024 %\n\n\n0.00022 %\n\n\n99.75908 %\n\n\n\n\nTable 2: Kingdom composition. Top: Composition across datasets. Bottom: Composition across sample types.\n\n\n\n\n\n\n\n\nsample_type\n\n\ndataset\n\n\nUnassigned\n\n\nBacterial\n\n\nArchaeal\n\n\nViral\n\n\n\n\n\n\nplasma\n\n\ncebriamendoza2021\n\n\n42.99205 %\n\n\n50.87219 %\n\n\n0.03376 %\n\n\n6.10200 %\n\n\n\n\nplasma\n\n\nthijssen2023\n\n\n94.12824 %\n\n\n5.81187 %\n\n\n0.01648 %\n\n\n0.04341 %\n\n\n\n\nplasma\n\n\nmengyi2023\n\n\n82.67637 %\n\n\n16.45903 %\n\n\n0.05935 %\n\n\n0.80525 %\n\n\n\n\nwhole-blood\n\n\nthompson2023\n\n\n89.47051 %\n\n\n10.25520 %\n\n\n0.05890 %\n\n\n0.21539 %\n\n\n\n\nwhole-blood\n\n\noconnell2023\n\n\n63.24574 %\n\n\n36.64757 %\n\n\n0.02763 %\n\n\n0.07906 %\n\n\n\n\nwhole-blood\n\n\naydillo2022\n\n\n75.97604 %\n\n\n23.83067 %\n\n\n0.13290 %\n\n\n0.06039 %\n\n\n\n\nAverage\n\n\n\n\nplasma\n\n\n—-\n\n\n73.26555 %\n\n\n24.38103 %\n\n\n0.03653 %\n\n\n2.31689 %\n\n\n\n\nwhole-blood\n\n\n—-\n\n\n76.23076 %\n\n\n23.57781 %\n\n\n0.07314 %\n\n\n0.11828 %\n\n\n\n\nTable 3: Kingdom composition controlled for human reads. Top: Composition across datasets. Bottom: Composition across sample types."
  },
  {
    "objectID": "notebooks/2024-09-24-blog3-preanalysis.html#human-infecting-viruses",
    "href": "notebooks/2024-09-24-blog3-preanalysis.html#human-infecting-viruses",
    "title": "Blog 3: Pre-analysis",
    "section": "4.2 Human-infecting viruses",
    "text": "4.2 Human-infecting viruses\n\n4.2.1 Overview\n\n\n\n\n\nFigure 2: Relative abundance of human-infecting viruses across datasets (samples with 0 reads are filtered out).\n\n\n\n\n\n\n\n\n\n\ndataset\n\n\nRA\n\n\nRA (control for human reads)\n\n\nsample_type\n\n\nSamples with &gt; 5 HV reads\n\n\nSamples with HV reads\n\n\nAverage number of reads\n\n\n\n\n\n\nThijssen et al. (2023)\n\n\n1.60e-04\n\n\n1.82e-04\n\n\nplasma\n\n\n21/21 (100.0%)\n\n\n21/21 (100.0%)\n\n\n5.6 M\n\n\n\n\nMengyi et al. (2023)\n\n\n9.84e-05\n\n\n5.11e-04\n\n\nplasma\n\n\n140/201 (69.7%)\n\n\n191/201 (95.0%)\n\n\n17.1 M\n\n\n\n\nThompson et al. (2023)\n\n\n1.51e-06\n\n\n3.18e-06\n\n\nwhole-blood\n\n\n69/417 (16.5%)\n\n\n202/417 (48.4%)\n\n\n66.4 M\n\n\n\n\nO’Connell et al. (2023)\n\n\n2.62e-08\n\n\n8.87e-08\n\n\nwhole-blood\n\n\n1/138 (0.7%)\n\n\n45/138 (32.6%)\n\n\n22.5 M\n\n\n\n\nAydillo et al. (2022)\n\n\n3.58e-07\n\n\n7.49e-07\n\n\nwhole-blood\n\n\n6/53 (11.3%)\n\n\n15/53 (28.3%)\n\n\n32.8 M\n\n\n\n\nTable 4: Relative abundance of human-infecting viruses in each dataset, with and without controlling for human reads.\n\n\n\n\n\n\n\n\nsample_type\n\n\nRA\n\n\nRA (control for human reads)\n\n\n\n\n\n\nplasma\n\n\n1.04e-04\n\n\n4.80e-04\n\n\n\n\nwhole-blood\n\n\n1.07e-06\n\n\n2.26e-06\n\n\n\n\nTable 5: Relative abundance of human-infecting viruses in each sample type, with and without controlling for human reads.\n\n\nThe relative abundance of human-infecting viruses is higher in plasma than whole blood (Figure 2, Table 4, Table 5).\n\n\n4.2.2 Family composition\n\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\n\n\n\nFigure 3: Family composition of human-infecting viral reads\n\n\n\n\nTODO\n\n\n4.2.3 Species composition\n\n\n\n\n\nFigure 4: Relative abundance of selected human-infecting viruses in each dataset. Top: without controlling for human reads. Bottom: controlling for human reads.\n\n\n\n\nTo gain a more granular understanding of each sample type, we can look at the relative abundance of specific viruses in each sample type that may be of interest (totalling to 21): those that are linked to disease, characterized by latent infections (this is in accordance to the NAO’s interest to detecting “stealth” pandemics), and those that are blood-borne. We get a wide range of human infecting viruses including Hepatitis, HIV, Herpes, and HPV. Importantly, most viruses seem to be detected in both sample types. When comparing the coverage of all viruses in each sample type, we see that plasma contains 104 unique viruses, whereas whole blood only countains about 56. However, when looking at these closely, we see that the majority of viruses captured by plasma all come from Anellovirdae, a non-harmful family of viruses. When we only look at the viruses specified above, we find that plasma contains 18 out of the 21 viruses, whereas whole blood contains 17 out of the 21 viruses. Specifically, plasma uniquely contains HBV, whereas whole blood uniquely contains HTLV-1 and HTLV-2."
  },
  {
    "objectID": "notebooks/2024-09-19-aydillo.html",
    "href": "notebooks/2024-09-19-aydillo.html",
    "title": "Workflow of Aydillo et al. (2022)",
    "section": "",
    "text": "AS OF NOW THIS TEXT IS NOT UPDATED.\nThis is another potential study of this series. In this post, I analyze Thijssen 2023, a dataset with 20 pooled samples from 100 healthy individuals in Iran.\nI’d like to thank Lenni for giving me feedback on the notebook and Will for providing me with a boilerplate rmarkdown file. This notebook uses the MGS Workflow v2.2.1 (note that this is old)."
  },
  {
    "objectID": "notebooks/2024-09-19-aydillo.html#about",
    "href": "notebooks/2024-09-19-aydillo.html#about",
    "title": "Workflow of Aydillo et al. (2022)",
    "section": "1.1 About",
    "text": "1.1 About\nThis dataset is composed of 20 samples which come from plasma pools of 5 people from Iran. In total, there were 100 healthy individuals that contributed to this pool. For each pooled sample, they performed a combined DNA and RNA library preparation, resulting in a single sequencing output that captures both nucleic acid types. This approach provides comprehensive genetic information but precludes separate analysis of DNA and RNA from individual samples.\n\n\nCode\n# Import libraries and extract metadata from sample names\nlibraries &lt;- read_csv(libraries_path, show_col_types = FALSE)\n#meta_data &lt;- read_csv('/Users/harmonbhasin/work/securebio/nao-harmon/thijssen2023/preprocessing/SraRunTable.txt') %&gt;%\n#  select('Library Name', Run) %&gt;% rename(sample = Run, library = 'Library Name')\n#libraries &lt;- libraries %&gt;%\n#  left_join(meta_data, by = 'sample') %&gt;%\n#  select(sample, library=library.y) %&gt;% \n#  filter(library != 'PCL21') %&gt;%\n#  mutate(library = factor(library, levels = c(paste0('PCL', 1:20))))\n#libraries\n\n\n\n1.1.1 Sample + library preparation\nThis cross-sectional study was conducted from 2017 to 2018 in the Boushehr Province, Iran. The individuals were recruited in one of the five transfusion clinics located in Boushehr. In total 100 healthy blood donors were included. Seven milliliters of blood were collected from each individual during blood transfusion or donation. Immediately after collection, plasma was separated from the samples and stored at −70 °C. Plasma samples were shipped under freezing conditions to the Laboratory for Clinical and Epidemiological Virology, Rega Institute, KU Leuven, Belgium.\nUpon arrival, the samples were processed in the laboratory. Initially, the samples were centrifuged and 100 µL of the supernatant was pooled with five samples per pool. The pooled plasma samples were subjected to an adapted version of the NetoVIR protocol for viral particle enrichment and metagenomic sequencing 20. To control for laboratory and environment contamination, negative controls were included in the different steps of the sample preparation procedure and pooled for sequencing. Pooled plasma samples and negative controls (H2O) were centrifuged for 3 min at 17,000× g and filtered through 0.8 µm polyether sulphone filters (Sartorius, Göttingen, Germany). To remove free-floating nucleic acids, the filtered samples were subjected to a nuclease treatment with a cocktail of 1 µL micrococcal nuclease (New England Biolabs, Ipswich, MA, USA) and 2 µL benzonase (Millipore, Burlington, United States) for 2 h at 37 °C. Both viral DNA and RNA were extracted (Viral RNA minikit, Qiagen, Hilden, Germany) and randomly amplified (including primary step of reverse transcription) with the Whole Transcriptome Amplification 2 kit (WTA2, Sigma Aldrich, Darmstadt, Germany) for 20 cycles.\nThe amplification product was purified with the MSB SPIN PCRAPACE kit (Stratec, Birkenfeld, Germany) and prepared for sequencing by using the Nextera XT kit (Illumina, San Diego, CA, USA). DNA products were quantified with the Qubit fluorometer (Thermo Fisher Scientific, Waltham, MA, USA), and the High-Sensitivity DNA kit (Agilent, Ratingen, Germany) for the Bioanalyzer 2100 (Agilent, Ratingen, Germany) was used to determine the average library fragment size. Samples were pooled in equimolar ratios, and paired-end sequencing (2 × 150 bp) was performed on a NextSeq 500 Illumina platform (Nucleomics Core, Leuven, Belgium) with an average of 10 million reads per sample."
  },
  {
    "objectID": "notebooks/2024-09-19-aydillo.html#quality-control-metrics",
    "href": "notebooks/2024-09-19-aydillo.html#quality-control-metrics",
    "title": "Workflow of Aydillo et al. (2022)",
    "section": "1.2 Quality control metrics",
    "text": "1.2 Quality control metrics\nIn total, these 20 samples contained ~116M read pairs. The samples had 1.3M - 11.1M (mean ~5.8M) read pairs each. The number of reads looks pretty good, although a few samples have a much lower number of reads. Considering the authors used these samples, we’ll use the same. The total number of base pairs also looks reasonable, matching the trends of the number of reads. The duplication rate is low. Adapter content is quite high for nextera-transposase-sequence. I believe this is library contamination, I need to look into this TODO. As we’d expect, we see higher quality Q scores near the beginning of the read and a gradual decline towards the end of the read, however all positions seem to have a Q score of 35 which means that our reads are ~99.97% accurate. When looking at the Q score over all sequences, we can see a sharp peak around 35, which corresponds to the previous plot, indicating high read quality.\n\n\nCode\n# Prepare data\nbasic_stats_raw_metrics &lt;- basic_stats_raw %&gt;%\n  select(library,\n         `# Read pairs` = n_read_pairs,\n         `Total base pairs\\n(approx)` = n_bases_approx,\n         `% Duplicates\\n(FASTQC)` = percent_duplicates) %&gt;%\n  pivot_longer(-library, names_to = \"metric\", values_to = \"value\") %&gt;%\n  mutate(metric = fct_inorder(metric)) \n\n# Set up plot templates\n\ng_basic &lt;- ggplot(basic_stats_raw_metrics, aes(x = library, y = value)) +\n  geom_col(position = \"dodge\") +\n  scale_x_discrete() +\n  scale_y_continuous(expand = c(0, 0)) +\n  expand_limits(y = c(0, 100)) +\n  facet_grid(metric ~ ., scales = \"free\", space = \"free_x\", switch = \"y\") +\n  theme_kit + theme(\n    axis.title.y = element_blank(),\n    strip.text.y = element_text(face = \"plain\")\n  )\ng_basic\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Set up plotting templates\ng_qual_raw &lt;- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters_raw &lt;- g_qual_raw + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats_raw) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,NA),\n                     breaks = seq(0,10,1), expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0)) +\n  facet_grid(.~adapter)\ng_adapters_raw\n\n\n\n\n\n\n\n\n\nCode\n# Visualize quality\ng_quality_base_raw &lt;- g_qual_raw +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats_raw) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0))\ng_quality_base_raw\n\n\n\n\n\n\n\n\n\nCode\ng_quality_seq_raw &lt;- g_qual_raw +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats_raw) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0))\ng_quality_seq_raw"
  },
  {
    "objectID": "notebooks/2024-09-19-aydillo.html#summary",
    "href": "notebooks/2024-09-19-aydillo.html#summary",
    "title": "Workflow of Aydillo et al. (2022)",
    "section": "2.1 Summary",
    "text": "2.1 Summary\nThe average fraction of reads at each stage in the preprocessing pipeline is shown in the following table. Adapter trimming & filtering doesn’t lose too many reads. Deduplication loses us about 30% of reads on average, then ribodepletion only loses as about 0.7% on average.\n\n\nCode\n# TODO: Group by pool size as well\n# Count read losses\nn_reads_rel &lt;- basic_stats %&gt;% \n  select(sample, stage, percent_duplicates, n_read_pairs) %&gt;%\n  group_by(sample) %&gt;% \n  arrange(sample, stage) %&gt;%\n  mutate(p_reads_retained = n_read_pairs / lag(n_read_pairs),\n         p_reads_lost = 1 - p_reads_retained,\n         p_reads_retained_abs = n_read_pairs / n_read_pairs[1],\n         p_reads_lost_abs = 1-p_reads_retained_abs,\n         p_reads_lost_abs_marginal = p_reads_lost_abs - lag(p_reads_lost_abs))\nn_reads_rel_display &lt;- n_reads_rel %&gt;% \n  rename(Stage=stage) %&gt;% \n  group_by(Stage) %&gt;% \n  summarize(`% Total Reads Lost (Cumulative)` = paste0(round(min(p_reads_lost_abs*100),1), \"-\", round(max(p_reads_lost_abs*100),1), \" (mean \", round(mean(p_reads_lost_abs*100),1), \")\"),\n            `% Total Reads Lost (Marginal)` = paste0(round(min(p_reads_lost_abs_marginal*100),1), \"-\", round(max(p_reads_lost_abs_marginal*100),1), \" (mean \", round(mean(p_reads_lost_abs_marginal*100),1), \")\"), .groups=\"drop\") %&gt;% \n  filter(Stage != \"raw_concat\") %&gt;%\n  mutate(Stage = Stage %&gt;% as.numeric %&gt;% factor(labels=c(\"Trimming & filtering\", \"Deduplication\", \"Initial ribodepletion\", \"Secondary ribodepletion\")))\nn_reads_rel_display"
  },
  {
    "objectID": "notebooks/2024-09-19-aydillo.html#quality-control-metrics-1",
    "href": "notebooks/2024-09-19-aydillo.html#quality-control-metrics-1",
    "title": "Workflow of Aydillo et al. (2022)",
    "section": "2.2 Quality control metrics",
    "text": "2.2 Quality control metrics\nHaven’t spent the time to interpret the adapter stuff as yet. Q score remain the same during read cleaning when looking at the positions, with the end of the read actually improving in score. Q scores across all sequences look pretty much the same throughout cleaning.\n\n\nCode\ng_qual &lt;- ggplot(mapping=aes(linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters &lt;- g_qual + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,20),\n                     breaks = seq(0,50,10), expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~adapter)\ng_adapters\n\n\n\n\n\n\n\n\n\nCode\n# Visualize quality\ng_quality_base &lt;- g_qual +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~.)\ng_quality_base\n\n\n\n\n\n\n\n\n\nCode\ng_quality_seq &lt;- g_qual +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0)) +\n  facet_grid(stage~., scales = \"free_y\")\ng_quality_seq\n\n\n\n\n\n\n\n\n\nThese plots below show the trends from above in each sample. All samples tend to follow similar trends for deduplication, with a large decrease in read length post adapter trimming. Ribosomal reads were quite low, near 1% for every sample.\n\n\nCode\ng_stage_trace &lt;- ggplot(basic_stats, aes(x=stage, group=sample)) +\n  theme_kit\n\n# Plot reads over preprocessing\ng_reads_stages &lt;- g_stage_trace +\n  geom_line(aes(y=n_read_pairs)) +\n  scale_y_continuous(\"# Read pairs\", expand=c(0,0), limits=c(0,NA))\ng_reads_stages\n\n\n\n\n\n\n\n\n\nCode\n# Plot relative read losses during preprocessing\ng_reads_rel &lt;- ggplot(n_reads_rel, \n                      aes(x=stage, group=sample)) +\n  geom_line(aes(y=p_reads_lost_abs_marginal)) +\n  scale_y_continuous(\"% Total Reads Lost\", expand=c(0,0), \n                     labels = function(x) x*100) +\n  theme_kit\ng_reads_rel\n\n\n\n\n\n\n\n\n\n\n\nCode\nstage_dup &lt;- basic_stats %&gt;% group_by(stage) %&gt;% \n  summarize(dmin = min(percent_duplicates), dmax=max(percent_duplicates),\n            dmean=mean(percent_duplicates), .groups = \"drop\")\n\ng_dup_stages &lt;- g_stage_trace +\n  geom_line(aes(y=percent_duplicates)) +\n  scale_y_continuous(\"% Duplicates\", limits=c(0,NA), expand=c(0,0))\ng_dup_stages\n\n\n\n\n\n\n\n\n\nCode\ng_readlen_stages &lt;- g_stage_trace + geom_line(aes(y=mean_seq_len)) +\n  scale_y_continuous(\"Mean read length (nt)\", expand=c(0,0), limits=c(0,NA))\ng_readlen_stages\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Calculate reads lost during ribodepletion (approximation for % ribosomal reads)\nreads_ribo &lt;- n_reads_rel %&gt;% \n  filter(stage %in% c(\"dedup\", \"ribo_secondary\")) %&gt;% \n  group_by(sample) %&gt;% \n  summarize(p_reads_ribo=1-n_read_pairs[2]/n_read_pairs[1], .groups = \"drop\") %&gt;%\n  inner_join(libraries, by = 'sample')\nreads_ribo_summ &lt;- reads_ribo %&gt;%\n  group_by(sample) %&gt;%\n  summarize(min=min(p_reads_ribo), max=max(p_reads_ribo),\n            mean=mean(p_reads_ribo), .groups = \"drop\") %&gt;%\n  inner_join(libraries, by = 'sample')\ng_reads_ribo &lt;- ggplot(reads_ribo, \n                       aes(x=library, y=p_reads_ribo)) +\n  geom_point() + \n  scale_y_continuous(name=\"Approx % ribosomal reads\", limits=c(0,1),\n                     breaks=seq(0,1,0.2), expand=c(0,0), labels = function(y) y*100)+\n  theme_kit\ng_reads_ribo"
  },
  {
    "objectID": "notebooks/2024-09-19-aydillo.html#high-level-composition",
    "href": "notebooks/2024-09-19-aydillo.html#high-level-composition",
    "title": "Workflow of Aydillo et al. (2022)",
    "section": "3.1 High-level composition",
    "text": "3.1 High-level composition\nTo assess the high-level composition of the reads, I ran the ribodepleted files through Kraken2 and summarized the results with Bracken.\nThe groups listed below were created by Will:\n\nFiltered (removed during cleaning)\nDuplicate (removed during deduplication)\nRibosomal (removed during ribodepletion)\nUnassigned (non-ribosomal reads that were not assigned to any taxon by Kraken/Bracken)\nBacterial (non-ribosomal reads assigned to the Bacteria domain by Kraken/Bracken)\nArchaeal (non-ribosomal reads assigned to the Archaea domain by Kraken/Bracken)\nViral (non-ribosomal reads assigned to the Viruses domain by Kraken/Bracken)\nHuman (non-ribosomal reads assigned to the Eukarya domain by Kraken/Bracken)\n\n\n\nCode\n# Prepare plotting templates\ng_comp_base &lt;- ggplot(mapping=aes(x=library, y=p_reads, fill=classification)) +\n  scale_x_discrete(name=\"Plasma pool\") +\n  theme_kit + \n  theme(plot.title = element_text(hjust=0, face=\"plain\", size=rel(1.5)))\nscale_y_pc_reads &lt;- purrr::partial(scale_y_continuous, name = \"% Reads\",\n                                   expand = c(0,0), labels = function(y) y*100)\ngeom_comp &lt;- purrr::partial(geom_col, position = \"stack\", width = 1)\n\n# Define a color palette for the classification\nclassification_colors &lt;- brewer.pal(8, \"Accent\")\nnames(classification_colors) &lt;- c(\"Filtered\", \"Duplicate\", \"Ribosomal\", \"Unassigned\", \"Bacterial\", \"Archaeal\", \"Viral\", \"Human\")\nscale_fill_classification &lt;- function() {\n  scale_fill_manual(values = classification_colors, name = \"Classification\")\n}\n\n# Plot overall composition\ng_comp &lt;- g_comp_base + geom_comp(data = comp) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (all reads, all groups)\")\ng_comp\n\n\n\n\n\n\n\n\n\nCode\ng_comp_assigned &lt;- g_comp_base + \n  geom_comp(data = comp_assigned) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (assigned reads, all groups)\")\ng_comp_assigned"
  },
  {
    "objectID": "notebooks/2024-09-19-aydillo.html#total-viral-content",
    "href": "notebooks/2024-09-19-aydillo.html#total-viral-content",
    "title": "Workflow of Aydillo et al. (2022)",
    "section": "3.2 Total viral content",
    "text": "3.2 Total viral content\nTotal viral fraction average \\(1.12 \\times 10^{-6}\\) across samples. As a fraction of assigned (rather than total) reads, this jumped to \\(2.96 \\times 10^{-6}\\):\n\n\nCode\np_reads_viral_all &lt;- comp %&gt;% filter(classification == \"Viral\") %&gt;%\n  mutate(read_group = \"All reads\")\np_reads_viral_assigned &lt;- comp_assigned %&gt;% filter(classification == \"Viral\") %&gt;%\n  mutate(read_group = \"Classified reads\")\np_reads_viral &lt;- bind_rows(p_reads_viral_all, p_reads_viral_assigned)\n\n# Plot\ng_viral &lt;- ggplot(p_reads_viral, aes(x=library, y=p_reads, color = read_group, group = library)) +\n  geom_point(size = 5) +\n  geom_line(color = 'black') +\n  scale_x_discrete(name=\"Plasma pool\") +\n  scale_y_log10(name=\"Viral read fraction\", labels = label_log(digits=2), limits = c(1e-6, 1e-2)) +\n  theme_kit + \n  coord_flip()\n\ng_viral\n\n\nWarning in scale_y_log10(name = \"Viral read fraction\", labels = label_log(digits = 2), : log-10 transformation introduced infinite values.\nlog-10 transformation introduced infinite values.\n\n\nWarning: Removed 44 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 44 rows containing missing values or values outside the scale range\n(`geom_line()`)."
  },
  {
    "objectID": "notebooks/2024-09-19-aydillo.html#taxonomic-composition-of-viruses",
    "href": "notebooks/2024-09-19-aydillo.html#taxonomic-composition-of-viruses",
    "title": "Workflow of Aydillo et al. (2022)",
    "section": "3.3 Taxonomic composition of viruses",
    "text": "3.3 Taxonomic composition of viruses\nThe two dominant viruses we see are Anellovirdae and Phycodnaviridae. The threshold for the label “other” are the set of families that make up less than 5% composition in all samples.\n\n\nCode\nmajor_threshold &lt;- 0.3\n\n# Identify major viral families\nviral_families_major_tab &lt;- viral_families %&gt;% \n  group_by(name, taxid) %&gt;%\n  summarize(p_reads_viral_max = max(p_reads_viral), .groups=\"drop\") %&gt;%\n  filter(p_reads_viral_max &gt;= major_threshold)\nviral_families_major_list &lt;- viral_families_major_tab %&gt;% pull(name)\nviral_families_major &lt;- viral_families %&gt;% \n  filter(name %in% viral_families_major_list) %&gt;%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_minor &lt;- viral_families_major %&gt;% \n  group_by(sample) %&gt;%\n  summarize(p_reads_viral_major = sum(p_reads_viral), .groups = \"drop\") %&gt;%\n  mutate(name = \"Other\", taxid=NA, p_reads_viral = 1-p_reads_viral_major) %&gt;%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_display &lt;- viral_families_major %&gt;% \n  bind_rows(viral_families_minor) %&gt;%\n  arrange(desc(p_reads_viral)) %&gt;% \n  mutate(name = factor(name, levels=c(viral_families_major_list, \"Other\"))) %&gt;%\n  rename(p_reads = p_reads_viral, classification=name) %&gt;%\n  inner_join(libraries, by='sample')\n\n\npal &lt;- c(brewer.pal(8, 'Dark2'),brewer.pal(8, 'Accent'), brewer.pal(8, 'Set1'), brewer.pal(8, 'Pastel1'), brewer.pal(8, 'Pastel2'))\n\nn_classifications &lt;- length(unique(viral_families_display$classification)) - 1\n\ncustom_palette_with_black &lt;- c(\n  pal[1:n_classifications],\n  \"black\"\n)\n\n# Plot\ng_families &lt;- g_comp_base + \n  geom_comp(data=viral_families_display) +\n  scale_y_continuous(name=\"% Viral Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_manual(values = custom_palette_with_black)\ng_families"
  },
  {
    "objectID": "notebooks/2024-09-19-aydillo.html#overall-relative-abundance",
    "href": "notebooks/2024-09-19-aydillo.html#overall-relative-abundance",
    "title": "Workflow of Aydillo et al. (2022)",
    "section": "4.1 Overall relative abundance",
    "text": "4.1 Overall relative abundance\nI calculated the relative abundance of human-infecting viruses in two ways:\n\nFirst, as the total number of deduplicated human-virus reads in each sample, divided by the number of raw reads (“All reads”). This results in a viral fraction of \\(1.5 \\times 10^{-6}\\) across all samples\nSecond, as a fraction of preprocessed (cleaned, deduplicated, computationally ribodepleted) reads (“Preprocessed reads”). This results in a viral fraction of \\(3.2 \\times 10^{-6}\\) across all samples.\n\n\n\nCode\n# Get raw read counts\nread_counts_raw &lt;- filter(basic_stats_raw) %&gt;%\n  select(sample, n_reads_raw = n_read_pairs)\nread_counts_preproc &lt;- basic_stats %&gt;% filter(stage == \"ribo_initial\") %&gt;%\n  select(sample, n_reads_preproc = n_read_pairs)\n\n# Get HV read counts\nread_counts_hv &lt;- mrg_hv %&gt;% filter(hv_status) %&gt;% \n  group_by(sample) %&gt;% \n  count(name=\"n_reads_hv\")\nread_counts &lt;- read_counts_raw %&gt;%\n  left_join(read_counts_hv, by=c(\"sample\")) %&gt;%\n  mutate(n_reads_hv = replace_na(n_reads_hv, 0)) %&gt;%\n  left_join(read_counts_preproc, by=c(\"sample\")) %&gt;%\n  inner_join(libraries, by=c(\"sample\")) %&gt;%\n  select(sample, n_reads_raw, n_reads_preproc, n_reads_hv) %&gt;%\n  mutate(n_samples = 1,\n         p_reads_total = n_reads_hv/n_reads_raw,\n         p_reads_preproc = n_reads_hv/n_reads_preproc)\nread_counts_long &lt;- read_counts %&gt;%\n  pivot_longer(starts_with(\"p_reads\"), names_to=\"read_group\", values_to=\"p_reads\") %&gt;%\n  mutate(read_group = ifelse(read_group == \"p_reads_total\", \"All reads\", \"Preprocessed reads\"))\n\n# Combine for display\nread_counts_agg &lt;- read_counts %&gt;%\n  mutate(p_reads_total = n_reads_hv/n_reads_raw,\n         p_reads_preproc = n_reads_hv/n_reads_preproc) %&gt;%\n  inner_join(libraries, by=c(\"sample\"))\nread_counts_agg_long &lt;- read_counts_agg %&gt;%\n  pivot_longer(starts_with(\"p_reads\"), names_to=\"read_group\", values_to=\"p_reads\") %&gt;%\n  mutate(read_group = ifelse(read_group == \"p_reads_total\", \"All reads (HV)\", \"Preprocessed reads (HV)\")) \n\n# Visualize\ng_read_counts &lt;- ggplot(read_counts_agg_long, aes(x=library, y=p_reads, color = read_group, group = library)) +\n  geom_point(size = 5) +\n  geom_line(color = 'black') +\n  scale_y_log10(name = \"Unique human-viral read fraction\", labels = label_log(digits=2), limits = c(1e-6, 1e-2)) +\n  theme_kit + \n  coord_flip()\ng_read_counts"
  },
  {
    "objectID": "notebooks/2024-09-19-aydillo.html#overall-taxonomy-and-composition",
    "href": "notebooks/2024-09-19-aydillo.html#overall-taxonomy-and-composition",
    "title": "Workflow of Aydillo et al. (2022)",
    "section": "4.2 Overall taxonomy and composition",
    "text": "4.2 Overall taxonomy and composition\nComposition of HV reads was changed from when looking at all viral reads. The two dominant viruses we see are Anellovirdae and Microviridae (bacteriophage). The threshold for the label “other” are the set of families that make up less than 5% composition in all samples.\n\n\nCode\nthreshold_major_family &lt;- 0.05\n\n# Count reads for each human-viral family\nhv_family_counts &lt;- hv_reads_family %&gt;% \n  group_by(sample, name, taxid) %&gt;%\n  count(name = \"n_reads_hv\") %&gt;%\n  group_by(sample) %&gt;%\n  mutate(p_reads_hv = n_reads_hv/sum(n_reads_hv))\n\n# Identify high-ranking families and group others\nhv_family_major_tab &lt;- hv_family_counts %&gt;% group_by(name) %&gt;% \n  filter(p_reads_hv == max(p_reads_hv)) %&gt;% filter(row_number() == 1) %&gt;%\n  arrange(desc(p_reads_hv)) %&gt;% filter(p_reads_hv &gt; threshold_major_family)\nhv_family_counts_major &lt;- hv_family_counts %&gt;%\n  mutate(name_display = ifelse(name %in% hv_family_major_tab$name, name, \"Other\")) %&gt;%\n  group_by(sample, name_display) %&gt;%\n  summarize(n_reads_hv = sum(n_reads_hv), p_reads_hv = sum(p_reads_hv), \n            .groups=\"drop\") %&gt;%\n  mutate(name_display = factor(name_display, \n                               levels = c(hv_family_major_tab$name, \"Other\")))\nhv_family_counts_display &lt;- hv_family_counts_major %&gt;%\n  rename(p_reads = p_reads_hv, classification = name_display) %&gt;%\n  inner_join(libraries, by = 'sample')\n\n# Plot\ng_hv_family &lt;- g_comp_base + \n  geom_col(data=hv_family_counts_display, position = \"stack\", width=1) +\n  scale_y_continuous(name=\"% HV Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_brewer(palette = 'Accent', name = \"Viral family\") +\n  labs(title=\"Family composition of human-viral reads\") +\n  guides(fill=guide_legend(ncol=4)) +\n  theme(plot.title = element_text(size=rel(1.4), hjust=0, face=\"plain\"))\ng_hv_family\n\n\n\n\n\n\n\n\n\nCode\n# Get most prominent families for text\nhv_family_collate &lt;- hv_family_counts %&gt;%\n  group_by(name, taxid) %&gt;% \n  summarize(n_reads_tot = sum(n_reads_hv),\n            p_reads_max = max(p_reads_hv), .groups=\"drop\") %&gt;% \n  arrange(desc(n_reads_tot))\nhv_family_collate"
  },
  {
    "objectID": "notebooks/2024-09-19-aydillo.html#analyzing-specific-families",
    "href": "notebooks/2024-09-19-aydillo.html#analyzing-specific-families",
    "title": "Workflow of Aydillo et al. (2022)",
    "section": "4.3 Analyzing specific families",
    "text": "4.3 Analyzing specific families\nWe now investigate the composition of specific families that had more than 5 viral reads. In investigating individual viral families, to avoid distortions from a few rare reads, I restricted myself to samples where that family made up at least 1% of human-viral reads:\n\n4.3.1 Flaviviridae (Number of reads: 594)\n\n\nCode\n# Flaviviridae\nplot_viral_family_histogram(taxid_chosen=11050)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Flaviviridae\nplot_viral_family_composition(taxid_chosen=11050, threshold_major_species = 0.01)"
  },
  {
    "objectID": "notebooks/2024-09-19-aydillo.html#relative-abundance-of-pathogenic-viruses-of-interest",
    "href": "notebooks/2024-09-19-aydillo.html#relative-abundance-of-pathogenic-viruses-of-interest",
    "title": "Workflow of Aydillo et al. (2022)",
    "section": "4.4 Relative abundance of pathogenic viruses of interest",
    "text": "4.4 Relative abundance of pathogenic viruses of interest\nEach dot represents a sample, colored by viral family. The x-axis shows the relative abundance of human-infecting viruses, and the y-axis shows the species.\n\n\nCode\nspecies_family &lt;- result %&gt;% select(species, family) %&gt;% rename('name' = 'species')\n\nplay &lt;- hv_species_counts %&gt;% \n  ungroup() %&gt;%\n  inner_join(libraries, by = 'sample') %&gt;%\n  inner_join(species_family, by = 'name') %&gt;%\n  mutate(name = ifelse(name == \"Severe acute respiratory syndrome-related coronavirus\", \"SARS-related coronavirus\", name))\n\nadjusted_play &lt;- play %&gt;% \n  group_by(name) %&gt;%\n  mutate(virus_prevalence_num = n_distinct(sample)/n_distinct(libraries),\n         total_reads_hv = sum(n_reads_hv)) %&gt;%\n  ungroup() %&gt;%\n  mutate(name = fct_reorder(name, virus_prevalence_num, .desc=TRUE)) %&gt;% \n  select(name, ra_reads_hv, family, virus_prevalence_num, total_reads_hv, n_reads_hv)\n\npal &lt;- c(brewer.pal(8, 'Dark2'),brewer.pal(8, 'Accent'))\n\n#, labels = label_log(digits=2)\n\nra_dot &lt;- ggplot(adjusted_play, aes(x = ra_reads_hv, y=name)) +\n  geom_quasirandom(orientation = 'y', aes(color = family)) +\n  scale_color_manual(values = pal) + \n    scale_x_log10(\n    \"Relative abundance human virus reads\",\n    labels=label_log(digits=3)\n  ) +\n  labs(y =  \"\",\n       color = 'Viral family') + \n  guides(color = guide_legend(ncol=2)) +\n  theme_light() + \n    theme(\n    axis.text.y = element_text(size = 10),\n    axis.text.x = element_text(size = 12),\n    axis.ticks.y = element_blank(),axis.line = element_line(colour = \"black\"),\n    axis.title.x = element_text(size = 14),    \n    legend.text = element_text(size = 10),\n    legend.title = element_text(size = 10, face=\"bold\"),\n    #legend.position = 'bottom',\n    legend.position = c(1, 1),  # Move legend to top right\n    legend.justification = c(1, 1),  # Align legend to top right\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank())\nra_dot\n\n\n\n\n\n\n\n\n\nI can then take all of the viruses that we found and look up what they’re responsible for and whether they’re dangerous.\n\n\n\n\n\n\n\n\nVirus Name\nCommon Name\nPathogenic Potential\n\n\n\n\nCytomegalovirus humanbeta5\nHuman Cytomegalovirus\nModerate to high, can cause severe disease in immunocompromised individuals and congenital infections\n\n\nPegivirus hominis\nHuman Pegivirus\nVery low, not known to cause disease in humans\n\n\n\nThis was interesting to see. This is the first study where we’ve seen signficant numbers of human-infecting viruses in whole blood."
  },
  {
    "objectID": "notebooks/2024-09-19-aydillo.html#relative-abundance-assuming-perfect-human-read-removal",
    "href": "notebooks/2024-09-19-aydillo.html#relative-abundance-assuming-perfect-human-read-removal",
    "title": "Workflow of Aydillo et al. (2022)",
    "section": "4.5 Relative abundance assuming perfect human read removal",
    "text": "4.5 Relative abundance assuming perfect human read removal\nAssuming we’re able to perfectly remove all human reads, the average relative abundance of known human infecting virus is \\(1.91 \\times 10^{-5}\\)."
  },
  {
    "objectID": "notebooks/2024-09-19-aydillo.html#human-infecting-virus-families-genera-and-species",
    "href": "notebooks/2024-09-19-aydillo.html#human-infecting-virus-families-genera-and-species",
    "title": "Workflow of Aydillo et al. (2022)",
    "section": "6.1 Human-infecting virus families, genera, and species",
    "text": "6.1 Human-infecting virus families, genera, and species\nTo get a good overview of families, genera, and species, we can look at a Sankey plot where the magnitude of relative abundance, averaged over all samples, is shown in parentheses.\n\n\nCode\n# Function to create links\ncreate_links &lt;- function(data) {\n  family_to_genus &lt;- data %&gt;%\n    filter(!is.na(genus)) %&gt;%\n    group_by(family, genus) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = genus)\n  \n  genus_to_species &lt;- data %&gt;%\n    group_by(genus, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = genus, target = species)\n\n  family_to_species &lt;- data %&gt;%\n    filter(is.na(genus)) %&gt;%\n    group_by(family, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = species)\n\n  bind_rows(family_to_genus, genus_to_species, family_to_species) %&gt;%\n    filter(!is.na(source))\n}\n\n# Function to create nodes\ncreate_nodes &lt;- function(links) {\n  data.frame(\n    name = c(links$source, links$target) %&gt;% unique()\n  )\n}\n\n# Function to prepare data for Sankey diagram\nprepare_sankey_data &lt;- function(links, nodes) {\n  links$IDsource &lt;- match(links$source, nodes$name) - 1\n  links$IDtarget &lt;- match(links$target, nodes$name) - 1\n  list(links = links, nodes = nodes)\n}\n\n# Function to create Sankey plot\ncreate_sankey_plot &lt;- function(sankey_data) {\n  sankeyNetwork(\n    Links = sankey_data$links, \n    Nodes = sankey_data$nodes,\n    Source = \"IDsource\", \n    Target = \"IDtarget\",\n    Value = \"value\", \n    NodeID = \"name\",\n    sinksRight = TRUE,\n    nodeWidth = 25,\n    fontSize = 14,\n  )\n}\n\nsave_sankey_as_png &lt;- function(sankey_plot, width = 1000, height = 800) {\n  # Save the plot as an HTML file\n  saveWidget(sankey_plot, sprintf('%s/sankey.html',data_dir))\n}\n\nformat_scientific &lt;- function(x, digits=2) {\n  sapply(x, function(val) {\n    if (is.na(val) || abs(val) &lt; 1e-15) {\n      return(\"0\")\n    } else {\n      exponent &lt;- floor(log10(abs(val)))\n      coef &lt;- val / 10^exponent\n      #return(sprintf(\"%.1f × 10^%d\", round(coef, digits), exponent))\n      # May or may not be smart, just keeping magnitude\n      return(sprintf(\"10^%d\", exponent))\n    }\n  })\n}\n\ndata &lt;- result %&gt;% \n  mutate(across(c(genus_n_reads_tot, genus_ra_reads_tot), ~replace_na(., 0)),\n         genus = ifelse(is.na(genus), \"Unknown Genus\", genus)) %&gt;%\n  mutate(\n  species = paste0(species, sprintf(' (%s)', format_scientific(species_ra_reads_tot))),\n  genus = paste0(genus, sprintf(' (%s)', format_scientific(genus_ra_reads_tot))),\n  family = paste0(family, sprintf(' (%s)', format_scientific(family_ra_reads_tot)))\n)\nlinks &lt;- as.data.frame(create_links(data))\nnodes &lt;- create_nodes(links)\nsankey_data &lt;- prepare_sankey_data(links, nodes)\nsankey &lt;- create_sankey_plot(sankey_data)\n\nsankey"
  }
]