[
  {
    "objectID": "notebooks/2024-07-23-mengyi.html",
    "href": "notebooks/2024-07-23-mengyi.html",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "",
    "text": "This one of the studies that we hope to discuss in our third blog post, which will cover the metagenomic analysis of whole blood/plasma. In this notebook, I analyze Mengyi 2023, a dataset from China with 201 pools of plasma, where each pool contains 160 samples (we don’t know whether 1 sample = 1 donation) from 7 different locations, for a total of 10,720 samples.\nI’d like to thank Lenni for giving me feedback on the notebook, Will for providing me with a boilerplate rmarkdown file, and Simon for giving me feedback on my figures. This notebook uses the MGS Workflow v2.2.1 (note that this is old)."
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#about",
    "href": "notebooks/2024-07-23-mengyi.html#about",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n1.1 About",
    "text": "1.1 About\nThis dataset from China has 201 pools of plasma, where each pool contains 160 samples from 7 different locations between 2012-2018, for a total of 10,720 samples. This paper did not discuss the number of individuals that contributed to the samples, but we’re going to attempt to contact the authors to get this information (this shouldn’t hold up any further analysis, but would be good to have this information). They did DNA-sequencing for each pool, with Illumina HiSeq 4500, producing 2x150 bp reads.\n\nCode# Import libraries and extract metadata from sample names\nlibraries &lt;- read_csv(libraries_path, show_col_types = FALSE)\nmetadata &lt;- read_tsv(sprintf('%s/metadata.tsv', data_dir), show_col_types = FALSE) %&gt;%\n  select('sample'=`Library`, `library`=`Sample title`, 'Geographic location') %&gt;%\n  mutate('location' = str_split(`Geographic location`, \":\", simplify = TRUE)[, ncol(str_split(`Geographic location`, \":\", simplify = TRUE))])\nlibraries &lt;- libraries %&gt;%\n  left_join(metadata, by = 'sample') %&gt;%\n  select(sample, library=library.y, location) %&gt;%\n  mutate(library = factor(library))\n\nlibraries %&gt;% group_by(location) %&gt;% summarize(n_pools = n())\n\n\n  \n\n\n\n\n1.1.1 Sample + library preparation\nThe following excerpt from the paper describes the sample and library preparation process. It’s crucial to note that while blood samples were initially collected from volunteers, these samples were converted to plasma through ultracentrifugation prior to sequencing:\n\nFrom January 1, 2012, to December 31, 2018, a total of 10,720 blood samples of 10 ml each were randomly selected from voluntary blood donors in 7 regions. The blood samples taken from various places were mixed in units of 160 (each 100 μl) for ultracentrifugation (32,000 rpm, 120 min, maximum centrifugal radius of 91.9 mm). Afterward, we rinsed and resuspended the precipitate with 500 μl PBS.\nThe pooled suspensions were subjected to extraction of total DNA using QIAamp® DNA Blood mini Kit (QIAGEN Cat. NO.160019269, Frankfurt, Germany), DNA concentration was measured by Equalbit® 1 × dsDNA HS Assay Kit (Vazyme Cat. NO. 7E302K9, Nanjing, China).\nThe metagenomic library was constructed using KAPA HyperPlus Kit (KAPA Cat. NO. 0000097583, Boston, USA) with dual-indexed Adapters (KAPA Cat. NO. 0000093370, Boston, USA), the DNA was fragmented to 250 bp approximately by the enzyme at 37 °C for 20 min, after end repair and A-tailing, adapter ligation, post-ligation cleanup, library amplification, and post-amplification cleanup, the library was constructed.\nAgilent 2100 Bioanalyzer (Agilent Technologies, Beijing, China) was used for library quality control, and qualified DNA library was sent to the Novogene company to sequence in HiSeq 4500."
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#quality-control-metrics",
    "href": "notebooks/2024-07-23-mengyi.html#quality-control-metrics",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n1.2 Quality control metrics",
    "text": "1.2 Quality control metrics\nThese 201 samples contained 3.4B read pairs. The samples had 8.2M - 30.1M (mean 17.1M) read pairs each. The number of read pairs and total bases look relatively evenly distributed across the locations. The duplication rate is also quite low, around ~10%. Adapter content is low. As we’d expect, we see higher quality Q scores near the beginning of the read and a gradual decline towards the end of the read, however all positions seem to have a Q score of 35 which means that our reads are ~99.97% accurate. When looking at the Q score over all sequences, we can see a sharp peak after 35, which closely follows the previous plot, indicating high read quality.\n\nCode# Prepare data\nbasic_stats_raw_metrics &lt;- basic_stats_raw %&gt;%\n  select(library,\n         location,\n         `# Read pairs` = n_read_pairs,\n         `Total base pairs\\n(approx)` = n_bases_approx,\n         `% Duplicates\\n(FASTQC)` = percent_duplicates) %&gt;%\n  pivot_longer(-(library:location), names_to = \"metric\", values_to = \"value\") %&gt;%\n  mutate(metric = fct_inorder(metric)) \n\n# Set up plot templates\n\ng_basic &lt;- ggplot(basic_stats_raw_metrics, aes(x = library, y = value, fill=location)) +\n  geom_col(position = \"dodge\") +\n  scale_x_discrete() +\n  scale_fill_brewer(palette = \"Dark2\") +\n  scale_y_continuous(expand = c(0, 0)) +\n  expand_limits(y = c(0, 100)) +\n  facet_grid(metric ~ ., scales = \"free\", space = \"free_x\", switch = \"y\") +\n  theme_kit + theme(\n    axis.title.y = element_blank(),\n    strip.text.y = element_text(face = \"plain\"),\n    axis.text.x = element_blank()\n  )\ng_basic\n\n\n\n\n\n\n\n\nCode# Set up plotting templates\ng_qual_raw &lt;- ggplot(mapping=aes(color = location, linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  scale_color_brewer(palette = \"Dark2\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters_raw &lt;- g_qual_raw + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats_raw) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,5),\n                     expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0)) +\n  facet_grid(.~adapter)\ng_adapters_raw\n\n\n\n\n\n\nCode# Visualize quality\ng_quality_base_raw &lt;- g_qual_raw +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats_raw) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,500,20), expand=c(0,0))\ng_quality_base_raw\n\n\n\n\n\n\nCodeg_quality_seq_raw &lt;- g_qual_raw +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats_raw) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0))\ng_quality_seq_raw"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#summary",
    "href": "notebooks/2024-07-23-mengyi.html#summary",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n2.1 Summary",
    "text": "2.1 Summary\nThe average fraction of reads at each stage in the preprocessing pipeline is shown in the following table. Reads lost during trimming and filtering approximately matches what we’d expect based on the raw adapter content. Deduplication loses us about 10% of reads which matched the amount of estimated duplicated reads by QC. Low ribodepletion is observed which makes sense because they only sequenced DNA.\n\nCode# TODO: Group by pool size as well\n# Count read losses\nn_reads_rel &lt;- basic_stats %&gt;% \n  select(sample,location, stage, percent_duplicates, n_read_pairs) %&gt;%\n  group_by(sample) %&gt;% \n  arrange(sample, stage) %&gt;%\n  mutate(p_reads_retained = n_read_pairs / lag(n_read_pairs),\n         p_reads_lost = 1 - p_reads_retained,\n         p_reads_retained_abs = n_read_pairs / n_read_pairs[1],\n         p_reads_lost_abs = 1-p_reads_retained_abs,\n         p_reads_lost_abs_marginal = p_reads_lost_abs - lag(p_reads_lost_abs))\nn_reads_rel_display &lt;- n_reads_rel %&gt;% \n  rename(Stage=stage) %&gt;% \n  group_by(Stage) %&gt;% \n  summarize(`% Total Reads Lost (Cumulative)` = paste0(round(min(p_reads_lost_abs*100),1), \"-\", round(max(p_reads_lost_abs*100),1), \" (mean \", round(mean(p_reads_lost_abs*100),1), \")\"),\n            `% Total Reads Lost (Marginal)` = paste0(round(min(p_reads_lost_abs_marginal*100),1), \"-\", round(max(p_reads_lost_abs_marginal*100),1), \" (mean \", round(mean(p_reads_lost_abs_marginal*100),1), \")\"), .groups=\"drop\") %&gt;% \n  filter(Stage != \"raw_concat\") %&gt;%\n  mutate(Stage = Stage %&gt;% as.numeric %&gt;% factor(labels=c(\"Trimming & filtering\", \"Deduplication\", \"Initial ribodepletion\", \"Secondary ribodepletion\")))\nn_reads_rel_display"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#quality-control-metrics-1",
    "href": "notebooks/2024-07-23-mengyi.html#quality-control-metrics-1",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n2.2 Quality control metrics",
    "text": "2.2 Quality control metrics\nTrimming and cleaning gets rid of the Illumina adapter as well as polyg, and we see a decrease in polya. Q score remain the same during read cleaning when looking at the positions, with the end of the read actually improving in score. Q scores across all sequences look pretty much the same throughout cleaning.\n\nCodeg_qual &lt;- ggplot(mapping=aes(color = location, linetype=read_pair, group=interaction(sample,read_pair))) + \n  scale_linetype_discrete(name = \"Read Pair\") +\n  scale_color_brewer(palette = \"Dark2\") +\n  guides(color=guide_legend(nrow=2,byrow=TRUE),\n         linetype = guide_legend(nrow=2,byrow=TRUE)) +\n  theme_base\n\n# Visualize adapters\ng_adapters &lt;- g_qual + \n  geom_line(aes(x=position, y=pc_adapters), data=adapter_stats) +\n  scale_y_continuous(name=\"% Adapters\", limits=c(0,5),\n                     expand=c(0,0)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~adapter)\ng_adapters\n\n\n\n\n\n\nCode# Visualize quality\ng_quality_base &lt;- g_qual +\n  geom_hline(yintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_hline(yintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=position, y=mean_phred_score), data=quality_base_stats) +\n  scale_y_continuous(name=\"Mean Phred score\", expand=c(0,0), limits=c(10,45)) +\n  scale_x_continuous(name=\"Position\", limits=c(0,NA),\n                     breaks=seq(0,140,20), expand=c(0,0)) +\n  facet_grid(stage~.)\ng_quality_base\n\n\n\n\n\n\nCodeg_quality_seq &lt;- g_qual +\n  geom_vline(xintercept=25, linetype=\"dashed\", color=\"red\") +\n  geom_vline(xintercept=30, linetype=\"dashed\", color=\"red\") +\n  geom_line(aes(x=mean_phred_score, y=n_sequences), data=quality_seq_stats) +\n  scale_x_continuous(name=\"Mean Phred score\", expand=c(0,0)) +\n  scale_y_continuous(name=\"# Sequences\", expand=c(0,0)) +\n  facet_grid(stage~., scales = \"free_y\")\ng_quality_seq\n\n\n\n\n\n\n\nNumber of read pairs look reasonable, same with a large portion being lost during deduplication. At the end of deduplication it seems that only 5% of reads are duplicates which doesn’t seem too bad. Mean read length stays around 150 bp which is pretty good.\n\nCodeg_stage_trace &lt;- ggplot(basic_stats, aes(x=stage, group=sample, color = location)) +\n  theme_kit +\n  scale_color_brewer(palette = \"Dark2\")\n# Plot reads over preprocessing\ng_reads_stages &lt;- g_stage_trace +\n  geom_line(aes(y=n_read_pairs)) +\n  scale_y_continuous(\"# Read pairs\", expand=c(0,0), limits=c(0,NA))\ng_reads_stages\n\n\n\n\n\n\nCode# Plot relative read losses during preprocessing\ng_reads_rel &lt;- ggplot(n_reads_rel, \n                      aes(x=stage, group=sample, color = location)) +\n  geom_line(aes(y=p_reads_lost_abs_marginal)) +\n  scale_y_continuous(\"% Total Reads Lost\", expand=c(0,0), \n                     labels = function(x) x*100) +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme_kit\ng_reads_rel\n\n\n\n\n\n\n\n\nCodestage_dup &lt;- basic_stats %&gt;% group_by(stage) %&gt;% \n  summarize(dmin = min(percent_duplicates), dmax=max(percent_duplicates),\n            dmean=mean(percent_duplicates), .groups = \"drop\")\n\ng_dup_stages &lt;- g_stage_trace +\n  geom_line(aes(y=percent_duplicates)) +\n  scale_y_continuous(\"% Duplicates\", limits=c(0,NA), expand=c(0,0))\ng_dup_stages\n\n\n\n\n\n\n\n\nCodeg_readlen_stages &lt;- g_stage_trace + geom_line(aes(y=mean_seq_len)) +\n  scale_y_continuous(\"Mean read length (nt)\", expand=c(0,0), limits=c(0,NA))\ng_readlen_stages\n\n\n\nReminder that this data is 2x150 bp."
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#high-level-composition",
    "href": "notebooks/2024-07-23-mengyi.html#high-level-composition",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n3.1 High-level composition",
    "text": "3.1 High-level composition\nTo assess the high-level composition of the reads, I ran the files through Kraken2 and summarized the results with Bracken.\nThe groups listed below were created by Will:\n\nFiltered (removed during cleaning)\nDuplicate (removed during deduplication)\nRibosomal (removed during ribodepletion)\nUnassigned (non-ribosomal reads that were not assigned to any taxon by Kraken/Bracken)\nBacterial (non-ribosomal reads assigned to the Bacteria domain by Kraken/Bracken)\nArchaeal (non-ribosomal reads assigned to the Archaea domain by Kraken/Bracken)\nViral (non-ribosomal reads assigned to the Viruses domain by Kraken/Bracken)\nHuman (non-ribosomal reads assigned to the Eukarya domain by Kraken/Bracken)\n\nHuman reads make up a large proportion of all reads at 82% total composition, whereas viruses only account for 0.01% of all reads.\n\nCodeclassifications &lt;- c(\"Filtered\", \"Duplicate\", \"Ribosomal\", \"Unassigned\",\n                     \"Bacterial\", \"Archaeal\", \"Viral\", \"Human\")\n\n# Import composition data\ntax_final_dir &lt;- file.path(results_dir, \"taxonomy_final\")\ncomp &lt;- read_tsv(sprintf(\"%s/taxonomic_composition.tsv.gz\", tax_final_dir)) %&gt;% \n  inner_join(libraries, by='sample')\n\ncomp_minor &lt;- comp %&gt;% \n  filter(classification %in% c(\"Archaeal\", \"Viral\", \"Human\", \"Other\"))\ncomp_assigned &lt;- comp %&gt;%\n  filter(! classification %in% c(\"Filtered\", \"Duplicate\", \n                                 \"Ribosomal\", \"Unassigned\")) %&gt;%\n  group_by(sample) %&gt;%\n  mutate(p_reads = n_reads/sum(n_reads))\ncomp_assigned_minor &lt;- comp_assigned %&gt;% \n  filter(classification %in% c(\"Archaeal\", \"Viral\", \"Human\", \"Other\"))\n\n# Summarize composition\nread_comp_summ &lt;- comp %&gt;% \n  group_by(classification) %&gt;%\n  summarize(n_reads = sum(n_reads), .groups = \"drop_last\") %&gt;%\n  mutate(n_reads = replace_na(n_reads,0),\n         p_reads = n_reads/sum(n_reads),\n         pc_reads = p_reads*100) %&gt;%\n  mutate(classification = factor(classification, levels=classifications)) %&gt;%\n  select(classification, n_reads, pc_reads) %&gt;%\n  rename(`# of reads` = n_reads, \"% of reads\" = pc_reads) %&gt;%\n  mutate(`% of reads` = sprintf(\"%.2f\", `% of reads`))\nread_comp_summ\n\n\n  \n\n\n\n\nCode# Prepare plotting templates\ng_comp_base &lt;- ggplot(mapping=aes(x=library, y=p_reads, fill=classification)) +\n  scale_x_discrete(name=\"Plasma pool\") +\n  theme_kit + \n  theme(plot.title = element_text(hjust=0, face=\"plain\", size=rel(1.5)),\n        axis.text.x = element_blank())\n\nscale_y_pc_reads &lt;- purrr::partial(scale_y_continuous, name = \"% Reads\",\n                                   expand = c(0,0), labels = function(y) y*100)\ngeom_comp &lt;- purrr::partial(geom_col, position = \"stack\", width = 1)\n\n# Define a color palette for the classification\nclassification_colors &lt;- brewer.pal(8, \"Accent\")\nnames(classification_colors) &lt;- c(\"Filtered\", \"Duplicate\", \"Ribosomal\", \"Unassigned\", \"Bacterial\", \"Archaeal\", \"Viral\", \"Human\")\nscale_fill_classification &lt;- function() {\n  scale_fill_manual(values = classification_colors, name = \"Classification\")\n}\n\n# Plot overall composition\ng_comp &lt;- g_comp_base + geom_comp(data = comp) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (all reads, all groups)\")\ng_comp\n\n\n\n\n\n\nCode# Create a faceted plot of composition by location\n#g_comp_by_location &lt;- g_comp_base +\n#  geom_comp(data = comp) +\n#  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n#  scale_fill_classification() +\n#  facet_wrap(~ location, scales = \"free_x\", ncol = 2) +\n#  theme(axis.text.x = element_blank(),  # Remove x-axis labels\n#        axis.ticks.x = element_blank()) +  # Remove x-axis ticks\n#  ggtitle(\"Read composition (all reads, all groups)\")\n\n# Display the plot\n#g_comp_by_location\n\n# Repeat for classified reads only\ng_comp_assigned &lt;- g_comp_base + \n  geom_comp(data = comp_assigned) +\n  scale_y_pc_reads(limits = c(0,1.01), breaks = seq(0,1,0.2)) +\n  scale_fill_classification() + \n  ggtitle(\"Read composition (assigned reads, all groups)\")\ng_comp_assigned\n\n\n\n\n\n\nCode# Plot composition of minor components\n#g_comp_minor &lt;- g_comp_base + \n#  geom_comp(data=comp_minor) +\n#  scale_y_pc_reads() +\n#  scale_fill_classification() + \n#  ggtitle(\"Read composition (all reads, minor groups)\")\n#g_comp_minor\n#g_comp_assigned_minor &lt;- g_comp_base + \n#  geom_comp(data=comp_assigned_minor) +\n#  scale_y_pc_reads() +\n#  scale_fill_classification() + \n#  ggtitle(\"Read composition (assigned reads, minor groups)\")\n#g_comp_assigned_minor"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#total-viral-content",
    "href": "notebooks/2024-07-23-mengyi.html#total-viral-content",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n3.2 Total viral content",
    "text": "3.2 Total viral content\nTotal viral fraction average \\(1.03 \\times 10^{-4}\\) across samples. As a fraction of assigned (rather than total) reads, this jumped to \\(1.28 \\times 10^{-4}\\). The increase in viral fraction from assigned reads to total reads was constant across all samples, however, we can see that the viral fractions differed by location. Note that one of the pools from “Heilongjiang,Mudanjiang” had no viral reads.\n\nCode#p_reads_viral_all &lt;- comp %&gt;% filter(classification == \"Viral\") %&gt;%\n#  mutate(read_group = \"All reads\")\np_reads_viral_assigned &lt;- comp_assigned %&gt;% filter(classification == \"Viral\") %&gt;%\n  mutate(read_group = \"Classified reads\")\n#p_reads_viral &lt;- bind_rows(p_reads_viral_all, p_reads_viral_assigned)\n\nlocation_viral &lt;- comp_assigned %&gt;% filter(classification == \"Viral\" ) %&gt;% group_by(location) \n\n# Plot\n# g_viral &lt;- ggplot(p_reads_viral, aes(x=p_reads, y=library, color=location, shape=read_group)) +\n#   geom_point() +\n#   scale_y_discrete(name=\"Plasma pool\") +\n#   scale_x_log10(name=\"Viral read fraction\") +\n#   scale_color_brewer(palette = \"Dark2\") +\n#   #facet_grid(.~read_group, scales = \"free\") +\n#   guides(color=guide_legend(nrow=2), shape=guide_legend(nrow=2),\n#          linetype=guide_legend(nrow=2)) +\n#   theme_kit\n\n#ggplot(location_viral, aes(x=p_reads, y=location, color = location)) +\n#  geom_quasirandom(size=2) +\n#  scale_x_log10(name=\"Viral read fraction\", labels = label_log(digits=2)) +\n#  scale_y_discrete(name=\"Location\") +\n#  scale_color_brewer(palette = \"Dark2\") +\n#  theme_light() + \n#    theme(\n#    axis.text.y = element_text(size = 8),\n#    axis.text.x = element_text(size = 14),\n#    axis.ticks.y = element_blank(),\n#    axis.line = element_line(colour = \"black\"),\n#    axis.title.x = element_text(size = 15),    \n#    axis.title.y = element_text(size = 15),  \n#    legend.text = element_text(size = 13),\n#    legend.title = element_text(size = 16),\n#    legend.position = c(1, 1),  # Move legend to top right\n##    legend.justification = c(1, 1),  # Align legend to top right\n#    panel.grid.minor = element_blank(),\n#    panel.border = element_blank(),\n#    panel.background = element_blank())\n\n# Calculate the number of samples per location\nlocation_counts &lt;- location_viral %&gt;%\n  group_by(location) %&gt;%\n  summarise(count = n()) %&gt;%\n  mutate(label = paste0(location, \" (n=\", count, \")\"))\n\n# Create a named vector for easy mapping\nlocation_labels &lt;- setNames(location_counts$label, location_counts$location)\n\ng_viral &lt;- ggplot(location_viral, aes(x=location, y=p_reads, fill=location)) +\n  geom_violin(trim=FALSE) +\n  geom_boxplot(width=0.1, fill=\"white\", color=\"black\", outlier.shape=NA) +\n  geom_jitter(width=0.1, size=0.5, alpha=0.5) +\n  scale_y_log10(name=\"Viral read fraction\", labels = label_log(digits=2)) +\n  scale_x_discrete(name=\"Location\", labels = location_labels) +\n  scale_fill_brewer(palette = \"Dark2\") +\n  labs(title=\"Total viral fraction based on assigned reads over all locations\") +\n  theme_light() + \n  theme(\n    axis.text.y = element_text(size = 12),\n    axis.text.x = element_text(size = 12, angle = 45, hjust = 1),\n    axis.title.x = element_text(size = 15),    \n    axis.title.y = element_text(size = 15),  \n    legend.position = \"none\",\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank()\n  ) +\n  theme_kit +\n  coord_flip()  # This flips the coordinates to make the plot horizontal\n\ng_viral"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#taxonomic-composition-of-viruses",
    "href": "notebooks/2024-07-23-mengyi.html#taxonomic-composition-of-viruses",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n3.3 Taxonomic composition of viruses",
    "text": "3.3 Taxonomic composition of viruses\nThe threshold for the label “other” are the set of families that make up less than 20% composition in all samples (the only reason I did this was because there were too many matches). We can see that other makes up a big portion of the viral composition. Outside of the “other” label, Hepadnaviridae makes up the largest portion of the viral composition.\n\nCodemajor_threshold &lt;- 0.20\n\n# Identify major viral families\nviral_families_major_tab &lt;- viral_families %&gt;% \n  group_by(name, taxid) %&gt;%\n  summarize(p_reads_viral_max = max(p_reads_viral), .groups=\"drop\") %&gt;%\n  filter(p_reads_viral_max &gt;= major_threshold)\nviral_families_major_list &lt;- viral_families_major_tab %&gt;% pull(name)\nviral_families_major &lt;- viral_families %&gt;% \n  filter(name %in% viral_families_major_list) %&gt;%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_minor &lt;- viral_families_major %&gt;% \n  group_by(sample) %&gt;%\n  summarize(p_reads_viral_major = sum(p_reads_viral), .groups = \"drop\") %&gt;%\n  mutate(name = \"Other\", taxid=NA, p_reads_viral = 1-p_reads_viral_major) %&gt;%\n  select(name, taxid, sample, p_reads_viral)\nviral_families_display &lt;- viral_families_major %&gt;% \n  bind_rows(viral_families_minor) %&gt;%\n  arrange(desc(p_reads_viral)) %&gt;% \n  mutate(name = factor(name, levels=c(viral_families_major_list, \"Other\"))) %&gt;%\n  rename(p_reads = p_reads_viral, classification=name) %&gt;%\n  inner_join(libraries, by='sample')\n\n# Create a custom color palette with up to 20 colors\ncustom_palette &lt;- c(\n  brewer.pal(12, \"Paired\"),\n  brewer.pal(12, \"Set3\")\n)\n\nn_classifications &lt;- length(unique(viral_families_display$classification)) - 1\n\ncustom_palette_with_black &lt;- c(\n  custom_palette[1:n_classifications],\n  \"black\"\n)\n\n# Create a new color palette with black for \"Other\"\ncustom_palette_with_black &lt;- c(\n  custom_palette[1:n_classifications],\n  \"black\"\n)\n\n# Plot\ng_families &lt;- g_comp_base + \n  geom_comp(data=viral_families_display) +\n  scale_y_continuous(name=\"% Viral Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_manual(values = custom_palette_with_black) +\n  facet_wrap(~ location, scales = \"free_x\", ncol = 2) \ng_families"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#overall-relative-abundance",
    "href": "notebooks/2024-07-23-mengyi.html#overall-relative-abundance",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n4.1 Overall relative abundance",
    "text": "4.1 Overall relative abundance\nI calculated the relative abundance of human-infecting viruses in two ways:\n\nFirst, as the total number of deduplicated human-virus reads in each sample, divided by the number of raw reads (“All reads”).\nSecond, as a fraction of preprocessed (cleaned, deduplicated, computationally ribodepleted) reads (“Preprocessed reads”).\n\nNote that 10 of the pools had no viral reads: 5 from “Heilongjiang, Mudanjiang”, 4 from “Jiangsu, Nanjing”, and 1 from “Xinjiang, Urmqi”.\n\nCode# Get raw read counts\nread_counts_raw &lt;- filter(basic_stats_raw) %&gt;%\n  select(sample, n_reads_raw = n_read_pairs)\nread_counts_preproc &lt;- basic_stats %&gt;% filter(stage == \"ribo_initial\") %&gt;%\n  select(sample, n_reads_preproc = n_read_pairs)\n\n# Get HV read counts\nread_counts_hv &lt;- mrg_hv %&gt;% filter(hv_status) %&gt;% \n  group_by(sample) %&gt;% \n  count(name=\"n_reads_hv\")\nread_counts &lt;- read_counts_raw %&gt;%\n  left_join(read_counts_hv, by=c(\"sample\")) %&gt;%\n  mutate(n_reads_hv = replace_na(n_reads_hv, 0)) %&gt;%\n  left_join(read_counts_preproc, by=c(\"sample\")) %&gt;%\n  inner_join(libraries, by=c(\"sample\")) %&gt;%\n  select(sample, n_reads_raw, n_reads_preproc, n_reads_hv) %&gt;%\n  mutate(n_samples = 1,\n         p_reads_total = n_reads_hv/n_reads_raw,\n         p_reads_preproc = n_reads_hv/n_reads_preproc)\nread_counts_long &lt;- read_counts %&gt;%\n  pivot_longer(starts_with(\"p_reads\"), names_to=\"read_group\", values_to=\"p_reads\") %&gt;%\n  mutate(read_group = ifelse(read_group == \"p_reads_total\", \"All reads\", \"Preprocessed reads\"))\n\n# Combine for display\nread_counts_agg &lt;- read_counts %&gt;%\n  mutate(p_reads_total = n_reads_hv/n_reads_raw,\n         p_reads_preproc = n_reads_hv/n_reads_preproc) %&gt;%\n  inner_join(libraries, by=c(\"sample\"))\nread_counts_agg_long &lt;- read_counts_agg %&gt;%\n  pivot_longer(starts_with(\"p_reads\"), names_to=\"read_group\", values_to=\"p_reads\") %&gt;%\n  mutate(read_group = ifelse(read_group == \"p_reads_total\", \"All reads\", \"Preprocessed reads\")) \n\n# Visualize\n#g_read_counts &lt;- ggplot(read_counts_agg_long, aes(x=library, y=p_reads)) +\n#  geom_point() +\n#  scale_y_log10(name = \"Unique human-viral read fraction\") +\n#  facet_grid(.~read_group, scales = \"free\") +\n#  theme_kit\n#g_read_counts\n\n#g_viral &lt;- ggplot(read_counts_agg_long, aes(x=p_reads, y=library, color=location, shape=read_group)) +\n#  geom_point() +\n#  scale_y_discrete(name=\"Plasma pool\") +\n#  scale_x_log10(name=\"Viral read fraction\") +\n#  scale_color_brewer(palette = \"Dark2\") +\n#  facet_grid(.~read_group, scales = \"free\") +\n#  guides(color=guide_legend(nrow=2), shape=guide_legend(nrow=2),\n#         linetype=guide_legend(nrow=2)) +\n#  theme_kit\n#g_viral\n\nhv_location &lt;- read_counts_agg_long %&gt;% filter(read_group == \"Preprocessed reads\" ) %&gt;% group_by(location) \n\nhv_location_counts &lt;- hv_location %&gt;%\n  group_by(location) %&gt;%\n  summarise(count = n()) %&gt;%\n  mutate(label = paste0(location, \" (n=\", count, \")\"))\n\n  # Create a named vector for easy mapping\nlocation_labels &lt;- setNames(hv_location_counts$label, hv_location_counts$location)\n\n# Create a named vector for easy mapping\n# Plot\n# g_viral &lt;- ggplot(p_reads_viral, aes(x=p_reads, y=library, color=location, shape=read_group)) +\n#   geom_point() +\n#   scale_y_discrete(name=\"Plasma pool\") +\n#   scale_x_log10(name=\"Viral read fraction\") +\n#   scale_color_brewer(palette = \"Dark2\") +\n#   #facet_grid(.~read_group, scales = \"free\") +\n#   guides(color=guide_legend(nrow=2), shape=guide_legend(nrow=2),\n#          linetype=guide_legend(nrow=2)) +\n#   theme_kit\n\n#ggplot(location_viral, aes(x=p_reads, y=location, color = location)) +\n#  geom_quasirandom(size=2) +\n#  scale_x_log10(name=\"Viral read fraction\", labels = label_log(digits=2)) +\n#  scale_y_discrete(name=\"Location\") +\n#  scale_color_brewer(palette = \"Dark2\") +\n#  theme_light() + \n#    theme(\n#    axis.text.y = element_text(size = 8),\n#    axis.text.x = element_text(size = 14),\n#    axis.ticks.y = element_blank(),\n#    axis.line = element_line(colour = \"black\"),\n#    axis.title.x = element_text(size = 15),    \n#    axis.title.y = element_text(size = 15),  \n#    legend.text = element_text(size = 13),\n#    legend.title = element_text(size = 16),\n#    legend.position = c(1, 1),  # Move legend to top right\n##    legend.justification = c(1, 1),  # Align legend to top right\n#    panel.grid.minor = element_blank(),\n#    panel.border = element_blank(),\n#    panel.background = element_blank())\n\ng_viral &lt;- ggplot(hv_location, aes(x=location, y=p_reads, fill=location)) +\n  geom_violin(trim=FALSE) +\n  geom_boxplot(width=0.1, fill=\"white\", color=\"black\", outlier.shape=NA) +\n  geom_jitter(width=0.1, size=0.5, alpha=0.5) +\n  scale_y_log10(name=\"Viral read fraction\", labels = label_log(digits=2)) +\n  scale_x_discrete(name=\"Location\", labels = location_labels) +\n  scale_fill_brewer(palette = \"Dark2\") +\n  theme_light() + \n  theme(\n    axis.text.y = element_text(size = 12),\n    axis.text.x = element_text(size = 12, angle = 45, hjust = 1),\n    axis.title.x = element_text(size = 15),    \n    axis.title.y = element_text(size = 15),  \n    legend.position = \"none\",\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank()\n  ) +\n  theme_kit +\n  coord_flip()  # This flips the coordinates to make the plot horizontal\n\ng_viral"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#overall-taxonomy-and-composition",
    "href": "notebooks/2024-07-23-mengyi.html#overall-taxonomy-and-composition",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n4.2 Overall taxonomy and composition",
    "text": "4.2 Overall taxonomy and composition\nThe two dominant viruses we see are Anellovirdae and Hepadnaviridae, with Parvoviridae . The threshold for the label “other” are the set of families that make up less than 5% composition in all samples.\n\nCodethreshold_major_family &lt;- 0.05\n\n# Count reads for each human-viral family\nhv_family_counts &lt;- hv_reads_family %&gt;% \n  group_by(sample, name, taxid) %&gt;%\n  count(name = \"n_reads_hv\") %&gt;%\n  group_by(sample) %&gt;%\n  mutate(p_reads_hv = n_reads_hv/sum(n_reads_hv))\n\n# Identify high-ranking families and group others\nhv_family_major_tab &lt;- hv_family_counts %&gt;% group_by(name) %&gt;% \n  filter(p_reads_hv == max(p_reads_hv)) %&gt;% filter(row_number() == 1) %&gt;%\n  arrange(desc(p_reads_hv)) %&gt;% filter(p_reads_hv &gt; threshold_major_family)\nhv_family_counts_major &lt;- hv_family_counts %&gt;%\n  mutate(name_display = ifelse(name %in% hv_family_major_tab$name, name, \"Other\")) %&gt;%\n  group_by(sample, name_display) %&gt;%\n  summarize(n_reads_hv = sum(n_reads_hv), p_reads_hv = sum(p_reads_hv), \n            .groups=\"drop\") %&gt;%\n  mutate(name_display = factor(name_display, \n                               levels = c(hv_family_major_tab$name, \"Other\")))\nhv_family_counts_display &lt;- hv_family_counts_major %&gt;%\n  rename(p_reads = p_reads_hv, classification = name_display) %&gt;%\n  inner_join(libraries, by = 'sample')\n\n# Plot\ng_hv_family &lt;- g_comp_base + \n  geom_col(data=hv_family_counts_display, position = \"stack\", width=1) +\n  scale_y_continuous(name=\"% HV Reads\", limits=c(0,1.01), \n                     breaks = seq(0,1,0.2),\n                     expand=c(0,0), labels = function(y) y*100) +\n  scale_fill_brewer(palette = \"Set1\", name = \"Viral family\") +\n\n  labs(title=\"Family composition of human-viral reads\") +\n  guides(fill=guide_legend(ncol=4)) +\n  theme(plot.title = element_text(size=rel(1.4), hjust=0, face=\"plain\")) +  \n  facet_wrap(~ location, scales = \"free_x\", ncol = 2) \ng_hv_family\n\n\n\n\n\n\nCode# Get most prominent families for text\nhv_family_collate &lt;- hv_family_counts %&gt;%\n  group_by(name, taxid) %&gt;% \n  summarize(n_reads_tot = sum(n_reads_hv),\n            p_reads_max = max(p_reads_hv), .groups=\"drop\") %&gt;% \n  arrange(desc(n_reads_tot))\ndisplay_hv_family_collate &lt;- hv_family_collate %&gt;%\n  select(name, n_reads_tot) %&gt;%\n  rename(`Family` = name, `Total number of reads` = n_reads_tot)\ndisplay_hv_family_collate"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#species-analysis",
    "href": "notebooks/2024-07-23-mengyi.html#species-analysis",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n4.3 Species analysis",
    "text": "4.3 Species analysis\nTo get a better idea of the relative abundance of species, we can create a dot plot where each dot represents the relative abundance of a particular species in a sample.\n\nCodespecies_family &lt;- result %&gt;% select(species, family) %&gt;% rename('name' = 'species')\n\nplay &lt;- hv_species_counts %&gt;% \n  ungroup() %&gt;%\n  inner_join(libraries, by = 'sample') %&gt;%\n  inner_join(species_family, by = 'name') %&gt;%\n  mutate(name = ifelse(name == \"Severe acute respiratory syndrome-related coronavirus\", \"SARS-related coronavirus\", name))\n\nadjusted_play &lt;- play %&gt;% \n  group_by(name) %&gt;%\n  mutate(virus_prevalence_num = n_distinct(sample)/n_distinct(libraries),\n         total_reads_hv = sum(n_reads_hv)) %&gt;%\n  ungroup() %&gt;%\n  mutate(name = fct_reorder(name, virus_prevalence_num, .desc=TRUE)) %&gt;% \n  select(name, ra_reads_hv, family, location, virus_prevalence_num, total_reads_hv, n_reads_hv)\n\npal &lt;- c(brewer.pal(8, 'Dark2'),brewer.pal(8, 'Accent'))\n\n#, labels = label_log(digits=2)\n\nra_dot &lt;- ggplot(adjusted_play, aes(x = ra_reads_hv, y=name)) +\n  geom_quasirandom(orientation = 'y', aes(color = family)) +\n  scale_color_manual(values = pal) + \n    scale_x_log10(\n    \"Relative abundance human virus reads\",\n    labels=label_log(digits=3)\n  ) +\n  labs(y =  \"\",\n       color = 'Viral family') + \n  guides(color = guide_legend(ncol=2)) +\n  theme_light() + \n    theme(\n    axis.text.y = element_text(size = 10),\n    axis.text.x = element_text(size = 12),\n    axis.ticks.y = element_blank(),axis.line = element_line(colour = \"black\"),\n    axis.title.x = element_text(size = 14),    \n    legend.text = element_text(size = 10),\n    legend.title = element_text(size = 10, face=\"bold\"),\n    legend.position = 'bottom',\n    #legend.position = c(1, 1),  # Move legend to top right\n    #legend.justification = c(1, 1),  # Align legend to top right\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank())\n#  geom_text(aes(label = total_reads_hv, y = name), \n#            x = 1e-9, hjust = 0, vjust = 0.5, size = 3, \n#            check_overlap = TRUE)\nprev_play &lt;- adjusted_play %&gt;%\n  group_by(name, location) %&gt;%\n  reframe(location_of_reads = n_reads_hv/total_reads_hv,\n          total_reads_hv = first(total_reads_hv))\n\nprevalence_bar &lt;- ggplot(prev_play, aes(x = location_of_reads, y = name, fill = location)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +\n  scale_fill_brewer(palette = \"Accent\") +\n  scale_x_continuous(\n    \"Relative composition of locations with reads\",\n    labels = scales::percent_format(scale = 100, accuracy = 1),\n    limits = c(0, 1)\n  ) +\n  labs(y = '',\n       fill = 'Location') +\n  guides(fill = guide_legend(ncol=1)) +\n  theme_light() + \n  theme(\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size = 12),\n    axis.ticks.y = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    axis.title.x = element_text(size = 14),    \n    axis.title.y = element_blank(),  \n    legend.text = element_text(size = 10),\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.position = 'bottom', \n    #legend.position = c(1, 1),  # Move legend to top right\n    #legend.justification = c(1, 1),  # Align legend to top right\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank()) + \n  geom_text(aes(label = total_reads_hv, y = name), \n            x = 1e-9, hjust = 0, vjust = 0.5, size = 3, \n            check_overlap = TRUE, fontface = \"bold\")\n# Combine the plots using ggarrange\ncombined_plot &lt;- ggarrange(ra_dot, prevalence_bar, \n                           ncol = 2, \n                           widths = c(2, 1),\n                           common.legend = FALSE,\n                           align = \"h\")\ncombined_plot\n\n\n\n\n\n\n\nWe can ask Claude to analyze the pathogenicity of these viruses along with their popular names.\n\n\n\n\n\n\n\nScientific Name\nPopular/Well-known Name\nPathogenicity to Humans\n\n\n\nHuman immunodeficiency virus 1\nHIV-1\nVery High\n\n\nSevere acute respiratory syndrome-related coronavirus\nSARS-CoV\nHigh\n\n\nHepatitis B virus\nHBV\nHigh\n\n\nHepacivirus hominis\nHepatitis C virus (HCV)\nHigh\n\n\nSimplexvirus humanalpha1\nHerpes simplex virus 1 (HSV-1)\nModerate to High\n\n\nCytomegalovirus humanbeta5\nHuman cytomegalovirus (HCMV)\nModerate to High\n\n\nLymphocryptovirus humangamma4\nEpstein-Barr virus (EBV)\nModerate\n\n\nHuman mastadenovirus C\nAdenovirus C\nModerate\n\n\nHuman mastadenovirus F\nAdenovirus F\nModerate\n\n\nRoseolovirus humanbeta6a\nHuman herpesvirus 6A (HHV-6A)\nLow to Moderate\n\n\nRoseolovirus humanbeta6b\nHuman herpesvirus 6B (HHV-6B)\nLow to Moderate\n\n\nRoseolovirus humanbeta7\nHuman herpesvirus 7 (HHV-7)\nLow to Moderate\n\n\nRhadinovirus humangamma8\nKaposi’s sarcoma-associated herpesvirus (KSHV)\nLow to Moderate\n\n\nMolluscum contagiosum virus\nMCV\nLow\n\n\nErythroparvovirus primate1\nParvovirus B19\nLow\n\n\nHuman erythrovirus V9\nErythrovirus V9\nLow\n\n\nAlphapapillomavirus 4\nHuman papillomavirus 4 (HPV-4)\nLow\n\n\nBetapolyomavirus hominis\nHuman polyomavirus\nLow\n\n\nDependoparvovirus primate1\nAdeno-associated virus (AAV)\nVery Low\n\n\nMurine leukemia virus\nMLV\nVery Low (not a human pathogen)\n\n\nMurine leukemia-related retroviruses\nMLV-related viruses\nVery Low (not typical human pathogens)\n\n\nGokushovirus WZ-2015a\n-\nUnknown (likely Very Low)\n\n\nHuman gut gokushovirus\n-\nUnknown (likely Very Low)\n\n\nMicroviridae sp.\n-\nUnknown (likely Very Low)\n\n\nMicrovirus sp.\n-\nUnknown (likely Very Low)\n\n\n\nI’d like to BLAST some of these reads against the NCBI nt database to see if we can get some more info on them."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Harmon’s public notebook",
    "section": "",
    "text": "Workflow of Mengyi et al. (2023)\n\n\nPooled plasma from China (DNA)\n\n\n\n\n\n\n\n\nJul 23, 2024\n\n\nHarmon Bhasin\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#sankey-plot-of-hv-families-genus-and-species",
    "href": "notebooks/2024-07-23-mengyi.html#sankey-plot-of-hv-families-genus-and-species",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n6.1 Sankey plot of HV families, genus, and species",
    "text": "6.1 Sankey plot of HV families, genus, and species\nTo get a good overview of families, genera, and species, we can look at a Sankey plot where the magnitude of relative abundance, averaged over all samples, is shown in parentheses.\n\nCode# Function to create links\ncreate_links &lt;- function(data) {\n  family_to_genus &lt;- data %&gt;%\n    filter(!is.na(genus)) %&gt;%\n    group_by(family, genus) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = genus)\n  \n  genus_to_species &lt;- data %&gt;%\n    group_by(genus, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = genus, target = species)\n\n  family_to_species &lt;- data %&gt;%\n    filter(is.na(genus)) %&gt;%\n    group_by(family, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = species)\n\n  bind_rows(family_to_genus, genus_to_species, family_to_species) %&gt;%\n    filter(!is.na(source))\n}\n\n# Function to create nodes\ncreate_nodes &lt;- function(links) {\n  data.frame(\n    name = c(links$source, links$target) %&gt;% unique()\n  )\n}\n\n# Function to prepare data for Sankey diagram\nprepare_sankey_data &lt;- function(links, nodes) {\n  links$IDsource &lt;- match(links$source, nodes$name) - 1\n  links$IDtarget &lt;- match(links$target, nodes$name) - 1\n  list(links = links, nodes = nodes)\n}\n\n# Function to create Sankey plot\ncreate_sankey_plot &lt;- function(sankey_data) {\n  sankeyNetwork(\n    Links = sankey_data$links, \n    Nodes = sankey_data$nodes,\n    Source = \"IDsource\", \n    Target = \"IDtarget\",\n    Value = \"value\", \n    NodeID = \"name\",\n    sinksRight = TRUE,\n    nodeWidth = 25,\n    fontSize = 14,\n  )\n}\n\nsave_sankey_as_png &lt;- function(sankey_plot, width = 1000, height = 800) {\n  # Save the plot as an HTML file\n  saveWidget(sankey_plot, sprintf('%s/sankey.html',data_dir))\n}\n\nformat_scientific &lt;- function(x, digits=2) {\n  sapply(x, function(val) {\n    if (is.na(val) || abs(val) &lt; 1e-15) {\n      return(\"0\")\n    } else {\n      exponent &lt;- floor(log10(abs(val)))\n      coef &lt;- val / 10^exponent\n      #return(sprintf(\"%.1f × 10^%d\", round(coef, digits), exponent))\n      # May or may not be smart, just keeping magnitude\n      return(sprintf(\"10^%d\", exponent))\n    }\n  })\n}\n\ndata &lt;- result %&gt;% \n  mutate(across(c(genus_n_reads_tot, genus_ra_reads_tot), ~replace_na(., 0)),\n         genus = ifelse(is.na(genus), \"Unknown Genus\", genus)) %&gt;%\n  mutate(\n  species = paste0(species, sprintf(' (%s)', format_scientific(species_ra_reads_tot))),\n  genus = paste0(genus, sprintf(' (%s)', format_scientific(genus_ra_reads_tot))),\n  family = paste0(family, sprintf(' (%s)', format_scientific(family_ra_reads_tot)))\n)\nlinks &lt;- as.data.frame(create_links(data))\nnodes &lt;- create_nodes(links)\nsankey_data &lt;- prepare_sankey_data(links, nodes)\nsankey &lt;- create_sankey_plot(sankey_data)\n\nsankey"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#sankey-plot-of-hv-infecting-families-genus-and-species",
    "href": "notebooks/2024-07-23-mengyi.html#sankey-plot-of-hv-infecting-families-genus-and-species",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n6.1 Sankey plot of HV infecting families, genus, and species",
    "text": "6.1 Sankey plot of HV infecting families, genus, and species\nTo get a good overview of families, genera, and species, we can look at a Sankey plot where the magnitude of relative abundance, averaged over all samples, is shown in parentheses.\n\nCode# Function to create links\ncreate_links &lt;- function(data) {\n  family_to_genus &lt;- data %&gt;%\n    filter(!is.na(genus)) %&gt;%\n    group_by(family, genus) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = genus)\n  \n  genus_to_species &lt;- data %&gt;%\n    group_by(genus, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = genus, target = species)\n\n  family_to_species &lt;- data %&gt;%\n    filter(is.na(genus)) %&gt;%\n    group_by(family, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = species)\n\n  bind_rows(family_to_genus, genus_to_species, family_to_species) %&gt;%\n    filter(!is.na(source))\n}\n\n# Function to create nodes\ncreate_nodes &lt;- function(links) {\n  data.frame(\n    name = c(links$source, links$target) %&gt;% unique()\n  )\n}\n\n# Function to prepare data for Sankey diagram\nprepare_sankey_data &lt;- function(links, nodes) {\n  links$IDsource &lt;- match(links$source, nodes$name) - 1\n  links$IDtarget &lt;- match(links$target, nodes$name) - 1\n  list(links = links, nodes = nodes)\n}\n\n# Function to create Sankey plot\ncreate_sankey_plot &lt;- function(sankey_data) {\n  sankeyNetwork(\n    Links = sankey_data$links, \n    Nodes = sankey_data$nodes,\n    Source = \"IDsource\", \n    Target = \"IDtarget\",\n    Value = \"value\", \n    NodeID = \"name\",\n    sinksRight = TRUE,\n    nodeWidth = 25,\n    fontSize = 14,\n  )\n}\n\nsave_sankey_as_png &lt;- function(sankey_plot, width = 1000, height = 800) {\n  # Save the plot as an HTML file\n  saveWidget(sankey_plot, sprintf('%s/sankey.html',data_dir))\n}\n\nformat_scientific &lt;- function(x, digits=2) {\n  sapply(x, function(val) {\n    if (is.na(val) || abs(val) &lt; 1e-15) {\n      return(\"0\")\n    } else {\n      exponent &lt;- floor(log10(abs(val)))\n      coef &lt;- val / 10^exponent\n      #return(sprintf(\"%.1f × 10^%d\", round(coef, digits), exponent))\n      # May or may not be smart, just keeping magnitude\n      return(sprintf(\"10^%d\", exponent))\n    }\n  })\n}\n\ndata &lt;- result %&gt;% \n  mutate(across(c(genus_n_reads_tot, genus_ra_reads_tot), ~replace_na(., 0)),\n         genus = ifelse(is.na(genus), \"Unknown Genus\", genus)) %&gt;%\n  mutate(\n  species = paste0(species, sprintf(' (%s)', format_scientific(species_ra_reads_tot))),\n  genus = paste0(genus, sprintf(' (%s)', format_scientific(genus_ra_reads_tot))),\n  family = paste0(family, sprintf(' (%s)', format_scientific(family_ra_reads_tot)))\n)\nlinks &lt;- as.data.frame(create_links(data))\nnodes &lt;- create_nodes(links)\nsankey_data &lt;- prepare_sankey_data(links, nodes)\nsankey &lt;- create_sankey_plot(sankey_data)\n\nsankey"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#human-infecting-virus-families-genera-and-species",
    "href": "notebooks/2024-07-23-mengyi.html#human-infecting-virus-families-genera-and-species",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n6.1 Human-infecting virus families, genera, and species",
    "text": "6.1 Human-infecting virus families, genera, and species\nTo get a good overview of families, genera, and species, we can look at a Sankey plot where the magnitude of relative abundance, averaged over all samples, is shown in parentheses.\n\nCode# Function to create links\ncreate_links &lt;- function(data) {\n  family_to_genus &lt;- data %&gt;%\n    filter(!is.na(genus)) %&gt;%\n    group_by(family, genus) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = genus)\n  \n  genus_to_species &lt;- data %&gt;%\n    group_by(genus, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = genus, target = species)\n\n  family_to_species &lt;- data %&gt;%\n    filter(is.na(genus)) %&gt;%\n    group_by(family, species) %&gt;%\n    summarise(value = n(), .groups = \"drop\") %&gt;%\n    mutate(source = family, target = species)\n\n  bind_rows(family_to_genus, genus_to_species, family_to_species) %&gt;%\n    filter(!is.na(source))\n}\n\n# Function to create nodes\ncreate_nodes &lt;- function(links) {\n  data.frame(\n    name = c(links$source, links$target) %&gt;% unique()\n  )\n}\n\n# Function to prepare data for Sankey diagram\nprepare_sankey_data &lt;- function(links, nodes) {\n  links$IDsource &lt;- match(links$source, nodes$name) - 1\n  links$IDtarget &lt;- match(links$target, nodes$name) - 1\n  list(links = links, nodes = nodes)\n}\n\n# Function to create Sankey plot\ncreate_sankey_plot &lt;- function(sankey_data) {\n  sankeyNetwork(\n    Links = sankey_data$links, \n    Nodes = sankey_data$nodes,\n    Source = \"IDsource\", \n    Target = \"IDtarget\",\n    Value = \"value\", \n    NodeID = \"name\",\n    sinksRight = TRUE,\n    nodeWidth = 25,\n    fontSize = 14,\n  )\n}\n\nsave_sankey_as_png &lt;- function(sankey_plot, width = 1000, height = 800) {\n  # Save the plot as an HTML file\n  saveWidget(sankey_plot, sprintf('%s/sankey.html',data_dir))\n}\n\nformat_scientific &lt;- function(x, digits=2) {\n  sapply(x, function(val) {\n    if (is.na(val) || abs(val) &lt; 1e-15) {\n      return(\"0\")\n    } else {\n      exponent &lt;- floor(log10(abs(val)))\n      coef &lt;- val / 10^exponent\n      #return(sprintf(\"%.1f × 10^%d\", round(coef, digits), exponent))\n      # May or may not be smart, just keeping magnitude\n      return(sprintf(\"10^%d\", exponent))\n    }\n  })\n}\n\ndata &lt;- result %&gt;% \n  mutate(across(c(genus_n_reads_tot, genus_ra_reads_tot), ~replace_na(., 0)),\n         genus = ifelse(is.na(genus), \"Unknown Genus\", genus)) %&gt;%\n  mutate(\n  species = paste0(species, sprintf(' (%s)', format_scientific(species_ra_reads_tot))),\n  genus = paste0(genus, sprintf(' (%s)', format_scientific(genus_ra_reads_tot))),\n  family = paste0(family, sprintf(' (%s)', format_scientific(family_ra_reads_tot)))\n)\nlinks &lt;- as.data.frame(create_links(data))\nnodes &lt;- create_nodes(links)\nsankey_data &lt;- prepare_sankey_data(links, nodes)\nsankey &lt;- create_sankey_plot(sankey_data)\n\nsankey\n\n\n\n\n\n\nCodespecies_family &lt;- result %&gt;% select(species, family) %&gt;% rename('name' = 'species')\n\nplay &lt;- hv_species_counts %&gt;% \n  ungroup() %&gt;%\n  inner_join(libraries, by = 'sample') %&gt;%\n  inner_join(species_family, by = 'name') %&gt;%\n  mutate(name = ifelse(name == \"Severe acute respiratory syndrome-related coronavirus\", \"SARS-related coronavirus\", name))\n\nadjusted_play &lt;- play %&gt;% \n  group_by(name) %&gt;%\n  mutate(virus_prevalence_num = n_distinct(sample)/n_distinct(libraries),\n         total_reads_hv = sum(n_reads_hv)) %&gt;%\n  ungroup() %&gt;%\n  mutate(name = fct_reorder(name, virus_prevalence_num, .desc=TRUE)) %&gt;% \n  select(name, ra_reads_hv, family, location, virus_prevalence_num, total_reads_hv, n_reads_hv)\n\npal &lt;- c(brewer.pal(8, 'Dark2'),brewer.pal(8, 'Accent'))\n\n#, labels = label_log(digits=2)\n\nra_dot &lt;- ggplot(adjusted_play, aes(x = ra_reads_hv, y=name)) +\n  geom_quasirandom(orientation = 'y', aes(color = family)) +\n  scale_color_manual(values = pal) + \n    scale_x_log10(\n    \"Relative abundance human virus reads\",\n    labels=label_log(digits=3)\n  ) +\n  labs(y =  \"\",\n       color = 'Viral family') + \n  guides(color = guide_legend(ncol=2)) +\n  theme_light() + \n    theme(\n    axis.text.y = element_text(size = 10),\n    axis.text.x = element_text(size = 12),\n    axis.ticks.y = element_blank(),axis.line = element_line(colour = \"black\"),\n    axis.title.x = element_text(size = 14),    \n    legend.text = element_text(size = 10),\n    legend.title = element_text(size = 10, face=\"bold\"),\n    legend.position = 'bottom',\n    #legend.position = c(1, 1),  # Move legend to top right\n    #legend.justification = c(1, 1),  # Align legend to top right\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank())\n#  geom_text(aes(label = total_reads_hv, y = name), \n#            x = 1e-9, hjust = 0, vjust = 0.5, size = 3, \n#            check_overlap = TRUE)\nprev_play &lt;- adjusted_play %&gt;%\n  group_by(name, location) %&gt;%\n  reframe(location_of_reads = n_reads_hv/total_reads_hv,\n          total_reads_hv = first(total_reads_hv))\n\nprevalence_bar &lt;- ggplot(prev_play, aes(x = location_of_reads, y = name, fill = location)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +\n  scale_fill_brewer(palette = \"Accent\") +\n  scale_x_continuous(\n    \"Relative composition of locations with reads\",\n    labels = scales::percent_format(scale = 100, accuracy = 1),\n    limits = c(0, 1)\n  ) +\n  labs(y = '',\n       fill = 'Location') +\n  guides(fill = guide_legend(ncol=1)) +\n  theme_light() + \n  theme(\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size = 12),\n    axis.ticks.y = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    axis.title.x = element_text(size = 14),    \n    axis.title.y = element_blank(),  \n    legend.text = element_text(size = 10),\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.position = 'bottom', \n    #legend.position = c(1, 1),  # Move legend to top right\n    #legend.justification = c(1, 1),  # Align legend to top right\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank()) + \n  geom_text(aes(label = total_reads_hv, y = name), \n            x = 1e-9, hjust = 0, vjust = 0.5, size = 3, \n            check_overlap = TRUE, fontface = \"bold\")\n# Combine the plots using ggarrange\ncombined_plot &lt;- ggarrange(ra_dot, prevalence_bar, \n                           ncol = 2, \n                           widths = c(2, 1),\n                           common.legend = FALSE,\n                           align = \"h\")\ncombined_plot"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#analyzing-specific-families",
    "href": "notebooks/2024-07-23-mengyi.html#analyzing-specific-families",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n4.3 Analyzing specific families",
    "text": "4.3 Analyzing specific families\nWe now investigate the composition of specific families that had more than 5 viral reads. In investigating individual viral families, to avoid distortions from a few rare reads, I restricted myself to samples where that family made up at least 10% of human-viral reads:\n\n4.3.1 Hepadnaviridae (Number of reads: 339,427)\n\nCode# Hepadnaviridae\nplot_viral_family_histogram(taxid_chosen=10404)\n\n\n\n\n\n\n\n\nCode# Hepadnaviridae\nplot_viral_family_composition(taxid_chosen=10404, threshold_major_species = 0.1)\n\n\n\n\n\n\n\n\n4.3.2 Parvoviridae (Number of reads: 17,401)\n\nCode# Parvoviridae\nplot_viral_family_histogram(taxid_chosen=10780)\n\n\n\n\n\n\n\n\nCode# Parvoviridae\nplot_viral_family_composition(taxid_chosen=10780, threshold_major_species = 0.1)\n\n\n\n\n\n\n\n\n4.3.3 Anelloviridae (Number of reads: 3001)\n\nCode# Anelloviridae\nplot_viral_family_histogram(taxid_chosen=687329)\n\n\n\n\n\n\n\n\nCode# Anelloviridae\nplot_viral_family_composition(taxid_chosen=687329, threshold_major_species = 0.1)\n\n\n\n\n\n\n\n\n4.3.4 Orthoherpesviridae (Number of reads: 298)\n\nCode# Orthoherpesviridae\nplot_viral_family_histogram(taxid_chosen=3044472)\n\n\n\n\n\n\n\n\nCode# Orthoherpesviridae\nplot_viral_family_composition(taxid_chosen=3044472, threshold_major_species = 0.1)\n\n\n\n\n\n\n\n\n4.3.5 Retroviridae (Number of reads: 115)\n\nCode# Retroviridae\nplot_viral_family_histogram(taxid_chosen=11632)\n\n\n\n\n\n\n\n\nCode# Retroviridae\nplot_viral_family_composition(taxid_chosen=11632, threshold_major_species = 0.1)\n\n\n\n\n\n\n\n\n4.3.6 Microviridae (Number of reads: 61)\n\nCode# Microviridae\nplot_viral_family_histogram(taxid_chosen=10841)\n\n\n\n\n\n\n\n\nCode# Microviridae\nplot_viral_family_composition(taxid_chosen=10841, threshold_major_species = 0.1)\n\n\n\n\n\n\n\n\n4.3.7 Adenoviridae (Number of reads: 28)\n\nCode# Adenoviridae\nplot_viral_family_histogram(taxid_chosen=10508)\n\n\n\n\n\n\n\n\nCode# Adenoviridae\nplot_viral_family_composition(taxid_chosen=10508, threshold_major_species = 0.1)"
  },
  {
    "objectID": "notebooks/2024-07-23-mengyi.html#relative-abundance-of-pathogenic-viruses-of-interest",
    "href": "notebooks/2024-07-23-mengyi.html#relative-abundance-of-pathogenic-viruses-of-interest",
    "title": "Workflow of Mengyi et al. (2023)",
    "section": "\n4.4 Relative abundance of pathogenic viruses of interest",
    "text": "4.4 Relative abundance of pathogenic viruses of interest\nEach dot represents a sample, colored by viral family. The x-axis shows the relative abundance of human-infecting viruses, and the y-axis shows the species.\n\nCodespecies_family &lt;- result %&gt;% select(species, family) %&gt;% rename('name' = 'species')\n\nplay &lt;- hv_species_counts %&gt;% \n  ungroup() %&gt;%\n  inner_join(libraries, by = 'sample') %&gt;%\n  inner_join(species_family, by = 'name') %&gt;%\n  mutate(name = ifelse(name == \"Severe acute respiratory syndrome-related coronavirus\", \"SARS-related coronavirus\", name)) %&gt;%\n  filter(!(family %in% c(\"Anelloviridae\", NA, \"Microviridae\", \"Rhabdoviridae\"))) \n\nadjusted_play &lt;- play %&gt;% \n  group_by(name) %&gt;%\n  mutate(virus_prevalence_num = n_distinct(sample)/n_distinct(libraries),\n         total_reads_hv = sum(n_reads_hv)) %&gt;%\n  ungroup() %&gt;%\n  mutate(name = fct_reorder(name, virus_prevalence_num, .desc=TRUE)) %&gt;% \n  select(name, ra_reads_hv, family, location, virus_prevalence_num, total_reads_hv, n_reads_hv)\n\npal &lt;- c(brewer.pal(8, 'Dark2'),brewer.pal(8, 'Accent'))\n\n#, labels = label_log(digits=2)\n\nra_dot &lt;- ggplot(adjusted_play, aes(x = ra_reads_hv, y=name)) +\n  geom_quasirandom(orientation = 'y', aes(color = family)) +\n  scale_color_manual(values = pal) + \n    scale_x_log10(\n    \"Relative abundance human virus reads\",\n    labels=label_log(digits=3)\n  ) +\n  labs(y =  \"\",\n       color = 'Viral family') + \n  guides(color = guide_legend(ncol=2)) +\n  theme_light() + \n    theme(\n    axis.text.y = element_text(size = 10),\n    axis.text.x = element_text(size = 12),\n    axis.ticks.y = element_blank(),axis.line = element_line(colour = \"black\"),\n    axis.title.x = element_text(size = 14),    \n    legend.text = element_text(size = 10),\n    legend.title = element_text(size = 10, face=\"bold\"),\n    legend.position = 'bottom',\n    #legend.position = c(1, 1),  # Move legend to top right\n    #legend.justification = c(1, 1),  # Align legend to top right\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank())\nra_dot\n\n\n\n\n\n\nCode#  geom_text(aes(label = total_reads_hv, y = name), \n#            x = 1e-9, hjust = 0, vjust = 0.5, size = 3, \n#            check_overlap = TRUE)\n\n\nWe can ask Claude to analyze the pathogenicity of these viruses along with their popular names.\n\n\n\n\n\n\n\nScientific Name\nPopular/Well-known Name\nPathogenicity to Humans\n\n\n\nHuman immunodeficiency virus 1\nHIV-1\nVery High\n\n\nSevere acute respiratory syndrome-related coronavirus\nSARS-CoV\nHigh\n\n\nHepatitis B virus\nHBV\nHigh\n\n\nHepacivirus hominis\nHepatitis C virus (HCV)\nHigh\n\n\nSimplexvirus humanalpha1\nHerpes simplex virus 1 (HSV-1)\nModerate to High\n\n\nCytomegalovirus humanbeta5\nHuman cytomegalovirus (HCMV)\nModerate to High\n\n\nLymphocryptovirus humangamma4\nEpstein-Barr virus (EBV)\nModerate\n\n\nHuman mastadenovirus C\nAdenovirus C\nModerate\n\n\nHuman mastadenovirus F\nAdenovirus F\nModerate\n\n\nRoseolovirus humanbeta6a\nHuman herpesvirus 6A (HHV-6A)\nLow to Moderate\n\n\nRoseolovirus humanbeta6b\nHuman herpesvirus 6B (HHV-6B)\nLow to Moderate\n\n\nRoseolovirus humanbeta7\nHuman herpesvirus 7 (HHV-7)\nLow to Moderate\n\n\nRhadinovirus humangamma8\nKaposi’s sarcoma-associated herpesvirus (KSHV)\nLow to Moderate\n\n\nMolluscum contagiosum virus\nMCV\nLow\n\n\nErythroparvovirus primate1\nParvovirus B19\nLow\n\n\nHuman erythrovirus V9\nErythrovirus V9\nLow\n\n\nAlphapapillomavirus 4\nHuman papillomavirus 4 (HPV-4)\nLow\n\n\nBetapolyomavirus hominis\nHuman polyomavirus\nLow\n\n\nDependoparvovirus primate1\nAdeno-associated virus (AAV)\nVery Low\n\n\nMurine leukemia virus\nMLV\nVery Low (not a human pathogen)\n\n\nMurine leukemia-related retroviruses\nMLV-related viruses\nVery Low (not typical human pathogens)\n\n\n\nI’d like to BLAST some of these reads against the NCBI nt database to see if we can get some more info on them.\nI would also like to make the relative abudnace plot where we assume that all human reads have been removed."
  }
]